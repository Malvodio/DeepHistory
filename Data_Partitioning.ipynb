{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DiegoMiranda_TA1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Malvodio/DeepHistory/blob/main/Data_Partitioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDiqJr-m4ZHu"
      },
      "source": [
        "# Tarea Académica 1 (TA1)\n",
        "\n",
        "**Curso:** CS199 - Tópicos Emergentes en Tecnologías de Entretenimiento (Deep Learning)\n",
        "\n",
        "**Profesor:** Jhosimar George Arias Figueroa\n",
        "\n",
        "*Universidad Peruana de Ciencias Aplicadas (UPC)*\n",
        "\n",
        "---\n",
        "\n",
        "## Datos del Alumno\n",
        "\n",
        "**Nombres y Apellidos:** *Diego Miranda Salazar*\n",
        "\n",
        "**Código:** *U201515166*\n",
        "\n",
        "---\n",
        "## Fecha de Entrega \n",
        "\n",
        "Puede entregar el trabajo hasta el día **Lunes 06 de Setiembre del 2021** hasta las 23:59 horas.\n",
        "\n",
        "## Nombre del archivo\n",
        "\n",
        "Deberá subir su trabajo con el nombre **DiegoMiranda_TA1**\n",
        "\n",
        "## Sobre el trabajo\n",
        "\n",
        "Puede acceder a la versión del trabajo en colab desde [aquí](https://colab.research.google.com/drive/1DJPCMaoTDHI0zQ3gVvY9CwEHHSyVfX8y?usp=sharing).\n",
        "\n",
        "Deberá sacar una copia a este notebook desde \"Archivo -> Guardar una copia en Drive\", y deberá completar todas las líneas de código que contengan comentarios TODO o esten inicializadas como None.\n",
        "\n",
        "## Objetivos\n",
        "\n",
        "En este trabajo implementará un clasificador de regresión logística usando operaciones sobre tensores y funciones predefinidas de PyTorch. Los objetivos del trabajo son los siguientes:\n",
        "\n",
        "- Aprenderá a implementar formulaciones matemáticas de forma eficiente usando tensores de PyTorch\n",
        "- Repasará conceptos básicos de machine learning que serán necesarios en futuros trabajos\n",
        "- Conocerá el flujo de trabajo usado al entrenar redes neuronales simples\n",
        "- Se familiarizará más con las funciones predefinidas de PyTorch y su simplicidad\n",
        "- Implementará todo el proceso, desde particionamiento de datos hasta las métricas de evaluación, usando diferentes operaciones y métodos de PyTorch\n",
        "\n",
        "## Calificación\n",
        "\n",
        "La nota del trabajo está basada en el puntaje total obtenido en este notebook y está dividido de la siguiente manera:\n",
        "\n",
        "#### Preparación del conjunto de datos (2 puntos)\n",
        "\n",
        "- Convertir la data a tensores (1 punto)\n",
        "- Particionamiento de datos (1 punto)\n",
        "\n",
        "#### Regresión logística desde cero (12 puntos)\n",
        "\n",
        "- Función de Activación (1 punto)\n",
        "- Inicialización de parámetros (1 punto)\n",
        "- Definición del Modelo (1 punto)\n",
        "- Función de Pérdida (1 punto)\n",
        "- Optimización (3 puntos)\n",
        "- Entrenamiento (3 puntos)\n",
        "- Predicción (1 punto)\n",
        "- Métrica de Evaluación (1 punto)\n",
        "\n",
        "#### Regresión logística usando métodos predefinidos (6 puntos)\n",
        "\n",
        "- Modelo (1.5 puntos)\n",
        "- Función de Pérdida (0.5 puntos)\n",
        "- Gradiente Descendente Estocástico (0.5 puntos)\n",
        "- Entrenamiento (2 puntos)\n",
        "- Predicción (0.5 puntos)\n",
        "- Métrica de Evaluación (0.5 puntos)\n",
        "- Prueba Final (0.5 puntos)\n",
        "\n",
        "El puntaje total es de $20$. \n",
        "\n",
        "*Los puntajes de la segunda parte son más bajos debido a que los métodos se implementan de manera similar a los de la primera parte del trabajo. La diferencia es que los parámetros no se usan explicitamente ya que están encapsulados en los módulos de PyTorch.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXxhUgUupWD"
      },
      "source": [
        "# Clasificador de Regresión Logística\n",
        "\n",
        "Este trabajo está basado en la implementación del clasificador de regresión logística el cual será aplicado sobre un conjunto de datos sintéticos. El flujo de trabajo se puede visualizar en la siguiente imagen:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Uyzxq2Dez-5BW9yLOyCdyVfnwvg3BUZy\" width=\"1000px\" />\n",
        "<p/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKq-llMyJUsP"
      },
      "source": [
        "## Importación de bibliotecas\n",
        "\n",
        "Empecemos importando las bibliotecas que serán usadas en este trabajo `numpy`, `matplotlib` y `torch`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5ven54VJgzg"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt # visualizaciones\n",
        "import torch # operaciones sobre tensores\n",
        "import random # para números aleatorios\n",
        "from sklearn.datasets import make_classification # generación de datos\n",
        "from sklearn.datasets import make_blobs # generación de datos\n",
        "from matplotlib.colors import ListedColormap # mapas de color"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk4-SHPOWEIu"
      },
      "source": [
        "## Seeds para reproducibilidad\n",
        "\n",
        "Un paso muy importante a la hora de implementar nuestros modelos es el uso de `seeds` que permitirá reproducir los resultados obtenidos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06tqtCEHWZ68"
      },
      "source": [
        "# Función para establecer el \"seed\"\n",
        "def set_seed(seed):\n",
        "  random.seed(seed)        # seed para generación de números aleatorios\n",
        "  torch.manual_seed(seed)  # seed de torch\n",
        "\n",
        "set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k8js2tJICHw"
      },
      "source": [
        "## Preparación del conjunto de datos\n",
        "\n",
        "En esta sección generaremos un conjunto de datos artificial, el cual convertirá a tensores y lo particionará en conjuntos de entrenamiento, validación y prueba."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JmZo02RManY"
      },
      "source": [
        "### Generación del conjunto de datos\n",
        "\n",
        "Antes de iniciar con la implementación, generaremos un conjunto de datos. Para simplificar las cosas, construiremos un conjunto de datos artificial. Mantendremos los datos de dimensiones reducidas para que podamos visualizarlos fácilmente.\n",
        "\n",
        "En el siguiente código, generamos un conjunto de datos que contiene 1000 muestras, cada uno de los cuales consta de 2 características. Por lo tanto, nuestro conjunto de datos sintéticos será una matriz $\\mathbf{X}\\in \\mathbb{R}^{1000 \\times 2}$.\n",
        "\n",
        "La clase roja tendrá la etiqueta 1 y la clase azul la etiqueta 0. Para generar los datos usaremos `scikit-learn`, no usaremos esta biblioteca para otros fines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIpwlpY2NWZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d52534b7-e379-42e1-bda2-c891632d94cb"
      },
      "source": [
        "# Crear mapas de color para visualización\n",
        "cmap_light = ListedColormap(['#AAAAFF', '#FFAAAA'])\n",
        "cmap_bold = ListedColormap(['#0000FF', '#FF0000'])\n",
        "\n",
        "# Generamos data aleatoria\n",
        "X_array, y_array = make_blobs(1000, 2, centers=2, random_state=10, cluster_std = 2.5)\n",
        "X_array = X_array - 10\n",
        "\n",
        "# Visualizamos la data generada\n",
        "plt.scatter(X_array[:, 0], X_array[:, 1], c=y_array, s=5, cmap=cmap_bold)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXB_TwQlNdOo"
      },
      "source": [
        "Podemos observar que la data es linealmente separable. Por lo tanto, se espera encontrar el límite de decisión óptimo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsUbMVBhOE4C"
      },
      "source": [
        "### Convertir la data a tensores (1 punto)\n",
        "\n",
        "La data generada es una lista de listas de python. Sin embargo, trabajará con tensores. Por lo tanto, será necesario convertir la data a tensores: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9EAQU_rO3e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de7f1147-6a6e-4350-bd88-0de3b1beeb00"
      },
      "source": [
        "# TODO: Convertir los arreglos X_array y y_array a tensores\n",
        "#       especificar el tipo de dato como torch.float para ambos\n",
        "#       datos (X) y etiquetas (y_true) \n",
        "X = torch.tensor(X_array,dtype=torch.float)\n",
        "y = torch.tensor(y_array,dtype=torch.float)\n",
        "\n",
        "# TODO: Actualmente 'y' es un vector de dimensión (n), deberá convertir\n",
        "#       este vector a su forma matricial. Puede usar .view o .reshape\n",
        "#       El tamaño deseado es (n,1)\n",
        "\n",
        "y = y.view(y.shape[0],1)\n",
        "\n",
        "# Verificación de implementación\n",
        "assert(torch.is_tensor(X) == True)\n",
        "assert(torch.is_tensor(y) == True)\n",
        "assert(X.dtype == torch.float)\n",
        "assert(y.dtype == torch.float)\n",
        "assert(y.shape == (y.shape[0],1))\n",
        "\n",
        "print('Tamaño del dataset: ', X.shape)\n",
        "print('Tamaño de las etiquetas: ', y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del dataset:  torch.Size([1000, 2])\n",
            "Tamaño de las etiquetas:  torch.Size([1000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdFe0exNN-73"
      },
      "source": [
        "### Particionamiento de datos (1 punto)\n",
        "\n",
        "Como no contamos con un conjunto de datos de validación y de prueba, el primer paso es particionar los datos.\n",
        "\n",
        "#### Particionamiento Hold-out\n",
        "\n",
        "Particionaremos el conjunto de datos en entrenamiento y prueba. Para ello, adicionaremos un parámetro `train_size` con valores entre $0$ y $1$ que indica el porcentaje de datos a considerar en la data de entrenamiento. Por ejemplo, si tenemos $1000$ datos y especificamos `train_size` igual a $0.8$. Entonces el método retornará dos conjuntos de datos: $(X_{train}, y_{train})$ y $(X_{test}, y_{test})$ con $800$ y $200$ muestras respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2fbypLNQiTW"
      },
      "source": [
        "def train_test_split(X, y, train_size=0.8):\n",
        "\n",
        "  '''\n",
        "    Este método permite dividir un conjunto de datos (X,y) en dos conjuntos \n",
        "    de datos (X_train, y_train) y (X_test, y_test) dada la proporción de datos \n",
        "    de entrenamiento deseado. \n",
        "\n",
        "    Es necesario aleatorizar los datos antes de realizar la división.\n",
        "    \n",
        "    Args:\n",
        "      - X: dataset de dimensión (n, m), donde n es el número de muestras y\n",
        "           m es el número de características.\n",
        "      - y: arreglo de dimensión (n), donde n es el número de muestras. Este\n",
        "           arreglo contiene las etiquetas (clases) de la data.\n",
        "      - train_size: representa la proporción del conjunto de datos a incluir en \n",
        "                    la data de entrenamiento.\n",
        "\n",
        "    Returns:\n",
        "      - X_train: tensor de dimensión (n_train, m)\n",
        "      - y_train: tensor de dimensión (n_train)\n",
        "      - X_test: tensor de dimensión (n_val, m)\n",
        "      - y_test: tensor de dimensióm (n_val)\n",
        "\n",
        "    Note: \n",
        "      - Los datos particionados deben sumar el total (n_train+n_val = n)\n",
        "      - Implementar el método usando solo operaciones de tensores de torch.\n",
        "      - No es válido usar métodos como split o random_split\n",
        "      - A continuación se deja una plantilla que puede usar, pero no es\n",
        "        obligatorio, puede realizar la implementación como mejor le parezca.\n",
        "  '''\n",
        "  n = X.shape[0]\n",
        "\n",
        "  # TODO: Crear una lista de índices aleatorios de los datos. Puede usar torch.randperm\n",
        "  indices = torch.randperm(n)\n",
        "\n",
        "  # TODO: Definir el número de muestras de la data de entrenamiento\n",
        "  n_train = int(n*train_size)\n",
        "\n",
        "  # TODO: Seleccionar los índices que se usarán en la data de entrenamiento y de prueba\n",
        "  train_indices = indices[:n_train]\n",
        "  test_indices = indices[n_train:]\n",
        "\n",
        "    # TODO: Particionar los datos usando los índices seleccionados anteriormente\n",
        "  X_train, y_train = X[train_indices,:], y[train_indices,:]\n",
        "  X_test, y_test = X[test_indices,:], y[test_indices,:]\n",
        "\n",
        "  # Retornamos los conjuntos de datos particionados\n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzH0K6SmKkHw"
      },
      "source": [
        "Verifiquemos si las dimensiones del método de particionamiento implementado son las correctas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFRiusdRKmTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a20bed-c2f5-411d-e2a5-d90ef091b119"
      },
      "source": [
        "# Test para probar la implementación del particionamiento de datos\n",
        "train_sizes = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
        "correct = True\n",
        "for train_size in train_sizes:\n",
        "  _X_train, _y_train, _X_test, _y_test = train_test_split(X, y, train_size)\n",
        "  difference = X.shape[0] - _X_train.shape[0] - _X_test.shape[0]\n",
        "  difference_y = y.shape[0] - _y_train.shape[0] - _y_test.shape[0]\n",
        "  if difference != 0 or difference_y != 0:\n",
        "    print(':( Las dimensiones del particionamiento no son correctas.\\n')\n",
        "    print(f'Total: ({X.shape},{y.shape})')\n",
        "    print(f'Train: ({_X_train.shape},{_y_train.shape})')\n",
        "    print(f'Test: ({_X_test.shape},{_y_test.shape})')\n",
        "    correct = False\n",
        "    break\n",
        "  elif _y_train.shape[1] != 1 or _y_test.shape[1] != 1:\n",
        "    print(':( Las dimensiones de las etiquetas no son correctas.\\n')\n",
        "    print(f'y train: {_y_train.shape}')\n",
        "    print(f'y test: {_y_test.shape}')\n",
        "if correct:\n",
        "  print(':) Las dimensiones del particionamiento son correctas.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":) Las dimensiones del particionamiento son correctas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib-dZg0jZTOc"
      },
      "source": [
        "Realizaremos el particionamiento de los datos considerando 60% para entrenamiento, 20% para validación y 20% para prueba:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYBJYetPY0qS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "916930f3-9ac2-4a20-f44d-9f7f83bb9506"
      },
      "source": [
        "# Particionamos el conjunto de datos en entrenamiento (train), validación (val)\n",
        "# y prueba (test)\n",
        "_X_train, _y_train, X_test, y_test = train_test_split(X, y, train_size=0.8)\n",
        "X_train, y_train, X_val, y_val = train_test_split(_X_train, _y_train, train_size=0.75)\n",
        "\n",
        "print('Tamaño original del dataset:', X.shape)\n",
        "print('---------------------------')\n",
        "print('Tamaño de la data de entrenamiento:', X_train.shape)\n",
        "print('Tamaño de la data de validación:', X_val.shape)\n",
        "print('Tamaño de la data de prueba:', X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño original del dataset: torch.Size([1000, 2])\n",
            "---------------------------\n",
            "Tamaño de la data de entrenamiento: torch.Size([600, 2])\n",
            "Tamaño de la data de validación: torch.Size([200, 2])\n",
            "Tamaño de la data de prueba: torch.Size([200, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGy0aKHLZj4U"
      },
      "source": [
        "### Visualización del conjunto de datos\n",
        "\n",
        "Procederemos con la visualización de los particionamientos previamente realizados. En este paso solo mostraremos la data de entrenamiento y de validación para saber el tipo de clasificación que necesitamos realizar. La data de prueba solo la usaremos al final de este trabajo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN_eR7RvZoVF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "fd685b48-2f3f-4679-d99c-0fe950873d57"
      },
      "source": [
        "def plot_dataset(X_train, y_train, X_test, y_test, is_validation=True):\n",
        "  \"\"\"\n",
        "    Este método permite visualizar nuestros datos de entrenamiento y prueba\n",
        "  \"\"\"\n",
        "  plt.subplots(figsize =(15, 5))\n",
        "  #plt.subplots(figsize =(11, 4))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, s=8, cmap=cmap_bold)  \n",
        "  plt.title('Data de Entrenamiento')\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.scatter(X_test[:,0], X_test[:,1], s=8)\n",
        "  if is_validation:\n",
        "    plt.title('Data de Validación')\n",
        "  else:\n",
        "    plt.title('Data de Prueba')\n",
        "  plt.show()\n",
        "\n",
        "plot_dataset(X_train.numpy(), y_train.numpy(), X_val.numpy(), y_val.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_WmmnQhbL7T"
      },
      "source": [
        "## Regresión logística desde cero (12 puntos)\n",
        "\n",
        "En esta sección implementará el método desde cero incluyendo el modelo, la función de pérdida y el optimizador de gradiente descendente. Si bien los frameworks de deep learning modernos pueden automatizar casi todo este trabajo, implementar las cosas desde cero es la única forma de asegurarnos de que realmente sabemos lo que estamos haciendo. \n",
        "\n",
        "La implementación estará basada solamente en operaciones sobre tensores, no es válido usar paquetes como `torch.nn` o `torch.optim`. Más adelante, realizará una implementación más concisa, aprovechando los métodos ya definidos de PyTorch. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exwr4QGWcgrQ"
      },
      "source": [
        "### Función de Activación (1 punto)\n",
        "\n",
        "La función de activación usada en regresión logística es la función sigmoidea:\n",
        "\n",
        "\\begin{align*}\n",
        "\\sigma(z) = \\frac{1}{1+e^{-z}}\n",
        "\\end{align*}\n",
        "\n",
        "A continuación, deberá implementar esta función:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU2bDXqsc80Q"
      },
      "source": [
        "def sigmoid(z):\n",
        "  '''\n",
        "    Este método implementa la función sigmoidea\n",
        "    \n",
        "    Args:\n",
        "      - z: un escalar o tensor de torch de tamaño variable\n",
        "\n",
        "    Returns:\n",
        "      - un escalar o tensor del mismo tamaño de z\n",
        "\n",
        "  '''\n",
        "  #TODO: Implemente la función sigmoidea\n",
        "  s = 1/(1+(1/torch.exp(z)))\n",
        "\n",
        "  assert(torch.is_tensor(s) == True)\n",
        "  assert(s.shape == z.shape)\n",
        "  return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6bHZcQ_dxi6"
      },
      "source": [
        "Recordemos que la idea principal de la función sigmoidea es que ajusta los valores entre 0 y 1. La función tiene una \"forma de s\" muy característica, que rápidamente va a 1 cuando z tiene al +∞ o va a 0 cuando z tiene al -∞. Esto hace que la función sea muy adecuada para la clasificación binaria. A continuación visualizaremos la función:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKLVADGXd8rf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "29712394-8f12-46b9-a088-6ec0e8a5894b"
      },
      "source": [
        "# Valores entre -15 y 15\n",
        "z = torch.arange(-15, 15)\n",
        "# Aplicamos la función sigmoide a los valores generados\n",
        "s = sigmoid(z)\n",
        "\n",
        "plt.plot(z.numpy(), s.numpy(), marker='o')\n",
        "plt.title('Sigmoid function')\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('sigmoid(z)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxc5XX/8c/RZsmrbGxsS14BYzAYbHBJ2BJICGYJYOgvBGdp4JeG0ELaFOoUpxQIbQrFoc0CWQghJGmBEH6O7ICDSViSQAkgRTLGgMAYy7Zk403yKms9vz/myhlJM9KMpNGdGX3fr5demnvnzNxzLc89c5/nPs81d0dERIa2nLATEBGR8KkYiIiIioGIiKgYiIgIKgYiIoKKgYiIoGIgGcDMPm1mT6fbds3seTP76zjPmZn92MzqzeyV1GUZc9u/NrPPDeY2JfOZxhlIOjCzs4C7gROANuBN4Mvu/mqoifXAzJ4H/tvdH4jx3NnAI8Bsdz+QwhxuB45x98+kahsyNOSFnYCImY0GngD+BngMKADOBprCzKufpgMbU1kIRAaSmokkHRwL4O6PuHubuze6+9Pu/hqAmV1tZi90BJvZ+WZWbWZ7zOy7Zva7juaaIPZFM/svM2swsw1mdkawfrOZbY9uQjGzMWb2UzPbYWY1ZnaLmeXE2e7HzOytYLv3AhZrZ8zs88ADwOlmtt/Mvtb1vYI4N7NjgscPmdl9Zvakme0zs5fN7Oio2BPM7DdmttvM3jezr5rZBcBXgU8G21kTxB5uvjKznGCfaoJ9/6mZjQmemxHk8Dkz22RmO83sn/v8V5SMpmIg6eBtoM3MfmJmF5rZ2HiBZjYeeBxYChwBVANndAn7APBa8PzDwKPAXwDHAJ8B7jWzkUHsd4AxwFHAh4G/Aq6Js93lwC3AeOBd4MxYObr7j4DrgJfcfaS739bbP0DgKuBrwFhgPfD1YNujgN8CTwElwX484+5PAf8O/DzYzskx3vPq4OfcYB9HAvd2iTkLmA18FLjVzI5PMF/JIioGEjp330vkgOTAD4EdZrbSzCbGCL8IWOfuy929Ffg2sK1LzHvu/mN3bwN+DkwF7nD3Jnd/GmgGjjGzXCIH4KXuvs/dNwL3AJ/tYbuPu3sL8M0Y2+2vX7r7K8F+/Q8wL1j/cWCbu9/j7oeCXF9O8D0/Dfynu29w9/1EiuhVZhbdRPy14GxsDbAGiFVUJMupGEhacPc33f1qd58CnEjkG/A3Y4SWAJujXufAli4x70c9bgziuq4bSeQbfj5QE/VcDVCa4HY3x4jrj+jicjDIESLF7N0+vmcJ3fcvD4gutPG2K0OIioGkHXd/C3iISFHoaiswpWPBzCx6OUk7gRYinb0dpgG1cbY7tct2p8aIi+cAMDzq9ZOSeO1mIk08sfR2OWAd3fevlc4FU0TFQMJnZseZ2U1mNiVYngosBv4YI/xJYK6ZLQqaOq4HkjmwHhY0Iz0GfN3MRpnZdOBG4L/jbPcEM7si2O7fJbndNcHr55lZIXB7Eq99AphsZl82s2FBrh8InnsfmNHR6R3DI8A/mNnMoJ+ko4+hNYntyxCgYiDpYB+RTt+XzewAkSLwOnBT10B33wl8gsiYhF3AHKCcvl+G+iUi39o3AC8Q6XB+sIft3hVsdxbwYqIbcfe3gTuIdAS/E2wr0dfuAz4GXEKkSecdIh3CAL8Ifu8ysz/FePmDwM+A3wPvAYeI7LNIJxp0Jhkt+Ea8Bfi0uz8Xdj4imUpnBpJxzGyhmRWb2TAi19kbsZuURCRBKgaSiU4ncnXNTiJNJ4vcvTHclEQym5qJREREZwYiIpKBE9WNHz/eZ8yYEXYaIiIZpaKiYqe7T4j3fMYVgxkzZlBeXh52GiIiGcXManp6Xs1EIiKiYiAiIioGIiKCioGIiKBiICIipPBqIjN7kMhNOba7e7epiIMpgL9F5KYhB4Gr3T3WRFsikqXKKmtZtrqauoZGSoqLWLJwNovmx7qdROKxQ/k9+yOVl5Y+ROT2ej+N8/yFRGZ+nEVkxsrvBb9FJMMlcvAqq6xl6fK1NLa0AVDb0MjS5WsB+hw7lN+zv1I6HYWZzQCeiHNm8APgeXd/JFiuBs5x9609veeCBQtc4wxEBl8y33ijD14AhXk5LFk4mw8dO4Gm1naaWtv54s/K2bm/udvrxw7PZ+lFx9Pe7rQ7tLnzjdXV7Gls6RY7ujCPvznnGDy4x8/3n3+XvYe636phVGEeXzj7KKIPdw+8sIF9cWKvOXPm4eUfv/heQnE9xg7L45ozZ0TFbWRfU+9xPcWWFhfx4s0f6bY+HjOrcPcFcZ8PsRg8Adzl7i8Ey88A/+Tu3Y70ZnYtcC3AtGnTTq2p6XHshIgMsFgH+Pxc46ITJ1Mytojd+5vZfbCZ3QeaWbO5gdZ2zXnWldmfH/d02I2O6ynWgPfuujiJ7fdcDDJiBLK73w/cD5Ezg5DTEckq8b7xN7e289a2vVRtbuDOVW91KgQALW3OijV15Oca40YUMHZ4AUeMLOixEHxn8XyG5eVQkJfDP/5iTcwzg4mjh/H4dWeQm2Pk5hhmcOm9L7Jtz6FusZPHFPLsTeccPoB+5BvPUxcjrqS4kD98JfItuuNYe9bdz1LX0D226zfuM+96ltqG7pPixvpmnmjsQLxnSXFRt3X9EebVRLV0vofsFGLfe1ZEUqTjG39tQyNOpD36pl+s4cN3P8uJt6/m0ntf5NYV67oVgg4GvP1vF/LyV8/jqS9/iP/56w9SGucgVVpcxCUnl3D+CZM4Z/aR3HLxHIryczvFFOXnsvTC45k6bjglxUVMHF3IkaMKufmC42LG/tMFx1FUkEthfuTnK3HivrLwuMPFJSf4+crC2LFLFs7utG7JwtkJxSUTm4r37K8wzwxWAjeY2aNEOo739NZfICID6+7V3b/xt7U7W/c0cfWZM5g3tZiTpxZz5ff/l9oY36JLiouwLu0aSxbO7takFOvg1dHfkEg/RKKxQ/k9+ytlfQZm9ghwDjCeyE27bwPyAdz9+8GlpfcCFxC5tPSaWP0FXakDWaT/3J3n397BNT9+NebzXdujY/UZFOXncucVc/t92aQMjtD6DNx9cS/PO3B9qrYvIrGtq9vDnave4oX1O8nNMdpitPF3bY9O9tvpovmlOvhnmIzoQBaR/tu6p5FvrH6b5ZVbGFOUz22XzGHUsDz+pUufQLz2aB3gs5uKgUgWim6mmTSmkBNLRvOH9Ttpb4drzz6Kvz33GMYU5QOQl5ujJh1RMRDJNl3b97fuOcTWPYc4ZWox31o8n6njhneK1zd+AU1UJ5J1lq2ujnkp6Pv7mroVApEOKgYiWaYuxgClntaLgIqBSNaZMGpYzPUDPWJVsouKgUgWaWxuI8e6r0/FiFXJLioGIlnkjifWsW1vE1/88FGUFhdhRKaBiDc4TKSDriYSyRK/WlPHI69s5roPH83NFx7H0guPDzslySA6MxDJAjW7DrB0+VpOmVbMTecfG3Y6koFUDEQyXFNrGzc8XEmOwbcXzyc/Vx9rSZ6aiUQy3H/8upq1tXv4wWdPZcpYjSOQvtFXCJEM9ps33ufBF9/j6jNmsPCESWGnIxlMxUAkQ9U1NLLk8TWcUDKapRcdF3Y6kuFUDEQyUGtbO3/3SCUtre3c+6lTGJaX2/uLRHqgPgORDNIxG2nHPXE/+8FpzBw/IuSsJBvozEAkQ0Tfr7jD4xW1lFXq1uHSfyoGIhki1mykjS1tLFtdHVJGkk1UDEQyhGYjlVRSMRDJEPFmHdVspDIQVAxEMsT15x7dbZ1mI5WBomIgkiHMInNTTxg1TLORyoDTpaUiGaKsspajJozgmRs/fLgwiAwUnRmIZIC6hkZefm83i+aVqhBISqgYiGSAX62pA+DSk0tCzkSylYqBSAYoq6pj3tRiZmi0saSIioFImnv7/X28uXUvi+bprEBSR8VAJM2VVdaSm2NcfJKKgaSOioFIGnN3VlTVceYx45kwaljY6UgWUzEQSWMVNfXUNjSqiUhSTsVAJI2VVdVSmJ/D+bqLmaRYSouBmV1gZtVmtt7Mbo7x/DQze87MKs3sNTO7KJX5iGSSlrZ2nnxtKx+bM4mRwzQ+VFIrZcXAzHKB+4ALgTnAYjOb0yXsFuAxd58PXAV8N1X5iGSa37+9g/qDLWoikkGRyjOD04D17r7B3ZuBR4HLusQ4MDp4PAaoS2E+IhllRVUdxcPzOXvWhLBTkSEglcWgFNgctbwlWBftduAzZrYFWAV8KdYbmdm1ZlZuZuU7duxIRa4iaeVAUyu/eeN9Lp47mYI8de1J6oX9v2wx8JC7TwEuAn5mZt1ycvf73X2Buy+YMEHfkiT7Pf3GNhpb2jQjqQyaVBaDWmBq1PKUYF20zwOPAbj7S0AhMD6FOYlkhLLKOkqLizh12tiwU5EhIpXF4FVglpnNNLMCIh3EK7vEbAI+CmBmxxMpBmoHkiFt5/4mXli/k8vmlZCToxlKZXCkrBi4eytwA7AaeJPIVUPrzOwOM7s0CLsJ+IKZrQEeAa52d09VTiKZ4MnXttLW7lw2T01EMnhSevGyu68i0jEcve7WqMdvAGemMgeRTFNWVctxk0Yxe9KosFORISTsDmQRiVKz6wCVmxrUcSyDTsVAJI2srKrDTDexkcGnYiCSJtydsqpaTpsxjpLiorDTkSFGxUAkTayr28u7Ow6o41hCodmvREJWVlnLstXV1DY0Bmt0QZ0MPhUDkRCVVdaydPlaGlvaDq/71yfeZHhBnjqRZVCpmUgkRMtWV3cqBACNLW0sW10dUkYyVKkYiISo7nDTUGLrRVJFxUAkRPGuGtLVRDLYVAxEQrRk4WwK8zt/DIvyc1mycHZIGclQpWIgEqJF80u55oyZh5dLi4u484q56jyWQaeriURCNiw/BzNYc9v5jC7MDzsdGaJ0ZiASsoqaemZPHKVCIKFSMRAJUVu7U7mpgQUzdBMbCZeKgUiIqrftY39TKwumjws7FRniVAxEQlRRsxuAU6frzEDCpWIgEqLymnomjh7GlLEaVyDhUjEQCVH5xnpOnT4WM93rWMKlYiASkm17DlHb0Mip6i+QNKBiIBKSipp6ABaov0DSgIqBSEjKa3ZTlJ/LnJLRYaciomIgEpaKmnpOnjqG/Fx9DCV8+l8oEoKDza2sq9ur8QWSNlQMREJQtbmBtnbX+AJJGyoGIiH4U9B5fMo0FQNJDyoGIiEor6nn2IkjGTNck9NJelAxEBlk7e3On2rqNb5A0oqKgcgge2f7fvYeatX4AkkrKgYig6xck9NJGlIxEBlkFRvrGT+ygOlHDA87FZHDEioGZnakmV1uZteb2f81s9PMrNfXmtkFZlZtZuvN7OY4MVea2Rtmts7MHk52B0QyTcUmTU4n6afHeyCb2bnAzcA4oBLYDhQCi4Cjzexx4B533xvjtbnAfcDHgC3Aq2a20t3fiIqZBSwFznT3ejM7cmB2SyQ97djXRM2ug3zmA9PDTkWkkx6LAXAR8AV339T1CTPLAz5O5GD//2K89jRgvbtvCOIfBS4D3oiK+QJwn7vXA7j79qT3QCSDHL6ZjW5zKWmmx2Lg7kt6eK4VKOvh5aXA5qjlLcAHusQcC2BmLwK5wO3u/lTXNzKza4FrAaZNm9ZTyiJprXxjPQV5OZxYMibsVEQ6SbTPoM3M7rKoRk4z+9MAbD8PmAWcAywGfmhmxV2D3P1+d1/g7gsmTJgwAJsVCUd5TT0nTxlDQZ6u3ZD0kuj/yHVB7NNm1jFSprfer1pgatTylGBdtC3ASndvcff3gLeJFAeRrHOopY11dXs02EzSUqLFoNXdvwI8APzBzE4FvJfXvArMMrOZZlYAXAWs7BJTRuSsADMbT6TZaEOCOYlklNe27KGlzTXYTNJSbx3IHQzA3X9uZuuAh4EeG+/dvdXMbgBWE+kPeNDd15nZHUC5u68MnjvfzN4A2oAl7r6rj/siktY02EzSWaLF4K87Hrj762Z2NpErg3rk7quAVV3W3Rr12IEbgx+RrFaxsZ6jJ4xg7IiCsFMR6abHZiIzOwvA3Sui17v7Hnf/qZmNNrMTU5mgSDZob3cqNtXrZjaStno7M/hLM7sbeAqoAHYQGXR2DHAuMB24KaUZimSBDTv303CwRU1EkrZ6G2fwD8HVQ38JfAKYDDQCbwI/cPcXUp+iSOYr3xi5mY0Gm0m66rXPwN13Az8MfkSkDypq6hk3ooCjxo8IOxWRmHqbm6jHjl13/8+BTUckO1XU1HPKNE1OJ+mrtzODUcHv2cBf8OdxApcAr6QqKZFssmt/Ext2HuDKv5jae7BISHrrM/gagJn9HjjF3fcFy7cDT6Y8O5EsUFET9Beo81jSWKIjkCcCzVHLzcE6EelFRU09Bbk5zC3V5HSSvhIddPZT4BUz+2WwvAh4KCUZiWSZ8pp6TiwdTWF+btipiMSV0JmBu38duAaoD36ucfc7U5mYSDZoam1j7ZY9LJihwWaS3nq7mmi0u+8NxhpsDH46nhsXXHYqInG8XruH5rZ29RdI2uutmehhInczqyAyS2n0dXEOHJWivEQyXlllLbeueB2A21auo7G5jUXzS0POSiS23q4m+njwe+bgpCOSHcoqa1m6fC2NLW0AbNtziKXL1wKoIEhaSvh2S2Z2qZl9I/j5eCqTEsl0y1ZXHy4EHRpb2li2ujqkjER6luhtL+8C/p7IzezfAP7ezP49lYmJZLK6hsak1ouELdFLSy8C5rl7O4CZ/QSoBL6aqsREMllJcRG1MQ78JcVFIWQj0rtk7sodfaN6jZ4R6cGShbPJzek8D1FRfi5LFs4OKSORniVaDO4EKs3soeCsoAL4eurSEslsi+aXcsSIAobl5WBAaXERd14xV53HkrYSaiZy90fM7Hkik9UB/JO7b0tZViIZruFgM9v3NbFk4WyuP/eYsNMR6VUyzUQTgt95wBlmdkUK8hHJCpqcTjJNQmcGZvYgcBKwDmgPVjuwPEV5iWS08pp68nKMk6cU9x4skgYSvZrog+4+J6WZiGSRipp6TigdQ1GBJqeTzJBoM9FLZqZiIJKA5tZ21mxuYIGaiCSDJDOF9Utmtg1oIjJHkbv7SSnLTCRDravbQ1OrJqeTzJJoMfgR8FlgLX/uMxCRGDo6j3VmIJkk0WKww91X9h4mIuUb65k6rogjRxeGnYpIwhItBpVm9jDwKyLNRAC4u64mEoni7lRsquesY8aHnYpIUhItBkVEisD5Uet0aalIF5t3N7JjX5P6CyTjJDoC+ZpUJyKSDcprIjf/WzBDxUAyS6KDzr4dY/UeoNzdVwxsSiKZq7ymnlHD8ph15KiwUxFJSqLjDAqBecA7wc9JwBTg82b2zRTlJpJxKjbWM3/62G4zloqku0SLwUnAue7+HXf/DnAecBxwOZ37EToxswvMrNrM1pvZzT3E/aWZuZktSCZ5kXSyp7GFt7fv0yWlkpESLQZjgZFRyyOAce7eRtTVRdHMLBe4D7gQmAMsjjWK2cxGEbmL2stJ5C2Sdio31eOu8QWSmRItBncDVWb2YzN7iMhdzpaZ2Qjgt3Fecxqw3t03uHsz8ChwWYy4fwX+AziUVOYiaaaipp7cHGPeNE1OJ5knoWLg7j8CzgDKgF8CZ7n7A+5+wN2XxHlZKbA5anlLsO4wMzsFmOruT/a0fTO71szKzax8x44diaQsMujKN9YzZ/JohhckesW2SProsRiY2XHB71OAyUQO7puBScG6PjOzHOA/gZt6i3X3+919gbsvmDBhQm/hIoOupa2dqs0NGl8gGau3rzA3AtcC90St86jHH+nhtbXA1KjlKcG6DqOAE4HnzQxgErDSzC519/Je8hJJK29u3UtjS5uKgWSsHs8M3P3a4OH3gMvc/VzgOSJjDP6xl/d+FZhlZjPNrAC4Cjg8v5G773H38e4+w91nAH8EVAgkIx2enE6DzSRDJdqBfIu77zWzs4icDTxApEDE5e6twA3AauBN4DF3X2dmd5jZpf1JWiTdlNfUU1pcxOQxRWGnItInifZ0tQW/LwZ+6O5Pmtm/9fYid18FrOqy7tY4seckmItIWnF3KjbWc9rMcWGnItJniZ4Z1JrZD4BPAqvMbFgSrxXJarUNjWzbe0hNRJLREj2gX0mkuWehuzcA44B4l5SKDCkd/QWnTFMxkMyV6KylB4martrdtwJbU5WUSCapqKlnREEux03S5HSSudTUI9JP5RvrmT9tLHm5+jhJ5tL/XpF+2N/Uylvb9mp8gWQ8FQORfqjcVE+7a3yBZD4VA5F+KN9YT47BvKmanE4ym4qBSD9U1NQze9JoRhXmh52KSL+oGIj0UVu7U7mpXvcvkKygYiDSR29t28uB5jb1F0hWUDEQ6aOOwWa6kkiygYqBSB+Vb6xn0uhCSos1OZ1kPhUDkT6qqKnn1OljCe7HIZLRVAxE+mDrnkZqGxrVRCRZQ8VApA90MxvJNioGIn1QvrGeovxcjp88OuxURAaEioFIH1TU1DNvajH5mpxOsoT+J4skoayyltPvfIa1tXt4vXYPZZW1YackMiASve2lyJBXVlnL0uVraWyJ3AV2X1MrS5evBWDR/NIwUxPpN50ZiCRo2erqw4WgQ2NLG8tWV4eUkcjAUTEQSVBdQ2NS60UyiYqBSIJK4ow0jrdeJJOoGIgkaMnC2eTldB5tXJSfy5KFs0PKSGTgqBiIJOiSk0sYXpBLYV4OBpQWF3HnFXPVeSxZQVcTiSTo5fd2sfdQK99ZPJ9LTi4JOx2RAaUzA5EEraisY0RBLucdPzHsVEQGnIqBSAIOtbSx6vWtLDxxEkUFuWGnIzLgVAxEEvB89Q72HWpl0Tz1D0h2UjEQScCKqlrGjyzgjKOPCDsVkZRQMRDpxd5DLTzz1nY+flIJeZqYTrJUSv9nm9kFZlZtZuvN7OYYz99oZm+Y2Wtm9oyZTU9lPiJ98dTabTS3tusSUslqKSsGZpYL3AdcCMwBFpvZnC5hlcACdz8JeBy4O1X5iPTVijW1zDhiOCdPGRN2KiIpk8ozg9OA9e6+wd2bgUeBy6ID3P05dz8YLP4RmJLCfESS9v7eQ/zvu7u4dF6p7nUsWS2VxaAU2By1vCVYF8/ngV/HesLMrjWzcjMr37FjxwCmKNKzX62pwx0WzdMgM8luadEbZmafARYAy2I97+73u/sCd18wYcKEwU1OhrSyqlpOmjKGoyaMDDsVkZRKZTGoBaZGLU8J1nViZucB/wxc6u5NKcxHJCnrt+/n9dq9XKaxBTIEpLIYvArMMrOZZlYAXAWsjA4ws/nAD4gUgu0pzEUkaSuraskxuOSkyWGnIpJyKSsG7t4K3ACsBt4EHnP3dWZ2h5ldGoQtA0YCvzCzKjNbGeftRAaVu1NWVccZR4/nyNGFYacjknIpnbXU3VcBq7qsuzXq8Xmp3L5IX1VubmDT7oN86SPHhJ2KyKBIiw5kkXSzorKWYXk5XHDipLBTERkUKgYiXbS0tfPEa1s57/iJjCrMDzsdkUGhYiDSxYvrd7LrQDOXamyBDCEqBiJdrKiqY3RhHufM1pgWGTpUDESiHGxuZfW6bVx80mSG5ekmNjJ0qBiIRPnNG+9zsLlNA81kyFExEImysqqOyWMKOW3GuLBTERlUKgYiQFllLaff+QzPvLWdfYdaWbmmLuyURAZVSgediWSCsspali5fS2NLGwD7m1pZunwtgG5oI0OGzgxkyFu2uvpwIejQ2NLGstXVIWUkMvhUDGTIq2toTGq9SDZSMZAh78jRw2KuLykuGuRMRMKjYiBDWktbO4V53T8GRfm5LFk4O4SMRMKhYiBD2j1Pv03N7kb+6vTplBYXYUBpcRF3XjFXnccypOhqIhmynq/ezvd/9y6LT5vGHZedyB2XhZ2RSHh0ZiBD0vt7D3HTY2uYPXEUt10yJ+x0REKnYiBDTlu78+VHqzjY3Ma9n5pPYb7mIBJRM5EMOfc+u56XNuzi7v9zErMmjgo7HZG0oDMDGVL+uGEX33rmbRbNK+ETp04JOx2RtKFiIEPGrv1N/P2jlUw/YgT/dvlczCzslETShoqBDAnt7c4//mIN9QdauPdT8xk5TC2kItFUDGRI+NEL7/Fc9Q5u+fjxnFAyJux0RNKOvh5J1iqrrGXZ6mrqGhpxYG7paD77welhpyWSlnRmIFmpY1rq2qAQALyzfT8rqnSfApFYVAwkK929+q1u01IfamnXtNQicagYSNZ56d1d1DUcivmcpqUWiU19BpI11m/fz12/fovfvvk+OQbt3j1G01KLxKZiIBknumO4pLiI6845ire37efhVzZRlJ/LVy6YzYSRw7h1xbpOTUWallokPhUDyShd71dc29DIv5Stw4DPnj6dv/voLMaPjNysJj83p1PRWLJwtqalFolDxUAyyrIYHcMAE0YN447LTuy0btH8Uh38RRKkYiAp1bVJJ96383hxu/Y3sWZLA1Wb91C1uYHaOB3DO/Y1pXpXRLJaSouBmV0AfAvIBR5w97u6PD8M+ClwKrAL+KS7bxzoPBI9ICUTq/dMLK5rk87S5WsBOsWXVdZy8/LXONTSfjjupsequOOJdew+0AJAjsGxE0cxvCCXg83dzwzUMSzSP+Ye45KLgXhjs1zgbeBjwBbgVWCxu78RFfO3wEnufp2ZXQVc7u6f7Ol9FyxY4OXl5Qnn0fWABJGOxFi3NUw0Vu/ZOa4wP4ebLzyOc449kua2dppa2mlua+OLP6tg5/5muirKz+X0o49g94Fmdh9oZvPug8T6X1iYn8ONHzuWk6cUM3fKGIYX5CW1TyLyZ2ZW4e4L4j6fwmJwOnC7uy8MlpcCuPudUTGrg5iXzCwP2AZM8B6SSrYYnHnXs9TGuLY8L8eYOX5Ep3Xv7TxAa4zrEfNyjBlRsRsTjEsmtqe46UcM73Sw3LTrYMzY3Bxj2rjhdPzzba5vpC1WnBmTxhTi7jjgDtv3HYp5KaYBRQW5tLU77e60tA3M/5cTS0czbsQwxg3PpyzOqGAD3rvr4m7rkznbEZGI3opBKpuJSoHNUctbgA/Ei3H3VjPbAxwB7IwOMrNrgWsBpk2bllQS8QYZtbY7s3bKSJgAAAX3SURBVCaO7LTune3748bOjroJyvoE45KJ7SnuuMmjgcjBEWDDjgMxY9vanbmlkUnYzGDjroOx49z54FFHYBZ5TzN4rHxLzFgHPv2BaeSYkZNjfO/5d2PGAfzXJ09mWF4uBbk5DMvP4R9+XhXzzKC0uIgnvnT24eVXN9bHLNjxmn7UMSwy8DKiA9nd7wfuh8iZQTKvLSkuinmgKS0u4rufPrXTunhnEaXFRdz36VMOL1clGJdMbI9xn+r8npWb4sd+e/H8w8vlcQ6ypcVF3HPlyZ3Wvbh+V9zYf774z/cIXllVFzfu8vmdbxZzy8VzYjbpdL3Wf8nC2QnFiUjqpHI6ilpgatTylGBdzJigmWgMkY7kAbNk4WyKutzjNt6BJtFYvWdi77lofil3XjGX0uIijEjBiNW2n2iciKROKvsM8oh0IH+UyEH/VeBT7r4uKuZ6YG5UB/IV7n5lT++bbJ8BZN9VOpn0niKSHkLrQA42fhHwTSKXlj7o7l83szuAcndfaWaFwM+A+cBu4Cp339DTe/alGIiIDHVhdiDj7quAVV3W3Rr1+BDwiVTmICIivdMU1iIiomIgIiIqBiIigoqBiIiQ4quJUsHMdgA1fXz5eLqMbs4C2bZP2bY/kH37lG37A9m3T7H2Z7q7T4j3gowrBv1hZuU9XVqVibJtn7JtfyD79inb9geyb5/6sj9qJhIRERUDEREZesXg/rATSIFs26ds2x/Ivn3Ktv2B7NunpPdnSPUZiIhIbEPtzEBERGJQMRARkaFRDMzsE2a2zszazWxB1PoZZtZoZlXBz/fDzDNR8fYneG6pma03s2ozWxhWjv1hZrebWW3U3+WisHPqCzO7IPg7rDezm8POZyCY2UYzWxv8XTJu+mAze9DMtpvZ61HrxpnZb8zsneD32DBzTFacfUr6MzQkigHwOnAF8PsYz73r7vOCn+sGOa++irk/ZjYHuAo4AbgA+K6Z5XZ/eUb4r6i/y6rew9NL8O9+H3AhMAdYHPx9ssG5wd8lE6/Lf4jIZyPazcAz7j4LeCZYziQP0X2fIMnP0JAoBu7+prtXh53HQOlhfy4DHnX3Jnd/D1gPnDa42UngNGC9u29w92bgUSJ/HwmRu/+eyL1Tol0G/CR4/BNg0aAm1U9x9ilpQ6IY9GKmmVWa2e/M7Ozew9NaKbA5anlLsC4T3WBmrwWnwBl12h7Ipr9FNAeeNrMKM7s27GQGyER33xo83gZMDDOZAZTUZyhrioGZ/dbMXo/x09O3sa3ANHefD9wIPGxmowcn4571cX8yRi/79z3gaGAekb/RPaEmK9HOcvdTiDR/XW9mHwo7oYHkkWvts+F6+6Q/Qym909lgcvfz+vCaJqApeFxhZu8CxwKhd4z1ZX+I3Gt6atTylGBd2kl0/8zsh8ATKU4nFTLmb5EMd68Nfm83s18SaQ6L1ReXSd43s8nuvtXMJgPbw06ov9z9/Y7HiX6GsubMoC/MbEJHB6uZHQXMAnq8B3OaWwlcZWbDzGwmkf15JeSckhZ8IDtcTqTDPNO8Cswys5lmVkCkY39lyDn1i5mNMLNRHY+B88nMv01XK4HPBY8/B6wIMZcB0ZfPUNacGfTEzC4HvgNMAJ40syp3Xwh8CLjDzFqAduA6d+93R0yqxdsfd19nZo8BbwCtwPXu3hZmrn10t5nNI3K6vhH4YrjpJM/dW83sBmA1kAs86O7rQk6rvyYCvzQziBw7Hnb3p8JNKTlm9ghwDjDezLYAtwF3AY+Z2eeJTI9/ZXgZJi/OPp2T7GdI01GIiMjQbiYSEZEIFQMREVExEBERFQMREUHFQEREUDEQERFUDEREBBUDkX4zs+ui5o1/z8yeCzsnkWRp0JnIADGzfOBZ4G53/1XY+YgkQ2cGIgPnW8CzKgSSiYbE3EQiqWZmVwPTgRtCTkWkT9RMJNJPZnYqkTtkne3u9WHnI9IXaiYS6b8bgHHAc0En8gNhJySSLJ0ZiIiIzgxERETFQEREUDEQERFUDEREBBUDERFBxUBERFAxEBER4P8DCIkb3yYANCoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ58jCDyd8KF"
      },
      "source": [
        "### Inicialización de parámetros (1 punto)\n",
        "\n",
        "Un paso importante es la inicialización de parámetros que deberá implementar en la siguiente función:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4rXfivxfhdK"
      },
      "source": [
        "def initialize_params(m):\n",
        "  \"\"\"\n",
        "    Este método crea dos tensores representando los pesos y el bias. \n",
        "    Ambos tensores serán inicializados con ceros. Considerar que los pesos (w)\n",
        "    tienen una dimensión de (m, 1) y el bias tiene una dimensión de (1,)\n",
        "\n",
        "    Este método crea dos tensores representando los pesos y el bias. \n",
        "    Inicializamos los pesos muestreando números aleatorios de una distribución \n",
        "    normal con media 0 y una desviación estándar de 0.01, y el bias con un \n",
        "    valor igual a 0. \n",
        "    \n",
        "    Considerar que los pesos (w) tienen una dimensión de (m, 1) y el bias \n",
        "    tiene una dimensión de (1,)\n",
        "\n",
        "    Args:\n",
        "      - m: tamaño del tensor w que crearemos (número de características)\n",
        "    \n",
        "    Returns:\n",
        "      - w: tensor de dimensión (m, 1)\n",
        "      - b: tensor de dimensión (1,)\n",
        "  \"\"\"\n",
        "  # TODO: Inicializar los pesos 'w' muestreando números aleatorios de una\n",
        "  #       distribución normal com media 0 y desviación estándar 0.01.\n",
        "  #       Puede usar métodos definidos de pytorch\n",
        "  w = torch.normal(0, 0.01, size=(m, 1))\n",
        "\n",
        "  # TODO: Inicializar el bias 'b' con zeros\n",
        "  b = torch.zeros(1)\n",
        "  \n",
        "  # Verificamos la implementación\n",
        "  assert(w.shape == (m, 1))\n",
        "  assert(b.shape == (1,))\n",
        "  assert(torch.is_tensor(w))\n",
        "  assert(torch.is_tensor(b))\n",
        "\n",
        "  return w, b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX1ZNJyIhngj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd202fef-7504-4c09-8b32-23e42f9fdc1e"
      },
      "source": [
        "# Probemos la implementación\n",
        "m = 2\n",
        "w, b = initialize_params(m)\n",
        "print (\"w = \" + str(w))\n",
        "print (\"b = \" + str(b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w = tensor([[0.0068],\n",
            "        [0.0083]])\n",
            "b = tensor([0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebRw5tKMyFmM"
      },
      "source": [
        "### Límite de decisión\n",
        "\n",
        "Podemos visualizar el limite de decisión acorde a los parámetros aleatorios:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrO0TjW-pbim",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ab392f61-b469-43d8-ec38-90c881c6bba7"
      },
      "source": [
        "def plot_decision_boundary_no_label(X, w, b):\n",
        "  plt.scatter(X[:, 0], X[:, 1], s=5, cmap=cmap_bold)  \n",
        "  x_values = torch.tensor([X[:,0].min(), X[:,0].max() ])\n",
        "  if w[1] > 0:\n",
        "    y_values = -(b + x_values * w[0])/ w[1]\n",
        "  else: \n",
        "    y_values = -(b + x_values * w[0])\n",
        "  plt.plot(x_values, y_values, c='purple')\n",
        "  plt.show()  \n",
        "\n",
        "plot_decision_boundary_no_label(X_train, w, b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz2V137oycy1"
      },
      "source": [
        "Como podemos observar el limite de decisión inicial no separa ambas clases de forma correcta, esto se debe a que los parámetros poseen valores aleatorios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_73SVoWiNCT"
      },
      "source": [
        "### Definición del Modelo (1 punto)\n",
        "\n",
        "A continuación, definiremos el modelo. Al igual que en regresión lineal, la transformación afín ($z$) está dada por el producto de la matriz de las características de entrada $\\mathbf{X}$ y el vector de pesos $\\mathbf{w}$, sumados con el bias $b$. Es decir,\n",
        "\n",
        "$$z = \\mathbf{X} \\mathbf{w} + b,$$\n",
        "\n",
        "como lo mencionado en clase, una interpretación de $z$ es que son distancias al límite de decisión. En regresión logística estamos interesados en predecir probabilidades. Por lo tanto, tenemos que aplicar la función sigmoide a la transformación afín. Como resultado obtendremos las predicciones del modelo:\n",
        "\n",
        "$$\\hat y = \\sigma(z),$$\n",
        "\n",
        "donde $\\sigma$ es la función sigmoide previamente implementada.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXzrMFDsniDY"
      },
      "source": [
        "def model(X, w, b):\n",
        "  \"\"\"\n",
        "    Este método realiza la transformación afín entre los datos de entrada\n",
        "    y los parámetros, luego se obtienen probabilidades aplicando la función de \n",
        "    activación sigmoide previamente implementada.\n",
        "\n",
        "    Args:\n",
        "      - X: tensor de dimensión (n, m), donde n es el número de datos y m\n",
        "           es el número de características\n",
        "      - w: tensor de dimensión (m, 1), representando los pesos del modelo\n",
        "      - b: tensor de dimensión (1,), representando el bias del modelo\n",
        "\n",
        "    Returns:\n",
        "      - y_pred: tensor de dimensión (n, 1), representando las predicciones\n",
        "                con valores entre 0 y 1\n",
        "  \"\"\"\n",
        "  # TODO: Implementar la transformación afín\n",
        "  z = torch.matmul(X, w) + b\n",
        "\n",
        "  # TODO: Aplicar la función de activación sigmoide\n",
        "  y_pred = sigmoid(z)\n",
        "\n",
        "  assert(y_pred.shape == (X.shape[0], 1))\n",
        "  return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pxZEZf-pcFR"
      },
      "source": [
        "Podemos probar la implementación, prediciendo valores para la data de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZNl8MjJpdVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b38924-bf79-4c96-f320-371273db3392"
      },
      "source": [
        "# Probemos si el código se ejecuta de forma correcta\n",
        "y_pred_train = model(X_train, w, b)\n",
        "\n",
        "print('Predicciones iniciales')\n",
        "print(y_pred_train[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicciones iniciales\n",
            "tensor([[0.4742],\n",
            "        [0.4925],\n",
            "        [0.4582],\n",
            "        [0.4423],\n",
            "        [0.4543],\n",
            "        [0.4524],\n",
            "        [0.4460],\n",
            "        [0.4774],\n",
            "        [0.4840],\n",
            "        [0.4721]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTSQPa2-0tdS"
      },
      "source": [
        "El modelo nos devuelve la predicción actual (probabilidades) dados los parámetros y la data. Los valores deben estar entre 0 y 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Neh-6RZx38iD"
      },
      "source": [
        "### Función de Pérdida (1 punto)\n",
        "\n",
        "La función de pérdida usual para clasificación binaria es la *entropía cruzada binaria (binary cross-entropy)* entre los valores predichos, $\\hat y$, y los valores reales, $y$.\n",
        "\n",
        "$$\\mathcal{l}^{(i)}(\\mathbf{w}, b) = - y^{(i)} \\log(\\hat y^{(i)}) - (1 - y^{(i)}) \\log(1 - \\hat y^{(i)}).$$\n",
        "\n",
        "Para medir la calidad de un modelo en todo el conjunto de datos de $n$ ejemplos, simplemente promediamos las pérdidas en el conjunto de entrenamiento\n",
        "\n",
        "$$\\mathcal{L}(\\mathbf{w}, b)= \\frac{1}{n}\\sum_{i=0}^n l^{(i)}(\\mathbf{w}, b) = -\\frac{1}{n} \\sum_{i=0}^n y^{(i)} \\log(\\hat y^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat y^{(i)}),$$\n",
        "\n",
        "donde $\\hat y^{(i)} = \\sigma (\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b)$ es la predicción del modelo. \n",
        "\n",
        "A continuación implementará la función de pérdida:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yZuPpbk7nYA"
      },
      "source": [
        "def log(z, eps=1e-20):\n",
        "  \"\"\"\n",
        "     Logaritmo numéricamente estable\n",
        "  \"\"\"\n",
        "  return torch.log(torch.maximum(z, torch.tensor(eps)))\n",
        "\n",
        "def BCE(y_pred, y_true):\n",
        "  \"\"\"\n",
        "    Este método calcula la función de pérdida de entropía cruzada binaria.\n",
        "\n",
        "    Args:\n",
        "      - y_pred: tensor de dimensión (n, 1), representando probabilidades\n",
        "      - y_true: tensor de dimensión (n, 1), representando los valores reales (0 o 1)\n",
        "\n",
        "    Returns:\n",
        "      - cost: valor flotante representando el promedio de las pérdidas de cada muestra\n",
        "  \"\"\"\n",
        "  #TODO: Usando la formulación anteriormente definida, implemente la función\n",
        "  #      de pérdida. Implementar la versión vectorizada sin usar bucles.\n",
        "  #      * No usar torch.log() directamente, mejor use la función log() \n",
        "  #        definida anteriormente. \n",
        "  cost = -1*(1/y_true.shape[0])*torch.sum(y_true*log(y_pred)+(1-y_true)*log(1-y_pred))\n",
        "  \n",
        "  return cost\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxdF9vxS9DQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ac97f0-900a-4b24-ca5d-0f6ea6213cb6"
      },
      "source": [
        "# Probemos la implementación del método\n",
        "print(\"Error actual: \", BCE(y_pred_train, y_train).item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error actual:  0.6724939346313477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhh3FRnx_X2p"
      },
      "source": [
        "### Optimización (3 puntos)\n",
        "\n",
        "Para optimizar el modelo implementará el algoritmo de gradiente descendente. La aplicación más simple de este algoritmo consiste en tomar la derivada de la función de pérdida, que es un promedio de las pérdidas calculadas en cada uno de los ejemplos del conjunto de datos. En la práctica, esto puede ser extremadamente lento: debemos pasar todo el conjunto de datos antes de realizar una sola actualización. Por lo tanto, a menudo nos conformaremos con muestrear un mini lote aleatorio de ejemplos cada vez que necesitemos calcular la actualización de parámetros, una variante llamada *mini-batch gradient descent*. \n",
        "\n",
        "La siguiente figura muestra un ejemplo de como se calculan los gradientes usando mini lotes:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1AjhlqZdJq9tm_vCdtL6xwwIqSnH7dla4\" width=\"800px\" />\n",
        "<p/>\n",
        "\n",
        "El primer paso es particionar la data en mini lotes aleatorios, los cuales serán usados de forma independiente para realizar predicciones y calcular la pérdida. El segundo paso es calcular los gradientes de la función de pérdida por lote. Finalmente se realiza la actualización de parámetros usando los gradientes calculados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC-_BIkaIBay"
      },
      "source": [
        "#### Particionamiento en mini lotes (1 punto)\n",
        "\n",
        "El primer paso del algoritmo es particionar los datos en mini lotes. Para ello, en cada iteración obtenemos un mini lote, $\\mathcal{B}$, que consta de un número fijo de muestras. En la figura previamente mostrada se usan mini lotes de tamaño tres ($|B|=3$). Tener en cuenta que muchas veces no es posible obtener un lote de tamaño exacto (Lote 4), esto ocurre cuando el número de datos no es divisible por el tamaño del lote ingresado. Asimismo, considerar que para la data de entrenamiento es necesario aleatorizar los datos antes de realizar el particionamiento en lotes, esto es opcional para la data de prueba.\n",
        "\n",
        "A continuación implementará el método que permita particionar la data en lotes dado el tamaño del lote (`batch_size`) y si se desea aleatorizar los datos antes del particionamiento (`shuffle`). Esta última opción es necesaria usarla durante el entrenamiento:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4yR-xedMhM1"
      },
      "source": [
        "def data_iter(X, y, batch_size, shuffle=True):\n",
        "  \"\"\"\n",
        "    Este método particiona la data en mini lotes de forma aleatoria acorde al \n",
        "    batch_size. En caso el número de datos, n, no sea divisible por el batch_size,\n",
        "    considerar los datos faltantes como un lote. Por ejemplo: Si n = 11 y \n",
        "    batch_size=3 entonces tenemos tres lotes con 3 muestras y un lote con 2 muestras\n",
        "\n",
        "    Args:\n",
        "      - X: tensor de dimensión (n, m), donde n es el número de datos y m\n",
        "           es el número de características\n",
        "      - y: tensor de dimensión (n, 1), representando los valores reales\n",
        "      - batch_size: tamaño de cada lote\n",
        "      - shuffle: True para que los datos se aleatoricen en cada época\n",
        "\n",
        "    Returns:\n",
        "      - Los lotes actuales mediante 'yield' para usar el método como iterador\n",
        "  \"\"\"\n",
        "  n = X.shape[0]\n",
        "  \n",
        "  if shuffle:\n",
        "    # TODO: Crear una lista de índices aleatorios de los datos. Puede usar torch.randperm\n",
        "    indices = torch.randperm(n)\n",
        "  else:\n",
        "    indices = range(n)\n",
        "\n",
        "  # Iteramos sobre los datos considerando el tamaño de cada lote (batch_size)\n",
        "  for i in range(0, n, batch_size):\n",
        "    \n",
        "    # TODO: Obtenga los índices del lote actual. El tamaño de cada lote debe \n",
        "    #       ser igual a batch_size con excepción del último lote que\n",
        "    #       puede ser <= batch_size\n",
        "    batch_indices = indices[i:i+batch_size if i+batch_size <=n else n]\n",
        "    \n",
        "    # TODO: Obtenga el lote de los datos y etiquetas usando los índices\n",
        "    #       previamente seleccionados\n",
        "    X_batch, y_batch = X[batch_indices,:],y[batch_indices,:]\n",
        "\n",
        "    # Retornamos los lotes actuales con yield para usar el método como iterador\n",
        "    yield X_batch, y_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwpOIVifMmBr"
      },
      "source": [
        "Probaremos la implementación mostrando el tamaño de cada lote:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USiYGTuVMmLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f64da6f3-ce68-484b-e38b-d577b4c28684"
      },
      "source": [
        "# Tamaño de cada lote\n",
        "batch_size = 32\n",
        "\n",
        "# Número total de muestras\n",
        "total_samples = 0\n",
        "\n",
        "# Iteramos sobre todos los datos y mostramos el tamaño de cada lote\n",
        "for i, (X_batch, y_batch) in enumerate(data_iter(X_train, y_train, batch_size), 1):\n",
        "  total_samples += X_batch.shape[0]\n",
        "  print(f'Lote {i} tiene tamaño {X_batch.shape[0]}')\n",
        "\n",
        "if total_samples == X_train.shape[0]:\n",
        "  print(':) El número total de muestras por lotes es correcto.')\n",
        "else:\n",
        "  print(':( El número total de muestras por lotes difiere del total de muestras.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lote 1 tiene tamaño 32\n",
            "Lote 2 tiene tamaño 32\n",
            "Lote 3 tiene tamaño 32\n",
            "Lote 4 tiene tamaño 32\n",
            "Lote 5 tiene tamaño 32\n",
            "Lote 6 tiene tamaño 32\n",
            "Lote 7 tiene tamaño 32\n",
            "Lote 8 tiene tamaño 32\n",
            "Lote 9 tiene tamaño 32\n",
            "Lote 10 tiene tamaño 32\n",
            "Lote 11 tiene tamaño 32\n",
            "Lote 12 tiene tamaño 32\n",
            "Lote 13 tiene tamaño 32\n",
            "Lote 14 tiene tamaño 32\n",
            "Lote 15 tiene tamaño 32\n",
            "Lote 16 tiene tamaño 32\n",
            "Lote 17 tiene tamaño 32\n",
            "Lote 18 tiene tamaño 32\n",
            "Lote 19 tiene tamaño 24\n",
            ":) El número total de muestras por lotes es correcto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJsuAaE1N0Kd"
      },
      "source": [
        "#### Gradiente de la función de pérdida (1 punto)\n",
        "\n",
        "El siguiente paso es calcular el gradiente de la función de pérdida con respecto a los parámetros del modelo. El gradiente de la entropía cruzada binaria (BCE) con respecto a los pesos, está dado por lo siguiente:\n",
        "\n",
        "$$ \\nabla_{\\mathbf{w}} \\mathcal{L}(\\mathbf{w},b) = \\frac{1}{n} \\mathbf X^\\top (\\hat y - y),$$\n",
        "\n",
        "donde $\\hat y = \\sigma( \\mathbf{Xw} + b)$. El gradiente con respecto al bias, está dado por lo siguiente:\n",
        "\n",
        "$$ \\nabla_{b} \\mathcal{L}(\\mathbf{w},b) = \\frac{1}{n} \\mathbf 1^\\top (\\hat y - y),$$\n",
        "\n",
        "donde $ \\mathbf{1}$ es una matriz columna de unos, creada a partir del gradiente con respecto al bias el cual es igual a $1$ para todas las muestras. Recuerde que esta multiplicación por la matriz columna de unos se puede reducir a una sumatoria. A continuación, deberá de implementar el método que retorna los gradientes dado un conjunto datos y los parámetros del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJam53luOHbU"
      },
      "source": [
        "def gradient(X, y_pred, y_true):\n",
        "  \"\"\"\n",
        "    Este método calcula el gradiente de la función de pérdida BCE.\n",
        "\n",
        "    Args:\n",
        "      - X: tensor de dimensión (n, m), donde n es el número de datos y m\n",
        "           es el número de características\n",
        "      - y_pred: tensor de dimensión (n, 1), representando probabilidades\n",
        "      - y_true: tensor de dimensión (n, 1), representando los valores reales\n",
        "\n",
        "    Returns:\n",
        "      - w_grad: tensor de dimensión (m, 1), representando los gradientes de los pesos\n",
        "      - b_grad: tensor de dimensión (1,), representando los gradientes del bias\n",
        "  \"\"\"\n",
        "\n",
        "  # Nos aseguramos de que y_true tenga las mismas dimensiones que y_pred\n",
        "  n = X.shape[0]\n",
        "\n",
        "  # TODO: Implemente el gradiente con respecto a los pesos y el bias siguiendo\n",
        "  # las formulaciones brindadas anteriormente\n",
        "  w_grad = 1/n*torch.matmul(torch.t(X),y_pred-y_true)\n",
        "  b_grad = (1/n)*torch.matmul(torch.t(torch.ones_like(X)),y_pred-y_true)\n",
        "  b_grad = (1/n)*torch.sum(y_pred-y_true,dim=0)\n",
        "\n",
        "  #print(b_grad)\n",
        "  #print(b_grad.shape)\n",
        "\n",
        "  # Verificamos dimensiones de resultados\n",
        "  assert(w_grad.shape == (X.shape[1], 1))\n",
        "  assert(b_grad.shape == (1,))\n",
        "\n",
        "  return w_grad, b_grad "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDM_nBt_OK7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "333b1622-6c77-4c70-9502-bbe87bced94a"
      },
      "source": [
        "# Probemos la funcionalidad del método\n",
        "w_grad, b_grad = gradient(X_train, y_pred_train, y_train)\n",
        "\n",
        "print(\"Gradiente de w: \", w_grad)\n",
        "print(\"Gradiente de b: \", b_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradiente de w:  tensor([[ 1.0353],\n",
            "        [-2.9797]])\n",
            "Gradiente de b:  tensor([-0.0452])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M26viSqbOTBb"
      },
      "source": [
        "#### Actualización de parámetros (1 punto)\n",
        "\n",
        "El último paso es actualizar los parámetros usando los gradientes por cada mini lote. Para ello, cada gradiente lo multiplicamos por la tasa de aprendizaje $\\eta$ y restamos el término resultante de los valores de los parámetros actuales. Podemos expresar la actualización de un mini lote matemáticamente de la siguiente manera ($\\nabla$ denota el gradiente):\n",
        "\n",
        "$$(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\nabla_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b).$$\n",
        "\n",
        "A diferencia de la implementación full-batch (visto en el notebook de regresión lineal), podemos ver que en esta versión dividimos por el tamaño del lote $|\\mathcal{B}|$, ya que consideramos un subconjunto de muestras en lugar de todo el conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QLfaKv-OpSL"
      },
      "source": [
        "def gradient_descent_step(w, b, w_grad, b_grad, learning_rate):#, batch_size):\n",
        "  \"\"\"\n",
        "    Este método calcula un paso de gradiente descendente\n",
        "\n",
        "    Args:\n",
        "      - w: tensor de dimensión (m, 1), representando los pesos del modelo\n",
        "      - b: tensor de dimensión (1,), representando el bias del modelo\n",
        "      - w_grad: tensor de dimensión (m, 1), representando los gradientes de los pesos\n",
        "      - b_grad: tensor de dimensión (1,), representando los gradientes del bias\n",
        "      - learning_rate: constante representando la tasa de aprendizaje\n",
        "\n",
        "    Returns:\n",
        "      No retornamos nada, pero actualizamos los parámetros w y b por referencia  \n",
        "  \"\"\"\n",
        "  # TODO: Actualice los pesos usando gradiente descendente\n",
        "  w -= learning_rate*w_grad#/batch_size\n",
        "\n",
        "  # TODO: Actualice el bias usando gradiente descendente\n",
        "  b -= learning_rate*b_grad#/batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pf0VkYzPXIo"
      },
      "source": [
        "Verifiquemos si la implementación actualiza los parámetros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvUd2D7FPXQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a5b693-c886-4763-d103-fa2e8130bd76"
      },
      "source": [
        "# Creamos parámetros temporales para probar la implementación\n",
        "w, b = initialize_params(m)\n",
        "\n",
        "# Realizamos un paso de gradiente descendente\n",
        "gradient_descent_step(w, b, w_grad, b_grad, 0.1)#, 32)\n",
        "\n",
        "# Mostramos los parámetros actualizados\n",
        "print (\"w = \" + str(w))\n",
        "print (\"b = \" + str(b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w = tensor([[-0.1047],\n",
            "        [ 0.3088]])\n",
            "b = tensor([0.0045])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZCQVHgsPjuC"
      },
      "source": [
        "Los parámetros actualizados deben ser diferentes de cero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaKQveLt6N0i"
      },
      "source": [
        "### Entrenamiento (3 puntos)\n",
        "\n",
        "En las secciones anteriores se han implementado diferentes métodos que se usarán durante el entrenamiento. Recordar que el entrenamiento se realiza durante un número específico de épocas. En cada época iteramos sobre todo el conjunto de datos y realizamos el entrenamiento. Una fase adicional e importante es la validación del modelo que se realiza una vez terminado el entrenamiento por época. En términos generales, el algoritmo está dado por lo siguiente:\n",
        "\n",
        "* Inicializar los parámetros $(\\mathbf{w}, b)$\n",
        "* Iterar por un determinado número de épocas. Para cada época:\n",
        "    * Entrenar el modelo usando la data de entrenamiento\n",
        "    * Validar el modelo usando la data de validación\n",
        "\n",
        "A continuación, se implementarán métodos para el entrenamiento y validación por época y luego usaremos estas funciones en un método de entrenamiento principal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q183FDTkr9MK"
      },
      "source": [
        "#### Fase de Entrenamiento (1 punto)\n",
        " \n",
        "Durante esta fase se usará la data de entrenamiento `(X_train, y_train)`. En esta fase **actualizamos los parámetros del modelo** mediante gradiente descendente usando mini lotes. El algoritmo es el siguiente:\n",
        "\n",
        "* Iterar sobre el conjunto de datos usando mini lotes. Para cada mini lote ($\\mathbf{X}, y$):\n",
        "\n",
        "  * Predecir probabilidades $\\hat y \\leftarrow \\sigma(\\mathbf{X}\\mathbf{w} + b)$\n",
        "  * Calcular el gradiente $\\mathbf{g} \\leftarrow \\nabla_{(\\mathbf{w},b)} \\frac{1}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} l(\\hat{y}^{(i)}, y^{(i)}, \\mathbf{w}, b)$\n",
        "  * Actualizar los parámetros $(\\mathbf{w}, b) \\leftarrow (\\mathbf{w}, b) - \\eta \\mathbf{g}$\n",
        "\n",
        "A continuación, se definirá un método para realizar las operaciones de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_G3N102u2Mv"
      },
      "source": [
        "def train_step(X_train, y_train, w, b, learning_rate, batch_size):\n",
        "  \"\"\"\n",
        "    Este método realiza la fase de entrenamiento usando la data de entrenamiento \n",
        "    (X_train, y_train) la que usaremos para actualizar los parámetros del modelo.\n",
        "\n",
        "    Args:\n",
        "      - X_train: tensor de dimensión (n, m), donde n es el número de \n",
        "            datos de entrenamiento y m es el número de características\n",
        "      - y_train: tensor de dimensión (n, 1), representando las etiquetas\n",
        "            reales de la data de entrenamiento \n",
        "      - w: tensor de dimensión (m, 1), representando los pesos del modelo\n",
        "      - b: tensor de dimensión (1,), representando el bias del modelo\n",
        "      - learning_rate: tasa de aprendizaje\n",
        "      - batch_size: tamaño de cada lote\n",
        "\n",
        "    Returns:\n",
        "      - train_loss: pérdida total de la data de entrenamiento\n",
        "  \"\"\"\n",
        "  n, m = X_train.shape\n",
        "  \n",
        "  # Pérdida de entrenamiento total\n",
        "  train_loss = 0.\n",
        "\n",
        "  # Iteramos sobre todos los datos de entrenamiento usando mini lotes\n",
        "  for X, y in data_iter(X_train, y_train, batch_size):\n",
        "\n",
        "    # TODO: Obtener probabilidades del lote actual a partir del modelo\n",
        "    y_pred = model(X,w,b)\n",
        "\n",
        "    # TODO: Calcular la pérdida usando el método BCE\n",
        "    loss = BCE(y_pred,y)\n",
        "\n",
        "    # TODO: Calcular los gradientes de la función de pérdida usando el lote de\n",
        "    #       entrenamiento (X, y) y sus predicciones\n",
        "    w_grad, b_grad = gradient(X,y_pred,y)\n",
        "\n",
        "    # TODO: Actualizar los parámetros con gradiente descendente\n",
        "    gradient_descent_step(w, b, w_grad, b_grad, learning_rate)\n",
        "\n",
        "    # Acumulamos pérdida\n",
        "    train_loss += loss.item() * X.shape[0]\n",
        "\n",
        "  # Pérdida promedio\n",
        "  train_loss /= n\n",
        "\n",
        "  return train_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd73e8OlwzzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dfe98ea-9fe6-44e1-90c8-45750be1e681"
      },
      "source": [
        "# Probemos la implementación\n",
        "m = 2\n",
        "w, b = initialize_params(m)\n",
        "print(f'Error de entrenamiento: {train_step(X_train, y_train, w, b, 0.001, 32):.8f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error de entrenamiento: 0.67249684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAUoN5yf6dKJ"
      },
      "source": [
        "Se espera un error de entrenamiento mayor a $0.5$ y menor a $0.7$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_rbN9bF6uvI"
      },
      "source": [
        "#### Fase de Validación (1 punto)\n",
        "\n",
        "Siempre es importante validar el modelo para saber si está generalizando correctamente, es por ello que usaremos la data de validación `(X_val, y_val)`. La validación se llevará a cabo en cada época, luego de la fase de entrenamiento. Recuerde que en la fase de validación **no actualizamos los parámetros**, por lo tanto, no calculamos gradientes y no usamos gradiente descendente. El algoritmo es el siguiente:\n",
        "\n",
        "* Iterar sobre el conjunto de datos usando mini lotes. Para cada mini lote ($\\mathbf{X}, y$):\n",
        "\n",
        "  * Predecir probabilidades $\\hat y = \\sigma(\\mathbf{X}\\mathbf{w} + b)$\n",
        "  * Calcular el error $\\frac{1}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} l(\\hat{y}^{(i)}, y^{(i)}, \\mathbf{w}, b)$\n",
        "  \n",
        "A continuación, se definirá un método para realizar las operaciones de validación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsRFIdBOC1FH"
      },
      "source": [
        "def validation_step(X_val, y_val, w, b, batch_size):\n",
        "  \"\"\"\n",
        "    Este método realiza la fase de validación usando la data de validación \n",
        "    (X_val, y_val) y los parámetros del modelo entrenado.\n",
        "\n",
        "    Args:\n",
        "      - X_val: tensor de dimensión (n_val, m), donde n_val es el número de \n",
        "            datos de validación y m es el número de características\n",
        "      - y_val: tensor de dimensión (n_val, 1), representando las etiquetas\n",
        "            reales de la data de validación \n",
        "      - w: tensor de dimensión (m, 1), representando los pesos del modelo\n",
        "      - b: tensor de dimensión (1,), representando el bias del modelo\n",
        "      - batch_size: tamaño de cada lote\n",
        "\n",
        "    Returns:\n",
        "      - val_loss: pérdida de toda la data de validación\n",
        "  \"\"\"\n",
        "  n_val, m = X_val.shape\n",
        "  \n",
        "  # Pérdida de validación total\n",
        "  val_loss = 0.\n",
        "\n",
        "  # Debido a que en la fase de validación no actualizamos los parámetros\n",
        "  # no es necesario usar los gradientes\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Iteramos sobre todos los datos de validación usando mini lotes\n",
        "    # No es necesario aleatorizar la data de validación\n",
        "    for X, y in data_iter(X_val, y_val, batch_size, False):\n",
        "\n",
        "      # TODO: Obtener probabilidades del lote actual a partir del modelo\n",
        "      y_pred = model(X,w,b)\n",
        "\n",
        "      # TODO: Calcular la pérdida usando el método BCE \n",
        "      loss = BCE(y_pred,y)\n",
        "      \n",
        "      # Acumulamos pérdida\n",
        "      val_loss += loss.item() * X.shape[0]\n",
        "\n",
        "  # Pérdida promedio\n",
        "  val_loss /= n_val\n",
        "\n",
        "  return val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKXF0qCbE-MV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d34d0911-3fe9-41bb-e3e5-6a69b1d20f04"
      },
      "source": [
        "# Probemos la implementación\n",
        "print(f'Error de validación: {validation_step(X_val, y_val, w, b, 32):.8f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error de validación: 0.57277378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm4Pp4_-G-6L"
      },
      "source": [
        "#### Fase Principal (1 punto)\n",
        "\n",
        "Ahora que tenemos todas las partes en su lugar, estamos listos para implementar el algoritmo de entrenamiento principal. Recordemos que el algoritmo está dado por lo siguiente:\n",
        "\n",
        "* Inicializar los parámetros $(\\mathbf{w}, b)$\n",
        "* Iterar por un determinado número de épocas. Para cada época:\n",
        "    * Entrenar el modelo usando la data de entrenamiento\n",
        "    * Validar el modelo usando la data de validación\n",
        "\n",
        "En cada *época*, iteraremos a través de todo el conjunto de datos usando mini lotes. El número de épocas, `num_epochs`, la tasa de aprendizaje, `lr`, y el tamaño del lote, `batch_size`, son hiperparámetros que debemos definir previos al entrenamiento. Desafortunadamente, definir los valores de los hiperparámetros es complicado y requiere algunos ajustes por prueba y error. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jebmLiHo-uVG"
      },
      "source": [
        "def train_model(X_train, y_train, X_val, y_val, num_epochs, learning_rate, batch_size):\n",
        "  \"\"\"\n",
        "    Este método realiza el entrenamiento del modelo usando (X_train, y_train), y\n",
        "    valida los resultados con (X_val, y_val).\n",
        "\n",
        "    Args:\n",
        "      - X_train: tensor de dimensión (n, m), donde n es el número de \n",
        "            datos de entrenamiento y m es el número de características\n",
        "      - y_train: tensor de dimensión (n, 1), representando las etiquetas\n",
        "            reales de la data de entrenamiento     \n",
        "      - X_val: tensor de dimensión (n_val, m), donde n_val es el número de \n",
        "            datos de validación y m es el número de características\n",
        "      - y_val: tensor de dimensión (n_val, 1), representando las etiquetas\n",
        "            reales de la data de validación \n",
        "      - num_epochs: número de épocas\n",
        "      - learning_rate: tasa de aprendizaje\n",
        "      - batch_size: tamaño de cada lote\n",
        "\n",
        "    Returns:\n",
        "      - w: tensor de dimensión (m, 1), representando los pesos actualizados\n",
        "      - b: tensor de dimensión (1,), representando el bias actualizado\n",
        "  \"\"\"\n",
        "  n, m = X_train.shape\n",
        "\n",
        "  # TODO: Inicializar los los parámetros del modelo\n",
        "  w, b = initialize_params(m)\n",
        "\n",
        "  # TODO: Iterar sobre el número de épocas especificado\n",
        "  for epoch in range(num_epochs):\n",
        "    # Fase de Entrenamiento\n",
        "    # TODO: Usar el método antes implementado para realizar el entrenamiento\n",
        "    train_loss = train_step(X_train, y_train, w, b, learning_rate, batch_size)\n",
        "\n",
        "    # Fase de Validación\n",
        "    # TODO: Usar el método antes implementado para realizar la validación    \n",
        "    val_loss = validation_step(X_val, y_val, w, b, batch_size)\n",
        "\n",
        "    # Imprimimos los errores de entrenamiento y validación\n",
        "    print(f'Epoch ({epoch+1}/{num_epochs}): train_loss = {train_loss:.8f}, val_loss= {val_loss:.8f}')\n",
        "\n",
        "  return w, b  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B0Hv20iBMkb"
      },
      "source": [
        "Ahora probaremos la implementación. Puede probar otros valores en los hiperparámetros que mejoren los resultados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POxxBXQWA4vV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c46d707-208e-4e85-a661-0f97b46f7aac"
      },
      "source": [
        "# Hiperparámetros\n",
        "num_epochs = 500\n",
        "learning_rate = 0.1\n",
        "batch_size = 32\n",
        "\n",
        "# Realizamos el entrenamiento\n",
        "w, b = train_model(X_train, y_train, X_val, y_val, num_epochs, learning_rate, batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch (1/500): train_loss = 0.18186839, val_loss= 0.10088057\n",
            "Epoch (2/500): train_loss = 0.10399512, val_loss= 0.06810453\n",
            "Epoch (3/500): train_loss = 0.08495912, val_loss= 0.07068280\n",
            "Epoch (4/500): train_loss = 0.07800312, val_loss= 0.05591370\n",
            "Epoch (5/500): train_loss = 0.07600862, val_loss= 0.04919173\n",
            "Epoch (6/500): train_loss = 0.07079547, val_loss= 0.04978632\n",
            "Epoch (7/500): train_loss = 0.07123866, val_loss= 0.05145899\n",
            "Epoch (8/500): train_loss = 0.06473291, val_loss= 0.04594831\n",
            "Epoch (9/500): train_loss = 0.06621920, val_loss= 0.04356080\n",
            "Epoch (10/500): train_loss = 0.06749361, val_loss= 0.05129819\n",
            "Epoch (11/500): train_loss = 0.06155810, val_loss= 0.04114991\n",
            "Epoch (12/500): train_loss = 0.06899585, val_loss= 0.03962775\n",
            "Epoch (13/500): train_loss = 0.06398158, val_loss= 0.03792581\n",
            "Epoch (14/500): train_loss = 0.06409724, val_loss= 0.03744528\n",
            "Epoch (15/500): train_loss = 0.06239735, val_loss= 0.03891751\n",
            "Epoch (16/500): train_loss = 0.06057997, val_loss= 0.03566579\n",
            "Epoch (17/500): train_loss = 0.06281780, val_loss= 0.03653739\n",
            "Epoch (18/500): train_loss = 0.05939976, val_loss= 0.03462358\n",
            "Epoch (19/500): train_loss = 0.05892311, val_loss= 0.03403783\n",
            "Epoch (20/500): train_loss = 0.05930744, val_loss= 0.03403041\n",
            "Epoch (21/500): train_loss = 0.06039425, val_loss= 0.03305332\n",
            "Epoch (22/500): train_loss = 0.05897886, val_loss= 0.03275597\n",
            "Epoch (23/500): train_loss = 0.06030170, val_loss= 0.03241744\n",
            "Epoch (24/500): train_loss = 0.05963004, val_loss= 0.03197567\n",
            "Epoch (25/500): train_loss = 0.05546125, val_loss= 0.03593806\n",
            "Epoch (26/500): train_loss = 0.05668444, val_loss= 0.03143017\n",
            "Epoch (27/500): train_loss = 0.05455573, val_loss= 0.03081171\n",
            "Epoch (28/500): train_loss = 0.05777318, val_loss= 0.03047563\n",
            "Epoch (29/500): train_loss = 0.05492123, val_loss= 0.03367645\n",
            "Epoch (30/500): train_loss = 0.05321315, val_loss= 0.03220572\n",
            "Epoch (31/500): train_loss = 0.05422215, val_loss= 0.02970725\n",
            "Epoch (32/500): train_loss = 0.05555047, val_loss= 0.03683624\n",
            "Epoch (33/500): train_loss = 0.05329164, val_loss= 0.03261333\n",
            "Epoch (34/500): train_loss = 0.05420404, val_loss= 0.02867075\n",
            "Epoch (35/500): train_loss = 0.05250722, val_loss= 0.02853033\n",
            "Epoch (36/500): train_loss = 0.05674400, val_loss= 0.03177422\n",
            "Epoch (37/500): train_loss = 0.05286875, val_loss= 0.02861055\n",
            "Epoch (38/500): train_loss = 0.05356240, val_loss= 0.02770401\n",
            "Epoch (39/500): train_loss = 0.05227145, val_loss= 0.03174495\n",
            "Epoch (40/500): train_loss = 0.05144532, val_loss= 0.02781801\n",
            "Epoch (41/500): train_loss = 0.04982070, val_loss= 0.02764811\n",
            "Epoch (42/500): train_loss = 0.05227061, val_loss= 0.02681406\n",
            "Epoch (43/500): train_loss = 0.04871073, val_loss= 0.02715609\n",
            "Epoch (44/500): train_loss = 0.04785167, val_loss= 0.02854532\n",
            "Epoch (45/500): train_loss = 0.05134173, val_loss= 0.02674195\n",
            "Epoch (46/500): train_loss = 0.04729547, val_loss= 0.02665625\n",
            "Epoch (47/500): train_loss = 0.04880077, val_loss= 0.02570895\n",
            "Epoch (48/500): train_loss = 0.04741543, val_loss= 0.02556658\n",
            "Epoch (49/500): train_loss = 0.04602826, val_loss= 0.02650632\n",
            "Epoch (50/500): train_loss = 0.04485066, val_loss= 0.02653977\n",
            "Epoch (51/500): train_loss = 0.04927089, val_loss= 0.02494880\n",
            "Epoch (52/500): train_loss = 0.04405502, val_loss= 0.02832074\n",
            "Epoch (53/500): train_loss = 0.04516307, val_loss= 0.02413339\n",
            "Epoch (54/500): train_loss = 0.04495346, val_loss= 0.02979908\n",
            "Epoch (55/500): train_loss = 0.04661385, val_loss= 0.03468308\n",
            "Epoch (56/500): train_loss = 0.04785143, val_loss= 0.02629272\n",
            "Epoch (57/500): train_loss = 0.04456171, val_loss= 0.02399581\n",
            "Epoch (58/500): train_loss = 0.04428706, val_loss= 0.02471570\n",
            "Epoch (59/500): train_loss = 0.04297687, val_loss= 0.02536058\n",
            "Epoch (60/500): train_loss = 0.04451673, val_loss= 0.02322463\n",
            "Epoch (61/500): train_loss = 0.04488072, val_loss= 0.02281440\n",
            "Epoch (62/500): train_loss = 0.04253944, val_loss= 0.02427975\n",
            "Epoch (63/500): train_loss = 0.04461702, val_loss= 0.02296962\n",
            "Epoch (64/500): train_loss = 0.04260438, val_loss= 0.02292743\n",
            "Epoch (65/500): train_loss = 0.04168634, val_loss= 0.02728509\n",
            "Epoch (66/500): train_loss = 0.04457365, val_loss= 0.02190220\n",
            "Epoch (67/500): train_loss = 0.04158218, val_loss= 0.02175274\n",
            "Epoch (68/500): train_loss = 0.04140297, val_loss= 0.02228282\n",
            "Epoch (69/500): train_loss = 0.04124812, val_loss= 0.02227688\n",
            "Epoch (70/500): train_loss = 0.04194454, val_loss= 0.02408300\n",
            "Epoch (71/500): train_loss = 0.04032651, val_loss= 0.02148619\n",
            "Epoch (72/500): train_loss = 0.03962561, val_loss= 0.02243854\n",
            "Epoch (73/500): train_loss = 0.04061234, val_loss= 0.02129285\n",
            "Epoch (74/500): train_loss = 0.03939951, val_loss= 0.02082224\n",
            "Epoch (75/500): train_loss = 0.04157742, val_loss= 0.02107596\n",
            "Epoch (76/500): train_loss = 0.04045940, val_loss= 0.02051046\n",
            "Epoch (77/500): train_loss = 0.03914410, val_loss= 0.02021998\n",
            "Epoch (78/500): train_loss = 0.04057598, val_loss= 0.02018368\n",
            "Epoch (79/500): train_loss = 0.03966915, val_loss= 0.02340656\n",
            "Epoch (80/500): train_loss = 0.04084271, val_loss= 0.01992008\n",
            "Epoch (81/500): train_loss = 0.03856721, val_loss= 0.01971891\n",
            "Epoch (82/500): train_loss = 0.03881178, val_loss= 0.02063299\n",
            "Epoch (83/500): train_loss = 0.03773624, val_loss= 0.01995106\n",
            "Epoch (84/500): train_loss = 0.03815258, val_loss= 0.01969630\n",
            "Epoch (85/500): train_loss = 0.03770707, val_loss= 0.01954726\n",
            "Epoch (86/500): train_loss = 0.03902873, val_loss= 0.01932062\n",
            "Epoch (87/500): train_loss = 0.03692591, val_loss= 0.01953964\n",
            "Epoch (88/500): train_loss = 0.03767548, val_loss= 0.01878590\n",
            "Epoch (89/500): train_loss = 0.03560805, val_loss= 0.02133338\n",
            "Epoch (90/500): train_loss = 0.03695908, val_loss= 0.02079394\n",
            "Epoch (91/500): train_loss = 0.03578191, val_loss= 0.01943430\n",
            "Epoch (92/500): train_loss = 0.03503509, val_loss= 0.01851791\n",
            "Epoch (93/500): train_loss = 0.03657506, val_loss= 0.01826035\n",
            "Epoch (94/500): train_loss = 0.03554012, val_loss= 0.01870162\n",
            "Epoch (95/500): train_loss = 0.03297864, val_loss= 0.01822963\n",
            "Epoch (96/500): train_loss = 0.03637071, val_loss= 0.01788959\n",
            "Epoch (97/500): train_loss = 0.03581717, val_loss= 0.01766479\n",
            "Epoch (98/500): train_loss = 0.03575837, val_loss= 0.01756761\n",
            "Epoch (99/500): train_loss = 0.03387261, val_loss= 0.02012865\n",
            "Epoch (100/500): train_loss = 0.03480444, val_loss= 0.01767605\n",
            "Epoch (101/500): train_loss = 0.03403193, val_loss= 0.01738427\n",
            "Epoch (102/500): train_loss = 0.03664605, val_loss= 0.01804566\n",
            "Epoch (103/500): train_loss = 0.03548473, val_loss= 0.01707807\n",
            "Epoch (104/500): train_loss = 0.03383684, val_loss= 0.01693959\n",
            "Epoch (105/500): train_loss = 0.03344917, val_loss= 0.01756003\n",
            "Epoch (106/500): train_loss = 0.03402592, val_loss= 0.01694595\n",
            "Epoch (107/500): train_loss = 0.03240358, val_loss= 0.01671294\n",
            "Epoch (108/500): train_loss = 0.03249257, val_loss= 0.01698386\n",
            "Epoch (109/500): train_loss = 0.03205782, val_loss= 0.01676490\n",
            "Epoch (110/500): train_loss = 0.03294015, val_loss= 0.01847853\n",
            "Epoch (111/500): train_loss = 0.03299596, val_loss= 0.01628030\n",
            "Epoch (112/500): train_loss = 0.03180857, val_loss= 0.01635051\n",
            "Epoch (113/500): train_loss = 0.03172175, val_loss= 0.01599685\n",
            "Epoch (114/500): train_loss = 0.03214739, val_loss= 0.01672018\n",
            "Epoch (115/500): train_loss = 0.03153096, val_loss= 0.01583550\n",
            "Epoch (116/500): train_loss = 0.03113072, val_loss= 0.01581235\n",
            "Epoch (117/500): train_loss = 0.03024706, val_loss= 0.01630589\n",
            "Epoch (118/500): train_loss = 0.03056776, val_loss= 0.01582189\n",
            "Epoch (119/500): train_loss = 0.03041721, val_loss= 0.01719733\n",
            "Epoch (120/500): train_loss = 0.02996013, val_loss= 0.01582620\n",
            "Epoch (121/500): train_loss = 0.03036093, val_loss= 0.01592549\n",
            "Epoch (122/500): train_loss = 0.03081418, val_loss= 0.01513902\n",
            "Epoch (123/500): train_loss = 0.03101014, val_loss= 0.01510059\n",
            "Epoch (124/500): train_loss = 0.02864357, val_loss= 0.01705662\n",
            "Epoch (125/500): train_loss = 0.02980949, val_loss= 0.01514983\n",
            "Epoch (126/500): train_loss = 0.03043628, val_loss= 0.01683163\n",
            "Epoch (127/500): train_loss = 0.02899023, val_loss= 0.01495109\n",
            "Epoch (128/500): train_loss = 0.02866369, val_loss= 0.01553033\n",
            "Epoch (129/500): train_loss = 0.02817414, val_loss= 0.01651398\n",
            "Epoch (130/500): train_loss = 0.02964201, val_loss= 0.01471891\n",
            "Epoch (131/500): train_loss = 0.02948993, val_loss= 0.01438079\n",
            "Epoch (132/500): train_loss = 0.03001318, val_loss= 0.01481298\n",
            "Epoch (133/500): train_loss = 0.03017153, val_loss= 0.01437177\n",
            "Epoch (134/500): train_loss = 0.02759524, val_loss= 0.01447968\n",
            "Epoch (135/500): train_loss = 0.02796576, val_loss= 0.01536131\n",
            "Epoch (136/500): train_loss = 0.02796256, val_loss= 0.01392392\n",
            "Epoch (137/500): train_loss = 0.02766873, val_loss= 0.01415635\n",
            "Epoch (138/500): train_loss = 0.02804064, val_loss= 0.01376647\n",
            "Epoch (139/500): train_loss = 0.02682188, val_loss= 0.01369644\n",
            "Epoch (140/500): train_loss = 0.02754533, val_loss= 0.01381627\n",
            "Epoch (141/500): train_loss = 0.02769459, val_loss= 0.01362742\n",
            "Epoch (142/500): train_loss = 0.02674553, val_loss= 0.01353067\n",
            "Epoch (143/500): train_loss = 0.02639450, val_loss= 0.01477767\n",
            "Epoch (144/500): train_loss = 0.02668116, val_loss= 0.01350472\n",
            "Epoch (145/500): train_loss = 0.02702480, val_loss= 0.01341192\n",
            "Epoch (146/500): train_loss = 0.02658400, val_loss= 0.01337812\n",
            "Epoch (147/500): train_loss = 0.02726614, val_loss= 0.01339099\n",
            "Epoch (148/500): train_loss = 0.02711158, val_loss= 0.01306686\n",
            "Epoch (149/500): train_loss = 0.02581841, val_loss= 0.01366123\n",
            "Epoch (150/500): train_loss = 0.02582039, val_loss= 0.01293901\n",
            "Epoch (151/500): train_loss = 0.02503307, val_loss= 0.01302109\n",
            "Epoch (152/500): train_loss = 0.02626425, val_loss= 0.01305743\n",
            "Epoch (153/500): train_loss = 0.02508520, val_loss= 0.01505755\n",
            "Epoch (154/500): train_loss = 0.02747068, val_loss= 0.01670389\n",
            "Epoch (155/500): train_loss = 0.02632440, val_loss= 0.01255337\n",
            "Epoch (156/500): train_loss = 0.02552278, val_loss= 0.01246075\n",
            "Epoch (157/500): train_loss = 0.02599742, val_loss= 0.01265282\n",
            "Epoch (158/500): train_loss = 0.02494661, val_loss= 0.01290593\n",
            "Epoch (159/500): train_loss = 0.02599932, val_loss= 0.01230562\n",
            "Epoch (160/500): train_loss = 0.02563250, val_loss= 0.01227518\n",
            "Epoch (161/500): train_loss = 0.02518668, val_loss= 0.01260012\n",
            "Epoch (162/500): train_loss = 0.02427948, val_loss= 0.01230770\n",
            "Epoch (163/500): train_loss = 0.02471855, val_loss= 0.01442343\n",
            "Epoch (164/500): train_loss = 0.02585134, val_loss= 0.01202009\n",
            "Epoch (165/500): train_loss = 0.02466541, val_loss= 0.01197405\n",
            "Epoch (166/500): train_loss = 0.02380789, val_loss= 0.01188257\n",
            "Epoch (167/500): train_loss = 0.02426423, val_loss= 0.01180493\n",
            "Epoch (168/500): train_loss = 0.02409437, val_loss= 0.01231563\n",
            "Epoch (169/500): train_loss = 0.02385531, val_loss= 0.01169446\n",
            "Epoch (170/500): train_loss = 0.02356984, val_loss= 0.01163818\n",
            "Epoch (171/500): train_loss = 0.02285610, val_loss= 0.01592335\n",
            "Epoch (172/500): train_loss = 0.02172454, val_loss= 0.01152102\n",
            "Epoch (173/500): train_loss = 0.02399796, val_loss= 0.01140309\n",
            "Epoch (174/500): train_loss = 0.02325203, val_loss= 0.01142829\n",
            "Epoch (175/500): train_loss = 0.02277129, val_loss= 0.01131627\n",
            "Epoch (176/500): train_loss = 0.02289292, val_loss= 0.01194605\n",
            "Epoch (177/500): train_loss = 0.02444448, val_loss= 0.01123224\n",
            "Epoch (178/500): train_loss = 0.02317451, val_loss= 0.01231836\n",
            "Epoch (179/500): train_loss = 0.02328637, val_loss= 0.01121996\n",
            "Epoch (180/500): train_loss = 0.02252988, val_loss= 0.01220815\n",
            "Epoch (181/500): train_loss = 0.02286110, val_loss= 0.01154914\n",
            "Epoch (182/500): train_loss = 0.02248847, val_loss= 0.01136080\n",
            "Epoch (183/500): train_loss = 0.02324058, val_loss= 0.01089858\n",
            "Epoch (184/500): train_loss = 0.02184731, val_loss= 0.01107771\n",
            "Epoch (185/500): train_loss = 0.02264767, val_loss= 0.01087313\n",
            "Epoch (186/500): train_loss = 0.02267017, val_loss= 0.01070262\n",
            "Epoch (187/500): train_loss = 0.02272190, val_loss= 0.01068766\n",
            "Epoch (188/500): train_loss = 0.02218594, val_loss= 0.01108174\n",
            "Epoch (189/500): train_loss = 0.02212616, val_loss= 0.01071695\n",
            "Epoch (190/500): train_loss = 0.02215825, val_loss= 0.01050795\n",
            "Epoch (191/500): train_loss = 0.02089362, val_loss= 0.01077225\n",
            "Epoch (192/500): train_loss = 0.02213931, val_loss= 0.01041220\n",
            "Epoch (193/500): train_loss = 0.02182530, val_loss= 0.01035863\n",
            "Epoch (194/500): train_loss = 0.02145306, val_loss= 0.01171831\n",
            "Epoch (195/500): train_loss = 0.02061556, val_loss= 0.01110702\n",
            "Epoch (196/500): train_loss = 0.02177523, val_loss= 0.01115990\n",
            "Epoch (197/500): train_loss = 0.02149595, val_loss= 0.01063753\n",
            "Epoch (198/500): train_loss = 0.02140083, val_loss= 0.01063626\n",
            "Epoch (199/500): train_loss = 0.02138562, val_loss= 0.01020179\n",
            "Epoch (200/500): train_loss = 0.02090680, val_loss= 0.01004663\n",
            "Epoch (201/500): train_loss = 0.02099072, val_loss= 0.01073832\n",
            "Epoch (202/500): train_loss = 0.02121935, val_loss= 0.01029837\n",
            "Epoch (203/500): train_loss = 0.02122483, val_loss= 0.00990659\n",
            "Epoch (204/500): train_loss = 0.02075221, val_loss= 0.00985363\n",
            "Epoch (205/500): train_loss = 0.02048693, val_loss= 0.00986793\n",
            "Epoch (206/500): train_loss = 0.02080795, val_loss= 0.01070553\n",
            "Epoch (207/500): train_loss = 0.02098025, val_loss= 0.00974937\n",
            "Epoch (208/500): train_loss = 0.01973670, val_loss= 0.01045608\n",
            "Epoch (209/500): train_loss = 0.02110078, val_loss= 0.00968920\n",
            "Epoch (210/500): train_loss = 0.02012530, val_loss= 0.00979881\n",
            "Epoch (211/500): train_loss = 0.02009455, val_loss= 0.00973185\n",
            "Epoch (212/500): train_loss = 0.02022238, val_loss= 0.00955725\n",
            "Epoch (213/500): train_loss = 0.02036946, val_loss= 0.00945559\n",
            "Epoch (214/500): train_loss = 0.01984121, val_loss= 0.01001954\n",
            "Epoch (215/500): train_loss = 0.01999003, val_loss= 0.00958862\n",
            "Epoch (216/500): train_loss = 0.01961004, val_loss= 0.00939629\n",
            "Epoch (217/500): train_loss = 0.02030657, val_loss= 0.00932025\n",
            "Epoch (218/500): train_loss = 0.01947279, val_loss= 0.00938255\n",
            "Epoch (219/500): train_loss = 0.01943536, val_loss= 0.00947549\n",
            "Epoch (220/500): train_loss = 0.01954352, val_loss= 0.00928047\n",
            "Epoch (221/500): train_loss = 0.01918012, val_loss= 0.00912870\n",
            "Epoch (222/500): train_loss = 0.01934191, val_loss= 0.00918049\n",
            "Epoch (223/500): train_loss = 0.01911732, val_loss= 0.00905795\n",
            "Epoch (224/500): train_loss = 0.01883723, val_loss= 0.00912836\n",
            "Epoch (225/500): train_loss = 0.01786990, val_loss= 0.01153006\n",
            "Epoch (226/500): train_loss = 0.01856572, val_loss= 0.00908939\n",
            "Epoch (227/500): train_loss = 0.01927701, val_loss= 0.00890428\n",
            "Epoch (228/500): train_loss = 0.01892513, val_loss= 0.00886834\n",
            "Epoch (229/500): train_loss = 0.01915391, val_loss= 0.00908500\n",
            "Epoch (230/500): train_loss = 0.01884282, val_loss= 0.00881128\n",
            "Epoch (231/500): train_loss = 0.01820206, val_loss= 0.00942593\n",
            "Epoch (232/500): train_loss = 0.01840303, val_loss= 0.00885167\n",
            "Epoch (233/500): train_loss = 0.01841110, val_loss= 0.00893878\n",
            "Epoch (234/500): train_loss = 0.01842854, val_loss= 0.00866658\n",
            "Epoch (235/500): train_loss = 0.01868915, val_loss= 0.00905873\n",
            "Epoch (236/500): train_loss = 0.01880175, val_loss= 0.00867777\n",
            "Epoch (237/500): train_loss = 0.01779282, val_loss= 0.00856493\n",
            "Epoch (238/500): train_loss = 0.01807168, val_loss= 0.00849105\n",
            "Epoch (239/500): train_loss = 0.01822937, val_loss= 0.00845196\n",
            "Epoch (240/500): train_loss = 0.01788919, val_loss= 0.00847988\n",
            "Epoch (241/500): train_loss = 0.01802758, val_loss= 0.00860704\n",
            "Epoch (242/500): train_loss = 0.01775449, val_loss= 0.00847060\n",
            "Epoch (243/500): train_loss = 0.01755651, val_loss= 0.00903848\n",
            "Epoch (244/500): train_loss = 0.01800061, val_loss= 0.00887725\n",
            "Epoch (245/500): train_loss = 0.01811426, val_loss= 0.00854588\n",
            "Epoch (246/500): train_loss = 0.01840073, val_loss= 0.00822749\n",
            "Epoch (247/500): train_loss = 0.01792509, val_loss= 0.00828737\n",
            "Epoch (248/500): train_loss = 0.01826340, val_loss= 0.00823523\n",
            "Epoch (249/500): train_loss = 0.01738315, val_loss= 0.00823181\n",
            "Epoch (250/500): train_loss = 0.01736132, val_loss= 0.00813422\n",
            "Epoch (251/500): train_loss = 0.01712642, val_loss= 0.00808772\n",
            "Epoch (252/500): train_loss = 0.01742337, val_loss= 0.00805520\n",
            "Epoch (253/500): train_loss = 0.01738789, val_loss= 0.00805176\n",
            "Epoch (254/500): train_loss = 0.01728322, val_loss= 0.00847463\n",
            "Epoch (255/500): train_loss = 0.01706843, val_loss= 0.00881706\n",
            "Epoch (256/500): train_loss = 0.01765046, val_loss= 0.00801887\n",
            "Epoch (257/500): train_loss = 0.01710698, val_loss= 0.00784531\n",
            "Epoch (258/500): train_loss = 0.01690111, val_loss= 0.00841629\n",
            "Epoch (259/500): train_loss = 0.01663020, val_loss= 0.00788774\n",
            "Epoch (260/500): train_loss = 0.01749360, val_loss= 0.00775171\n",
            "Epoch (261/500): train_loss = 0.01660549, val_loss= 0.00854047\n",
            "Epoch (262/500): train_loss = 0.01700569, val_loss= 0.00814541\n",
            "Epoch (263/500): train_loss = 0.01693819, val_loss= 0.00784664\n",
            "Epoch (264/500): train_loss = 0.01721420, val_loss= 0.00789315\n",
            "Epoch (265/500): train_loss = 0.01636705, val_loss= 0.00808177\n",
            "Epoch (266/500): train_loss = 0.01682078, val_loss= 0.00797239\n",
            "Epoch (267/500): train_loss = 0.01695686, val_loss= 0.00765686\n",
            "Epoch (268/500): train_loss = 0.01664140, val_loss= 0.00752126\n",
            "Epoch (269/500): train_loss = 0.01616087, val_loss= 0.00798977\n",
            "Epoch (270/500): train_loss = 0.01684251, val_loss= 0.00757639\n",
            "Epoch (271/500): train_loss = 0.01655985, val_loss= 0.00744654\n",
            "Epoch (272/500): train_loss = 0.01677266, val_loss= 0.00740352\n",
            "Epoch (273/500): train_loss = 0.01632609, val_loss= 0.00737440\n",
            "Epoch (274/500): train_loss = 0.01645337, val_loss= 0.00777270\n",
            "Epoch (275/500): train_loss = 0.01615557, val_loss= 0.00760781\n",
            "Epoch (276/500): train_loss = 0.01587755, val_loss= 0.00737263\n",
            "Epoch (277/500): train_loss = 0.01617793, val_loss= 0.00735366\n",
            "Epoch (278/500): train_loss = 0.01592377, val_loss= 0.00762074\n",
            "Epoch (279/500): train_loss = 0.01556822, val_loss= 0.00735868\n",
            "Epoch (280/500): train_loss = 0.01564875, val_loss= 0.00792017\n",
            "Epoch (281/500): train_loss = 0.01592763, val_loss= 0.00722999\n",
            "Epoch (282/500): train_loss = 0.01600287, val_loss= 0.00778542\n",
            "Epoch (283/500): train_loss = 0.01592368, val_loss= 0.00713692\n",
            "Epoch (284/500): train_loss = 0.01611817, val_loss= 0.00708280\n",
            "Epoch (285/500): train_loss = 0.01560599, val_loss= 0.00762864\n",
            "Epoch (286/500): train_loss = 0.01538685, val_loss= 0.00840171\n",
            "Epoch (287/500): train_loss = 0.01533735, val_loss= 0.00705475\n",
            "Epoch (288/500): train_loss = 0.01536482, val_loss= 0.00701084\n",
            "Epoch (289/500): train_loss = 0.01557056, val_loss= 0.00707037\n",
            "Epoch (290/500): train_loss = 0.01513267, val_loss= 0.00743781\n",
            "Epoch (291/500): train_loss = 0.01539047, val_loss= 0.00689736\n",
            "Epoch (292/500): train_loss = 0.01528998, val_loss= 0.00696417\n",
            "Epoch (293/500): train_loss = 0.01517849, val_loss= 0.00706351\n",
            "Epoch (294/500): train_loss = 0.01533195, val_loss= 0.00729945\n",
            "Epoch (295/500): train_loss = 0.01529803, val_loss= 0.00711956\n",
            "Epoch (296/500): train_loss = 0.01543580, val_loss= 0.00683143\n",
            "Epoch (297/500): train_loss = 0.01496180, val_loss= 0.00693220\n",
            "Epoch (298/500): train_loss = 0.01570708, val_loss= 0.00707359\n",
            "Epoch (299/500): train_loss = 0.01509313, val_loss= 0.00756558\n",
            "Epoch (300/500): train_loss = 0.01519120, val_loss= 0.00668406\n",
            "Epoch (301/500): train_loss = 0.01507169, val_loss= 0.00667158\n",
            "Epoch (302/500): train_loss = 0.01512770, val_loss= 0.00665033\n",
            "Epoch (303/500): train_loss = 0.01481323, val_loss= 0.00699109\n",
            "Epoch (304/500): train_loss = 0.01460748, val_loss= 0.00771255\n",
            "Epoch (305/500): train_loss = 0.01495525, val_loss= 0.00676029\n",
            "Epoch (306/500): train_loss = 0.01457609, val_loss= 0.00711624\n",
            "Epoch (307/500): train_loss = 0.01500319, val_loss= 0.00655971\n",
            "Epoch (308/500): train_loss = 0.01431005, val_loss= 0.00701863\n",
            "Epoch (309/500): train_loss = 0.01462327, val_loss= 0.00676418\n",
            "Epoch (310/500): train_loss = 0.01454702, val_loss= 0.00646425\n",
            "Epoch (311/500): train_loss = 0.01493588, val_loss= 0.00651202\n",
            "Epoch (312/500): train_loss = 0.01450158, val_loss= 0.00643434\n",
            "Epoch (313/500): train_loss = 0.01451691, val_loss= 0.00648717\n",
            "Epoch (314/500): train_loss = 0.01441581, val_loss= 0.00638355\n",
            "Epoch (315/500): train_loss = 0.01432003, val_loss= 0.00658070\n",
            "Epoch (316/500): train_loss = 0.01438382, val_loss= 0.00635158\n",
            "Epoch (317/500): train_loss = 0.01421388, val_loss= 0.00632346\n",
            "Epoch (318/500): train_loss = 0.01465631, val_loss= 0.00637137\n",
            "Epoch (319/500): train_loss = 0.01432473, val_loss= 0.00634691\n",
            "Epoch (320/500): train_loss = 0.01396586, val_loss= 0.00694208\n",
            "Epoch (321/500): train_loss = 0.01414293, val_loss= 0.00654372\n",
            "Epoch (322/500): train_loss = 0.01434522, val_loss= 0.00627977\n",
            "Epoch (323/500): train_loss = 0.01379091, val_loss= 0.00625945\n",
            "Epoch (324/500): train_loss = 0.01429394, val_loss= 0.00635119\n",
            "Epoch (325/500): train_loss = 0.01367525, val_loss= 0.00695204\n",
            "Epoch (326/500): train_loss = 0.01400130, val_loss= 0.00616056\n",
            "Epoch (327/500): train_loss = 0.01358277, val_loss= 0.00646645\n",
            "Epoch (328/500): train_loss = 0.01384352, val_loss= 0.00634860\n",
            "Epoch (329/500): train_loss = 0.01361754, val_loss= 0.00690621\n",
            "Epoch (330/500): train_loss = 0.01360638, val_loss= 0.00613187\n",
            "Epoch (331/500): train_loss = 0.01375484, val_loss= 0.00607816\n",
            "Epoch (332/500): train_loss = 0.01383195, val_loss= 0.00642527\n",
            "Epoch (333/500): train_loss = 0.01395620, val_loss= 0.00627850\n",
            "Epoch (334/500): train_loss = 0.01360188, val_loss= 0.00631875\n",
            "Epoch (335/500): train_loss = 0.01344113, val_loss= 0.00624539\n",
            "Epoch (336/500): train_loss = 0.01346640, val_loss= 0.00593776\n",
            "Epoch (337/500): train_loss = 0.01327380, val_loss= 0.00621809\n",
            "Epoch (338/500): train_loss = 0.01343747, val_loss= 0.00611264\n",
            "Epoch (339/500): train_loss = 0.01345004, val_loss= 0.00604175\n",
            "Epoch (340/500): train_loss = 0.01417842, val_loss= 0.00660094\n",
            "Epoch (341/500): train_loss = 0.01366765, val_loss= 0.00602872\n",
            "Epoch (342/500): train_loss = 0.01366209, val_loss= 0.00580993\n",
            "Epoch (343/500): train_loss = 0.01315966, val_loss= 0.00635939\n",
            "Epoch (344/500): train_loss = 0.01319687, val_loss= 0.00577365\n",
            "Epoch (345/500): train_loss = 0.01315359, val_loss= 0.00578598\n",
            "Epoch (346/500): train_loss = 0.01295629, val_loss= 0.00573717\n",
            "Epoch (347/500): train_loss = 0.01298484, val_loss= 0.00585376\n",
            "Epoch (348/500): train_loss = 0.01318472, val_loss= 0.00572361\n",
            "Epoch (349/500): train_loss = 0.01321368, val_loss= 0.00569653\n",
            "Epoch (350/500): train_loss = 0.01305462, val_loss= 0.00628140\n",
            "Epoch (351/500): train_loss = 0.01278907, val_loss= 0.00569288\n",
            "Epoch (352/500): train_loss = 0.01325741, val_loss= 0.00573180\n",
            "Epoch (353/500): train_loss = 0.01313701, val_loss= 0.00591520\n",
            "Epoch (354/500): train_loss = 0.01286724, val_loss= 0.00568817\n",
            "Epoch (355/500): train_loss = 0.01276752, val_loss= 0.00602458\n",
            "Epoch (356/500): train_loss = 0.01346457, val_loss= 0.00579047\n",
            "Epoch (357/500): train_loss = 0.01287862, val_loss= 0.00592236\n",
            "Epoch (358/500): train_loss = 0.01266662, val_loss= 0.00581119\n",
            "Epoch (359/500): train_loss = 0.01268119, val_loss= 0.00692343\n",
            "Epoch (360/500): train_loss = 0.01325247, val_loss= 0.00577878\n",
            "Epoch (361/500): train_loss = 0.01286915, val_loss= 0.00549087\n",
            "Epoch (362/500): train_loss = 0.01315771, val_loss= 0.00547845\n",
            "Epoch (363/500): train_loss = 0.01260113, val_loss= 0.00617192\n",
            "Epoch (364/500): train_loss = 0.01255368, val_loss= 0.00557028\n",
            "Epoch (365/500): train_loss = 0.01295226, val_loss= 0.00564113\n",
            "Epoch (366/500): train_loss = 0.01270789, val_loss= 0.00541517\n",
            "Epoch (367/500): train_loss = 0.01221162, val_loss= 0.00584675\n",
            "Epoch (368/500): train_loss = 0.01247564, val_loss= 0.00542980\n",
            "Epoch (369/500): train_loss = 0.01255662, val_loss= 0.00536119\n",
            "Epoch (370/500): train_loss = 0.01262370, val_loss= 0.00540979\n",
            "Epoch (371/500): train_loss = 0.01250842, val_loss= 0.00546838\n",
            "Epoch (372/500): train_loss = 0.01262030, val_loss= 0.00531734\n",
            "Epoch (373/500): train_loss = 0.01212650, val_loss= 0.00583488\n",
            "Epoch (374/500): train_loss = 0.01228588, val_loss= 0.00549121\n",
            "Epoch (375/500): train_loss = 0.01218784, val_loss= 0.00584831\n",
            "Epoch (376/500): train_loss = 0.01233448, val_loss= 0.00549552\n",
            "Epoch (377/500): train_loss = 0.01225022, val_loss= 0.00532048\n",
            "Epoch (378/500): train_loss = 0.01206464, val_loss= 0.00523781\n",
            "Epoch (379/500): train_loss = 0.01180627, val_loss= 0.00642623\n",
            "Epoch (380/500): train_loss = 0.01251683, val_loss= 0.00531347\n",
            "Epoch (381/500): train_loss = 0.01228976, val_loss= 0.00530776\n",
            "Epoch (382/500): train_loss = 0.01207857, val_loss= 0.00516202\n",
            "Epoch (383/500): train_loss = 0.01204005, val_loss= 0.00519158\n",
            "Epoch (384/500): train_loss = 0.01180227, val_loss= 0.00541976\n",
            "Epoch (385/500): train_loss = 0.01213564, val_loss= 0.00552717\n",
            "Epoch (386/500): train_loss = 0.01220753, val_loss= 0.00531926\n",
            "Epoch (387/500): train_loss = 0.01210912, val_loss= 0.00519866\n",
            "Epoch (388/500): train_loss = 0.01224819, val_loss= 0.00527336\n",
            "Epoch (389/500): train_loss = 0.01204514, val_loss= 0.00562243\n",
            "Epoch (390/500): train_loss = 0.01189257, val_loss= 0.00550443\n",
            "Epoch (391/500): train_loss = 0.01185571, val_loss= 0.00506132\n",
            "Epoch (392/500): train_loss = 0.01155402, val_loss= 0.00588313\n",
            "Epoch (393/500): train_loss = 0.01190192, val_loss= 0.00536117\n",
            "Epoch (394/500): train_loss = 0.01156433, val_loss= 0.00506804\n",
            "Epoch (395/500): train_loss = 0.01200309, val_loss= 0.00504016\n",
            "Epoch (396/500): train_loss = 0.01147693, val_loss= 0.00552960\n",
            "Epoch (397/500): train_loss = 0.01186315, val_loss= 0.00542337\n",
            "Epoch (398/500): train_loss = 0.01163461, val_loss= 0.00511787\n",
            "Epoch (399/500): train_loss = 0.01164913, val_loss= 0.00491500\n",
            "Epoch (400/500): train_loss = 0.01164622, val_loss= 0.00492179\n",
            "Epoch (401/500): train_loss = 0.01177481, val_loss= 0.00507119\n",
            "Epoch (402/500): train_loss = 0.01159346, val_loss= 0.00542866\n",
            "Epoch (403/500): train_loss = 0.01157852, val_loss= 0.00501099\n",
            "Epoch (404/500): train_loss = 0.01160949, val_loss= 0.00521840\n",
            "Epoch (405/500): train_loss = 0.01159568, val_loss= 0.00512779\n",
            "Epoch (406/500): train_loss = 0.01141658, val_loss= 0.00521707\n",
            "Epoch (407/500): train_loss = 0.01165716, val_loss= 0.00487146\n",
            "Epoch (408/500): train_loss = 0.01151996, val_loss= 0.00480679\n",
            "Epoch (409/500): train_loss = 0.01160032, val_loss= 0.00483856\n",
            "Epoch (410/500): train_loss = 0.01138918, val_loss= 0.00498091\n",
            "Epoch (411/500): train_loss = 0.01128777, val_loss= 0.00474998\n",
            "Epoch (412/500): train_loss = 0.01146588, val_loss= 0.00476513\n",
            "Epoch (413/500): train_loss = 0.01136504, val_loss= 0.00483122\n",
            "Epoch (414/500): train_loss = 0.01128009, val_loss= 0.00473454\n",
            "Epoch (415/500): train_loss = 0.01150796, val_loss= 0.00482389\n",
            "Epoch (416/500): train_loss = 0.01157133, val_loss= 0.00479861\n",
            "Epoch (417/500): train_loss = 0.01118621, val_loss= 0.00485455\n",
            "Epoch (418/500): train_loss = 0.01132550, val_loss= 0.00469540\n",
            "Epoch (419/500): train_loss = 0.01115396, val_loss= 0.00484276\n",
            "Epoch (420/500): train_loss = 0.01113953, val_loss= 0.00485591\n",
            "Epoch (421/500): train_loss = 0.01116781, val_loss= 0.00473596\n",
            "Epoch (422/500): train_loss = 0.01110621, val_loss= 0.00527068\n",
            "Epoch (423/500): train_loss = 0.01119811, val_loss= 0.00513804\n",
            "Epoch (424/500): train_loss = 0.01115577, val_loss= 0.00487950\n",
            "Epoch (425/500): train_loss = 0.01100795, val_loss= 0.00459867\n",
            "Epoch (426/500): train_loss = 0.01104322, val_loss= 0.00478182\n",
            "Epoch (427/500): train_loss = 0.01096049, val_loss= 0.00461956\n",
            "Epoch (428/500): train_loss = 0.01085027, val_loss= 0.00509544\n",
            "Epoch (429/500): train_loss = 0.01114343, val_loss= 0.00474032\n",
            "Epoch (430/500): train_loss = 0.01092471, val_loss= 0.00452781\n",
            "Epoch (431/500): train_loss = 0.01095367, val_loss= 0.00499667\n",
            "Epoch (432/500): train_loss = 0.01093646, val_loss= 0.00485700\n",
            "Epoch (433/500): train_loss = 0.01112297, val_loss= 0.00451711\n",
            "Epoch (434/500): train_loss = 0.01090498, val_loss= 0.00461549\n",
            "Epoch (435/500): train_loss = 0.01089134, val_loss= 0.00446519\n",
            "Epoch (436/500): train_loss = 0.01102508, val_loss= 0.00449727\n",
            "Epoch (437/500): train_loss = 0.01072031, val_loss= 0.00471317\n",
            "Epoch (438/500): train_loss = 0.01080762, val_loss= 0.00449180\n",
            "Epoch (439/500): train_loss = 0.01073205, val_loss= 0.00456013\n",
            "Epoch (440/500): train_loss = 0.01066047, val_loss= 0.00494809\n",
            "Epoch (441/500): train_loss = 0.01064134, val_loss= 0.00444663\n",
            "Epoch (442/500): train_loss = 0.01070343, val_loss= 0.00487225\n",
            "Epoch (443/500): train_loss = 0.01063145, val_loss= 0.00483130\n",
            "Epoch (444/500): train_loss = 0.01086890, val_loss= 0.00436476\n",
            "Epoch (445/500): train_loss = 0.01039953, val_loss= 0.00521486\n",
            "Epoch (446/500): train_loss = 0.01063694, val_loss= 0.00470866\n",
            "Epoch (447/500): train_loss = 0.01058224, val_loss= 0.00452893\n",
            "Epoch (448/500): train_loss = 0.01039707, val_loss= 0.00442923\n",
            "Epoch (449/500): train_loss = 0.01055099, val_loss= 0.00444387\n",
            "Epoch (450/500): train_loss = 0.01046076, val_loss= 0.00450546\n",
            "Epoch (451/500): train_loss = 0.01070960, val_loss= 0.00443651\n",
            "Epoch (452/500): train_loss = 0.01038724, val_loss= 0.00429008\n",
            "Epoch (453/500): train_loss = 0.01055621, val_loss= 0.00430784\n",
            "Epoch (454/500): train_loss = 0.01059772, val_loss= 0.00434165\n",
            "Epoch (455/500): train_loss = 0.01028527, val_loss= 0.00454130\n",
            "Epoch (456/500): train_loss = 0.01065314, val_loss= 0.00422634\n",
            "Epoch (457/500): train_loss = 0.01041197, val_loss= 0.00438941\n",
            "Epoch (458/500): train_loss = 0.01041191, val_loss= 0.00456048\n",
            "Epoch (459/500): train_loss = 0.01019778, val_loss= 0.00423751\n",
            "Epoch (460/500): train_loss = 0.01038835, val_loss= 0.00418283\n",
            "Epoch (461/500): train_loss = 0.01034050, val_loss= 0.00433155\n",
            "Epoch (462/500): train_loss = 0.01030564, val_loss= 0.00433676\n",
            "Epoch (463/500): train_loss = 0.01034237, val_loss= 0.00448842\n",
            "Epoch (464/500): train_loss = 0.01042744, val_loss= 0.00439118\n",
            "Epoch (465/500): train_loss = 0.01031975, val_loss= 0.00444940\n",
            "Epoch (466/500): train_loss = 0.01026762, val_loss= 0.00432351\n",
            "Epoch (467/500): train_loss = 0.01011955, val_loss= 0.00448690\n",
            "Epoch (468/500): train_loss = 0.01006036, val_loss= 0.00410444\n",
            "Epoch (469/500): train_loss = 0.01002940, val_loss= 0.00460023\n",
            "Epoch (470/500): train_loss = 0.01019452, val_loss= 0.00421034\n",
            "Epoch (471/500): train_loss = 0.00992560, val_loss= 0.00411916\n",
            "Epoch (472/500): train_loss = 0.01004030, val_loss= 0.00409096\n",
            "Epoch (473/500): train_loss = 0.01006784, val_loss= 0.00415631\n",
            "Epoch (474/500): train_loss = 0.00985932, val_loss= 0.00403291\n",
            "Epoch (475/500): train_loss = 0.01009432, val_loss= 0.00429468\n",
            "Epoch (476/500): train_loss = 0.00977166, val_loss= 0.00405680\n",
            "Epoch (477/500): train_loss = 0.01007921, val_loss= 0.00404623\n",
            "Epoch (478/500): train_loss = 0.00987167, val_loss= 0.00430709\n",
            "Epoch (479/500): train_loss = 0.00994127, val_loss= 0.00456949\n",
            "Epoch (480/500): train_loss = 0.00990997, val_loss= 0.00418549\n",
            "Epoch (481/500): train_loss = 0.01001842, val_loss= 0.00441543\n",
            "Epoch (482/500): train_loss = 0.00996377, val_loss= 0.00406668\n",
            "Epoch (483/500): train_loss = 0.00985491, val_loss= 0.00428242\n",
            "Epoch (484/500): train_loss = 0.00990204, val_loss= 0.00424235\n",
            "Epoch (485/500): train_loss = 0.00978473, val_loss= 0.00407421\n",
            "Epoch (486/500): train_loss = 0.00983456, val_loss= 0.00394476\n",
            "Epoch (487/500): train_loss = 0.00983983, val_loss= 0.00423252\n",
            "Epoch (488/500): train_loss = 0.00976757, val_loss= 0.00410036\n",
            "Epoch (489/500): train_loss = 0.00985458, val_loss= 0.00406926\n",
            "Epoch (490/500): train_loss = 0.00965519, val_loss= 0.00415018\n",
            "Epoch (491/500): train_loss = 0.00967801, val_loss= 0.00396503\n",
            "Epoch (492/500): train_loss = 0.00970856, val_loss= 0.00410047\n",
            "Epoch (493/500): train_loss = 0.00982619, val_loss= 0.00399860\n",
            "Epoch (494/500): train_loss = 0.00966061, val_loss= 0.00384632\n",
            "Epoch (495/500): train_loss = 0.00972278, val_loss= 0.00396026\n",
            "Epoch (496/500): train_loss = 0.00964733, val_loss= 0.00401896\n",
            "Epoch (497/500): train_loss = 0.00946036, val_loss= 0.00383658\n",
            "Epoch (498/500): train_loss = 0.00974059, val_loss= 0.00382501\n",
            "Epoch (499/500): train_loss = 0.00979565, val_loss= 0.00404774\n",
            "Epoch (500/500): train_loss = 0.00971259, val_loss= 0.00399248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTVUe5wqBhoz"
      },
      "source": [
        "Como se puede observar, tanto el error de entrenamiento como el de validación comienzan a bajar, lo que nos indica que el entrenamiento se está realizando de forma correcta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFxKdV9exx1F"
      },
      "source": [
        "### Predicción (1 punto)\n",
        "\n",
        "Las predicciones actuales son probabilidades. Sin embargo, en clasificación estamos interesados en valores discretos, en este caso nos interesan valores 0 y 1. Por lo tanto, podemos usar un threshold, si las probabilidades de predicción son mayores que ese threshold entonces clasificamos esos datos como clase 1 sino como clase 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7OZzOxAyK87"
      },
      "source": [
        "def predict(X, w, b, threshold=0.5):\n",
        "  \"\"\" \n",
        "     Este método predice si la etiqueta es 0 o 1 utilizando los parámetros\n",
        "     del modelo (w, b) y un threshold\n",
        "\n",
        "    Args:\n",
        "      - X: tensor de dimensión (n, m), donde n es el número de datos y m\n",
        "           es el número de características\n",
        "      - w: tensor de dimensión (m, 1), representando los pesos del modelo\n",
        "      - b: tensor de dimensión (1,), representando el bias del modelo\n",
        "      - threshold: umbral para obtener valores discretos a partir de probabilidades\n",
        "    \n",
        "    Returns:\n",
        "      - y_pred: tensor de dimensión (n, 1), representando las predicciones\n",
        "                con valores 0 o 1. No probabilidades.\n",
        "  \"\"\"    \n",
        "  # Debido a que en esta fase no actualizamos los parámetros\n",
        "  # no es necesario usar los gradientes\n",
        "  with torch.no_grad():\n",
        "    #TODO: Obtenga probabilidades a partir del modelo\n",
        "    y_prob = model(X,w,b)\n",
        "\n",
        "    #TODO: Convierta las probabilidades en 0 (si activación < threshold) o \n",
        "    #      1 (si activación >= threshold), almacenar las predicciones en y_pred\n",
        "    #      Se recomienda implementar la versión vectorizada (sin bucles)\n",
        "    y_pred = torch.where(y_prob < threshold,0,1)\n",
        "  \n",
        "  assert(y_pred.shape == y_prob.shape)\n",
        "  return y_pred "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQaCUbZTzenb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcf4bdf1-e9bc-4b44-a5c5-1bacf265ed20"
      },
      "source": [
        "# Probemos la implementación\n",
        "y_pred_val = predict(X_val, w, b)\n",
        "\n",
        "print('Primeras 10 predicciones: ')\n",
        "print(y_pred_val[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeras 10 predicciones: \n",
            "tensor([[0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTCmbjuVrgAr"
      },
      "source": [
        "#### Límite de Decisión\n",
        "\n",
        "Podemos visualizar el límite de decisión y las predicciones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO0jYwNOriEM"
      },
      "source": [
        "def plot_decision_boundary(X, y, w, b):\n",
        "  plt.scatter(X[:, 0], X[:, 1], c=y, s=10, cmap=cmap_bold)  \n",
        "  x_values = torch.tensor([X[:, 0].min(), X[:, 0].max()])\n",
        "  #x_values = torch.tensor([-8, 15])\n",
        "  if w[1] > 0:\n",
        "    y_values = -(b + x_values * w[0])/ w[1]\n",
        "  else: \n",
        "    y_values = -(b + x_values * w[0])#/ 1e-8\n",
        "  plt.plot(x_values, y_values, c='purple')\n",
        "  plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKuyXDWrKBqh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "6d584c68-73b2-4621-e8ec-b4c1f81edc17"
      },
      "source": [
        "plot_decision_boundary(X_val, y_pred_val, w, b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXlKzrNzK_Kq"
      },
      "source": [
        "Podemos ver que el límite de decisión separa ambas clases, asi como las predicciones. Visualizar los resultados es algo bueno, pero solo se puede aplicar en datos con pocas dimensiones o características. Una mejor forma de evaluar el modelo es cuantificar los resultados y medir el rendimiento mediante métricas de evaluación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrG_GsyjzSuQ"
      },
      "source": [
        "### Métrica de Evaluación (1 punto)\n",
        "\n",
        "Una forma de evaluar el rendimiento de nuestro modelo es mediante métricas de evaluación. Existen diferentes métricas para clasificación, en este trabajo usaremos el `accuracy`, el cual está definido de la siguiente manera:\n",
        "\n",
        "$$\\text{Accuracy} = \\frac{\\text{Número de predicciones correctas}}{\\text{Número total de predicciones}} = \\frac{1}{n}\\sum_{i=0}^{n} \\mathbb{I}(\\hat y^{(i)} = y^{(i)} ),$$\n",
        "\n",
        "donde $\\mathbb{I}$ es una función indicadora que retorna 1 cada vez que se cumple la condición, caso contrario retorna 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtdBW3WkzdEo"
      },
      "source": [
        "def accuracy(y_true, y_pred): \n",
        "  \"\"\"\n",
        "    Este método devuelve la métrica de evaluación 'accuracy' del clasificador.\n",
        "    Recordar que accuracy cuenta la cantidad promedio de datos correctamente predichos\n",
        "    para ello comparamos los valores reales, 'y_true', con los valores predichos,\n",
        "    'y_pred', realizamos el conteo de valores correctamente clasificados y retornamos\n",
        "    el promedio.\n",
        "\n",
        "    Args: \n",
        "        - y_true: tensor de dimensión (n,1) conteniendo las etiquetas reales \n",
        "        - y_pred: tensor de dimensión (n,1) conteniendo las etiquetas predichas.\n",
        "                  estas predicciones deben ser valores discretos (0 y 1), no probabilidades\n",
        "\n",
        "    Returns:\n",
        "        - accuracy: Accuracy del clasificador. Su valor estará en el rango de [0, 1], \n",
        "                    siendo 1 una clasificación perfecta.\n",
        "  \"\"\" \n",
        "  n = y_true.shape[0]\n",
        "\n",
        "  # TODO: Calcule el accuracy. Implementar la versión vectorizada (sin bucles)\n",
        "  acc = 1/n*torch.sum(torch.where(y_pred==y_true,1,0))\n",
        "\n",
        "  assert(acc >= 0 and acc <= 1)\n",
        "  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMkQ-95oMEJq"
      },
      "source": [
        "Podemos calcular el accuracy de la data de entrenamiento y validación. Para ello, son necesarias las predicciones que devuelven valores discretos (0 y 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VsR3jFw0xuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd370f9-8d95-42a5-ac8a-059b0c35887a"
      },
      "source": [
        "# TODO: Obtenga predicciones discretas para la data entrenamiento y validación\n",
        "#       usando los parámetros w y b hallados durante el entrenamiento\n",
        "y_pred_val = predict(X_val, w, b, threshold=0.5)\n",
        "y_pred_train = predict(X_train, w, b, threshold=0.5)\n",
        "\n",
        "# TODO: Calcule el accuracy de ambas predicciones\n",
        "train_acc = accuracy(y_val, y_pred_val)\n",
        "val_acc = accuracy(y_train, y_pred_train)\n",
        "\n",
        "print(f'accuracy: entrenamiento={train_acc:.5f}, validación={val_acc:.5f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: entrenamiento=1.00000, validación=1.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4DQRCj-NOPP"
      },
      "source": [
        "Ha culminado la implementación usando solamente operaciones sobre tensores. En la siguiente sección implementará el modelo usando métodos predefinidos de PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twdx7_ILPUS_"
      },
      "source": [
        "## Regresión logística usando métodos predefinidos (6 puntos)\n",
        "\n",
        "En esta sección, implementará el modelo usando métodos predefinidos de PyTorch. Es válido usar paquetes como `torch.nn` o `torch.optim`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKoXbNMvX448"
      },
      "source": [
        "### Importación de bibliotecas adicionales\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yz-eTryYCmV"
      },
      "source": [
        "from torch import nn  # paquete de capas y funciones de activación\n",
        "from torch import optim  # paquete de optimización"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouYm2q_aO9n0"
      },
      "source": [
        "### Conjunto de datos\n",
        "\n",
        "En esta parte usaremos la data sintética generada en la primera parte del trabajo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtltbmd3Yoqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf5ed3e2-d469-4417-d249-3af6ff283283"
      },
      "source": [
        "print('Tamaño original del dataset: ', X.shape)\n",
        "print('---------------------------')\n",
        "print('Tamaño de la data de entrenamiento: ', X_train.shape)\n",
        "print('Tamaño de la data de validación: ', X_val.shape)\n",
        "print('Tamaño de la data de prueba: ', X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño original del dataset:  torch.Size([1000, 2])\n",
            "---------------------------\n",
            "Tamaño de la data de entrenamiento:  torch.Size([600, 2])\n",
            "Tamaño de la data de validación:  torch.Size([200, 2])\n",
            "Tamaño de la data de prueba:  torch.Size([200, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kFRTByfZGQw"
      },
      "source": [
        "### Modelo (1.5 puntos)\n",
        "\n",
        "Para implementar el modelo, usaremos una capa lineal (`nn.Linear`) y la función de activación sigmoide (`nn.Sigmoid`). Ambos clases pueden ser accedidas a través del paquete `torch.nn`. Estas clases también se les conoce como módulos. En PyTorch, una red neuronal se construye a partir de módulos. Los módulos pueden contener otros módulos, y una red neuronal también se considera un módulo en sí. Recordemos que regresión logística puede ser representada como una red neuronal de una capa con varias entradas y una salida.\n",
        "\n",
        "La plantilla básica de un módulo es la siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8MJ7nMye22w"
      },
      "source": [
        "class MyModule(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # Aqui podemos definir otros módulos\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Aqui realizamos los cálculos con los módulos antes definidos\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4FV4P6wfLXq"
      },
      "source": [
        "La función forward es donde se realizan los cálculos del módulo, y se ejecuta cuando llama al módulo (`net = MyModule(); net(x)`). En la función init, generalmente creamos los parámetros del módulo, usando `nn.Parameter`, o definiendo otros módulos que se usan en la función forward como `nn.Linear`. El cálculo de propagación hacia atrás se realiza automáticamente, pero también se puede sobrescribir si se desea."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6d55YErftbV"
      },
      "source": [
        "#### Módulo de regresión logística\n",
        "\n",
        "Ahora podemos hacer uso de los módulos predefinidos en el paquete `torch.nn` y definir nuestro propio modelo de regresión logística como una red neuronal. Como lo indicado anteriormente, usaremos una capa lineal (`nn.Linear`) que representa la transformación afín, y la función de activación sigmoide (`nn.Sigmoid`). Ambos módulo serán usados dentro de un módulo general llamado `LogisticRegressionNetwork`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im12urGUgfaW"
      },
      "source": [
        "# Módulo de regresión logística que lo implementa como una red neuronal\n",
        "class LogisticRegressionNetwork(nn.Module):\n",
        "\n",
        "  def __init__(self, num_features, num_outputs):\n",
        "    \"\"\"\n",
        "      Constructor de la clase LogisticRegressionNetwork, que recibe dos parámetros\n",
        "      para la creación del modelo\n",
        "\n",
        "      Args: \n",
        "        - num_features: número de características de entrada (capa de entrada)\n",
        "        - num_outputs: número de neuronas salidas (capa de salida)\n",
        "\n",
        "      Returns:\n",
        "        No se retorna nada pero se definen los módulos respectivos\n",
        "    \"\"\" \n",
        "    super().__init__() # usado porque estamos heredando de la clase nn.Module\n",
        "    \n",
        "    # TODO: Definir un módulo Linear que represente la transformación afín\n",
        "    #       Aqui deberá usar los parámetros num_features y num_outputs\n",
        "    self.linear = nn.Linear(num_features,num_outputs)\n",
        "\n",
        "    # TODO: Definir un módulo Sigmoid que represente la función de activación\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, X):\n",
        "    \"\"\" \n",
        "      Este método realiza la propagación hacia adelante en una red neuronal.\n",
        "      En nuestro problema realizará las mismas operaciones del método model()\n",
        "      implementado en la primera parte de este trabajo\n",
        "\n",
        "      Args:\n",
        "        - X: tensor de dimensión (n, m), donde n es el número de datos y m\n",
        "            es el número de características\n",
        "      \n",
        "      Returns:\n",
        "        - y_pred: tensor de dimensión (n, 1), representando las predicciones\n",
        "                  con valores entre 0 y 1\n",
        "    \"\"\"   \n",
        "    # TODO: Usando las inicializaciones en el constructor (__init__) realice\n",
        "    #       la propagación hacia adelante. Es decir aplique self.linear para\n",
        "    #       la transformación afín y self.sigmoid para la función de activación\n",
        "    #       de self.sigmoid\n",
        "    y_pred = self.sigmoid(self.linear(X))\n",
        "\n",
        "    assert(y_pred.shape == (X.shape[0], 1))\n",
        "    return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5THYYXpkNAS"
      },
      "source": [
        "Usaremos el módulo implementado para modelar regresión logística. Para el conjunto de datos sintéticos el número de características es 2 y la salida es 1 ya que estamos trabajando con clasificación binaria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joEaFRB3khVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a66aa27-b068-43d4-8762-ca65e550faca"
      },
      "source": [
        "# Creamos una instancia del modelo\n",
        "model = LogisticRegressionNetwork(X.shape[1], 1)\n",
        "\n",
        "# Mostramos el modelo\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegressionNetwork(\n",
            "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwBHPN6EkrW0"
      },
      "source": [
        "La impresión del modelo enumera todos los submódulos que contiene. Los parámetros de un módulo se pueden obtener usando sus funciones `parameters()`, o `named_parameters()` para obtener un nombre para cada objeto de parámetro. Para nuestro modelo, tenemos los siguientes parámetros: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXCe6npNkKqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e05d2d-1db6-4989-eee3-5eaa5aea8dae"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "  print(\"Parámetro %s, shape %s\" % (name, str(param.shape)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parámetro linear.weight, shape torch.Size([1, 2])\n",
            "Parámetro linear.bias, shape torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMMOZiynlLXE"
      },
      "source": [
        "Cada capa lineal tiene una matriz de peso de la forma \"[salida, entrada]\", y un bias de la forma \"[salida]\". La función de activación sigmoide no tiene ningún parámetro. Notar que en la implementación manual de la primera parte, la matriz de pesos es de la forma \"[entrada, salida]\". Existen diferentes formas de representar los pesos, al final el problema se resuelve de la misma forma solo que con diferencias en las operaciones matriciales. Al usar PyTorch no tendremos que preocuparnos ya que esas operaciones se realizan internamente. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IiHLG4HmGE0"
      },
      "source": [
        "### Función de Pérdida (0.5 puntos)\n",
        "\n",
        "PyTorch proporciona una lista de funciones de pérdida predefinidas que podemos usar. Por ejemplo, para la entropía cruzada binaria BCE, PyTorch tiene dos módulos: `nn.BCELoss()`, `nn.BCEWithLogitsLoss()`. Mientras que `nn.BCELoss` espera que las entradas $x$ estén en el rango $[0,1]$, es decir, la salida de un sigmoide,`nn.BCEWithLogitsLoss` combina la capa sigmoide y la pérdida de BCE en una sola clase. Para el modelo previamente definido, usaremos el módulo `nn.BCELoss()` ya que la salida del modelo son probabilidades."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdLURPOdnrIY"
      },
      "source": [
        "# TODO: Definir el módulo de función de pérdida BCE\n",
        "loss_fn = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ1p5Cg5oTJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad117e22-498f-42d9-8d3a-11d70dfd6e37"
      },
      "source": [
        "# Probemos la implementación\n",
        "y_pred = model(X_train)\n",
        "print(\"Error actual: \", loss_fn(y_pred, y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error actual:  tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHiT55tOoK2Y"
      },
      "source": [
        "Como lo indicado anteriormente, es posible usar el módulo `nn.BCEWithLogitsLoss` que combina la función sigmoide con la función de pérdida BCE. En este caso nuestro módulo de regresión logística no necesitaría el submódulo `nn.Sigmoid`. La función `nn.BCEWithLogitsLoss` es más estable que `BCELoss` por lo que es más recomendable. Sin embargo, para fines de entender mejor el modelo y compararlo con la implementación de la primera parte, usamos `BCELoss`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23d63sNZq_8O"
      },
      "source": [
        "### Gradiente Descendente Estocástico (0.5 puntos)\n",
        "\n",
        "Para actualizar los parámetros, PyTorch proporciona el paquete `torch.optim` que tiene implementados los optimizadores más populares. En este trabajo se usará gradiente descendente (`optim.SGD`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AdykOzQrkz3"
      },
      "source": [
        "# TODO: Definir el optimizador SGD usando los parámetros del modelo y \n",
        "#       una tasa de aprendizaje de 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKCOjBLVsJSQ"
      },
      "source": [
        "### Entrenamiento (2 puntos)\n",
        "\n",
        "Del mismo modo a lo realizado en la primera parte, deberá implementar los métodos `train_step()` y `val_step()` para realizar las fases de entrenamiento y validación respectivamente. A diferencia de las implementaciones con tensores, aqui deberá usar el optimizador antes definido asi como el método `backward()` para el cálculo de gradientes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPID070gGhbN"
      },
      "source": [
        "#### Fase de Entrenamiento (1 punto)\n",
        "\n",
        "Durante esta fase se usará la data de entrenamiento `(X_train, y_train)`. En esta fase **actualizamos los parámetros del modelo** mediante gradiente descendente usando mini lotes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AROTYkUYsxGS"
      },
      "source": [
        "def train_step(X_train, y_train, model, loss_fn, optimizer, batch_size):\n",
        "  \"\"\"\n",
        "    Este método realiza la fase de entrenamiento usando la data de entrenamiento \n",
        "    (X_train, y_train) la que usaremos para actualizar los parámetros del modelo.\n",
        "\n",
        "    Args:\n",
        "      - X_train: tensor de dimensión (n, m), donde n es el número de \n",
        "            datos de entrenamiento y m es el número de características\n",
        "      - y_train: tensor de dimensión (n, 1), representando las etiquetas\n",
        "            reales de la data de entrenamiento\n",
        "      - model: modelo que recibe la data de entrada y devuelve probabilidades           \n",
        "      - loss_fn: función de pérdida\n",
        "      - optimizer: optimizador para la actualización de los parámetros\n",
        "      - batch_size: tamaño de cada lote\n",
        "      \n",
        "    Returns:\n",
        "      - train_loss: tensor de dimensión (1,), representando la pérdida de toda\n",
        "                    la data de entrenamiento\n",
        "  \"\"\"\n",
        "  n, m = X_train.shape\n",
        "\n",
        "  # Pérdida de entrenamiento total\n",
        "  train_loss = 0.\n",
        "\n",
        "  # Iteramos sobre todos los datos de entrenamiento usando mini lotes\n",
        "  for X, y in data_iter(X_train, y_train, batch_size):\n",
        "\n",
        "    # TODO: Obtener probabilidades del lote actual a partir del modelo \n",
        "    #       creado con nn.Module\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # TODO: Calcular la pérdida entre la predicción y valor real\n",
        "    loss = loss_fn(y_pred,y)\n",
        "\n",
        "    # TODO: Calcular las gradientes de la función de pérdida usando la función\n",
        "    #       backward()\n",
        "    loss.backward()\n",
        "\n",
        "    # TODO: Actualizar los parámetros con un paso de gradiente descendente usando\n",
        "    #       el optimizador sgd definido anteriormente.\n",
        "    optimizer.step()\n",
        "\n",
        "    # TODO: Establecer los gradientes en cero para que no se acumulen\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Acumulamos pérdida\n",
        "    train_loss += loss.item() * X_batch.shape[0]\n",
        "\n",
        "  # Pérdida promedio\n",
        "  train_loss /= n\n",
        "\n",
        "  return train_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZLmhWApMHWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d608fd4-f773-4ca9-f15e-13a9a0056d7c"
      },
      "source": [
        "# Probemos la implementación\n",
        "print(f'Error de entrenamiento: {train_step(X_train, y_train, model, loss_fn, optimizer, 32):.8f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error de entrenamiento: 0.30752805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwx-dm0vuZO9"
      },
      "source": [
        "#### Fase de Validación (0.5 puntos)\n",
        "\n",
        "En esta fase se usará la data de validación `(X_val, y_val)`. La validación se llevará a cabo en cada época, luego de la fase de entrenamiento. Recuerde que en la fase de validación **no actualizamos los parámetros**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtge8eiWMnbK"
      },
      "source": [
        "def validation_step(X_val, y_val, model, loss_fn, batch_size):\n",
        "  \"\"\"\n",
        "    Este método realiza la fase de validación usando la data de validación \n",
        "    (X_val, y_val) y los parámetros del modelo entrenado.\n",
        "\n",
        "    Args:\n",
        "      - X_val: tensor de dimensión (n_val, m), donde n_val es el número de \n",
        "            datos de validación y m es el número de características\n",
        "      - y_val: tensor de dimensión (n_val, 1), representando las etiquetas\n",
        "            reales de la data de validación \n",
        "            - model: modelo que recibe la data de entrada y devuelve logits\n",
        "      - model: modelo que recibe la data de entrada y devuelve probabilidades           \n",
        "      - loss_fn: función de pérdida\n",
        "      - batch_size: tamaño de cada lote\n",
        "\n",
        "    Returns:\n",
        "      - val_loss: pérdida de toda la data de validación\n",
        "  \"\"\"\n",
        "  n_val, m = X_val.shape\n",
        "  \n",
        "  # Pérdida de validación total\n",
        "  val_loss = 0.\n",
        "\n",
        "  # Debido a que en la fase de validación no actualizamos los parámetros\n",
        "  # no es necesario usar los gradientes\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Iteramos sobre todos los datos y mostramos el tamaño de cada lote\n",
        "    # No es necesario aleatorizar la data de validación\n",
        "    for X, y in data_iter(X_val, y_val, batch_size, False):\n",
        "\n",
        "      # TODO: Obtener probabilidades del lote actual a partir del modelo\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # TODO: Calcular la pérdida entre la predicción y valor real\n",
        "      loss = loss_fn(y_pred,y)\n",
        "      \n",
        "      # Acumulamos pérdida\n",
        "      val_loss += loss.item() * X.shape[0]\n",
        "\n",
        "  # Pérdida promedio\n",
        "  val_loss /= n_val\n",
        "\n",
        "  return val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmjjfkYfNJk_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc8e440-8dee-4eda-b159-eb7397b59cfc"
      },
      "source": [
        "# Probemos la implementación\n",
        "print(f'Error de validación: {validation_step(X_val, y_val, model, loss_fn, batch_size):.8f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error de validación: 0.31449990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAuZl4gfvoEU"
      },
      "source": [
        "#### Fase Principal (0.5 puntos)\n",
        "\n",
        "Ahora que tenemos todas las partes en su lugar, estamos listos para implementar el algoritmo de entrenamiento principal. A diferencia de la implementación de la primera parte, aqui adicionaremos la función de pérdida y el optimizador como parte de este método. El algoritmo está dado por lo siguiente:\n",
        "\n",
        "* Definir la función de pérdida\n",
        "* Definir el optimizador usando los parámetros del módelo\n",
        "* Iterar por un determinado número de épocas. Para cada época:\n",
        "    * Entrenar el modelo usando la data de entrenamiento\n",
        "    * Validar el modelo usando la data de validación\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LFf6BQvKIk7"
      },
      "source": [
        "def train_model(X_train, y_train, X_val, y_val, model, num_epochs, learning_rate, batch_size):\n",
        "  \"\"\"\n",
        "    Este método realiza el entrenamiento del modelo usando (X_train, y_train), y\n",
        "    valida los resultados con (X_val, y_val).\n",
        "\n",
        "    Args:\n",
        "      - X_train: tensor de dimensión (n, m), donde n es el número de \n",
        "            datos de entrenamiento y m es el número de características\n",
        "      - y_train: tensor de dimensión (n, 1), representando las etiquetas\n",
        "            reales de la data de entrenamiento     \n",
        "      - X_val: tensor de dimensión (n_val, m), donde n_val es el número de \n",
        "            datos de validación y m es el número de características\n",
        "      - y_val: tensor de dimensión (n_val, 1), representando las etiquetas\n",
        "            reales de la data de validación \n",
        "      - model: modelo que recibe la data de entrada y devuelve probabilidades            \n",
        "      - num_epochs: número de épocas\n",
        "      - learning_rate: tasa de aprendizaje\n",
        "      - batch_size: tamaño de cada lote\n",
        "\n",
        "    Returns:\n",
        "      No se retorna nada en este método\n",
        "  \"\"\"\n",
        "  n, m = X_train.shape\n",
        "\n",
        "  # TODO: Defina el módulo de función de pérdida BCELoss\n",
        "  loss_fn = nn.BCELoss()\n",
        "\n",
        "  # TODO: Defina el optimizador sgd usando los parámetros del modelo y\n",
        "  #       la tasa de aprendizaje\n",
        "  optimizer = torch.optim.SGD(model.parameters(),learning_rate)\n",
        "\n",
        "  # TODO: Itere sobre el número de épocas\n",
        "  for epoch in range(num_epochs):\n",
        "    # Fase de Entrenamiento\n",
        "    # TODO: Usar el método antes implementado para realizar el entrenamiento\n",
        "    train_loss = train_step(X_train, y_train, model, loss_fn, optimizer, batch_size)\n",
        "\n",
        "    # Fase de Validación\n",
        "    # TODO: Usar el método antes implementado para realizar la validación    \n",
        "    val_loss = validation_step(X_val, y_val, model, loss_fn, batch_size)\n",
        "\n",
        "    # Imprimimos el error\n",
        "    print(f'Epoch ({epoch+1}/{num_epochs}): train_loss = {train_loss:.8f}, val_loss= {val_loss:.8f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdoN-dWewpy_"
      },
      "source": [
        "Ahora probaremos la implementación, puede probar otros valores en los hiperparámetros que mejoren los resultados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epfSsdzAFBbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0104d089-23f4-4aba-dbd4-7c51c81bf987"
      },
      "source": [
        "# Hiperparámetros\n",
        "num_epochs = 500\n",
        "learning_rate = 0.1\n",
        "batch_size = 32\n",
        "\n",
        "# Creamos modelo\n",
        "model = LogisticRegressionNetwork(X.shape[1], 1)\n",
        "\n",
        "# Entrenamiento\n",
        "train_model(X_train, y_train, X_val, y_val, model, num_epochs, learning_rate, batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch (1/500): train_loss = 0.12214294, val_loss= 0.10316853\n",
            "Epoch (2/500): train_loss = 0.07194743, val_loss= 0.06943528\n",
            "Epoch (3/500): train_loss = 0.06239750, val_loss= 0.05769297\n",
            "Epoch (4/500): train_loss = 0.06007353, val_loss= 0.05686178\n",
            "Epoch (5/500): train_loss = 0.05869862, val_loss= 0.04981556\n",
            "Epoch (6/500): train_loss = 0.05745229, val_loss= 0.04858938\n",
            "Epoch (7/500): train_loss = 0.05379022, val_loss= 0.04872047\n",
            "Epoch (8/500): train_loss = 0.05393157, val_loss= 0.04399813\n",
            "Epoch (9/500): train_loss = 0.05368256, val_loss= 0.04831438\n",
            "Epoch (10/500): train_loss = 0.05124674, val_loss= 0.04150759\n",
            "Epoch (11/500): train_loss = 0.04881922, val_loss= 0.04065126\n",
            "Epoch (12/500): train_loss = 0.04893301, val_loss= 0.03964512\n",
            "Epoch (13/500): train_loss = 0.04998361, val_loss= 0.03996504\n",
            "Epoch (14/500): train_loss = 0.04666512, val_loss= 0.04294110\n",
            "Epoch (15/500): train_loss = 0.04619840, val_loss= 0.04124460\n",
            "Epoch (16/500): train_loss = 0.04815843, val_loss= 0.03756212\n",
            "Epoch (17/500): train_loss = 0.04869928, val_loss= 0.03873071\n",
            "Epoch (18/500): train_loss = 0.04488329, val_loss= 0.04214446\n",
            "Epoch (19/500): train_loss = 0.04615454, val_loss= 0.03510995\n",
            "Epoch (20/500): train_loss = 0.04539206, val_loss= 0.03465810\n",
            "Epoch (21/500): train_loss = 0.04651833, val_loss= 0.03442195\n",
            "Epoch (22/500): train_loss = 0.04505628, val_loss= 0.03392208\n",
            "Epoch (23/500): train_loss = 0.04485299, val_loss= 0.03506110\n",
            "Epoch (24/500): train_loss = 0.04552948, val_loss= 0.03294542\n",
            "Epoch (25/500): train_loss = 0.04353514, val_loss= 0.03250278\n",
            "Epoch (26/500): train_loss = 0.04689940, val_loss= 0.03421465\n",
            "Epoch (27/500): train_loss = 0.04492230, val_loss= 0.03593252\n",
            "Epoch (28/500): train_loss = 0.04076526, val_loss= 0.03945633\n",
            "Epoch (29/500): train_loss = 0.04657670, val_loss= 0.03487260\n",
            "Epoch (30/500): train_loss = 0.04262875, val_loss= 0.03147336\n",
            "Epoch (31/500): train_loss = 0.04163432, val_loss= 0.03159743\n",
            "Epoch (32/500): train_loss = 0.04319897, val_loss= 0.03294736\n",
            "Epoch (33/500): train_loss = 0.04256537, val_loss= 0.02979812\n",
            "Epoch (34/500): train_loss = 0.04102920, val_loss= 0.03441324\n",
            "Epoch (35/500): train_loss = 0.04098561, val_loss= 0.02937289\n",
            "Epoch (36/500): train_loss = 0.04282065, val_loss= 0.02895770\n",
            "Epoch (37/500): train_loss = 0.04259737, val_loss= 0.02873943\n",
            "Epoch (38/500): train_loss = 0.04234566, val_loss= 0.03022206\n",
            "Epoch (39/500): train_loss = 0.03905263, val_loss= 0.03087257\n",
            "Epoch (40/500): train_loss = 0.04036176, val_loss= 0.02829042\n",
            "Epoch (41/500): train_loss = 0.04000306, val_loss= 0.02783754\n",
            "Epoch (42/500): train_loss = 0.03909178, val_loss= 0.02790926\n",
            "Epoch (43/500): train_loss = 0.03890403, val_loss= 0.02725775\n",
            "Epoch (44/500): train_loss = 0.03908004, val_loss= 0.02741248\n",
            "Epoch (45/500): train_loss = 0.03926483, val_loss= 0.02745202\n",
            "Epoch (46/500): train_loss = 0.03820894, val_loss= 0.02691989\n",
            "Epoch (47/500): train_loss = 0.03788727, val_loss= 0.02674421\n",
            "Epoch (48/500): train_loss = 0.03756667, val_loss= 0.02750522\n",
            "Epoch (49/500): train_loss = 0.03643914, val_loss= 0.02689082\n",
            "Epoch (50/500): train_loss = 0.03739964, val_loss= 0.03265045\n",
            "Epoch (51/500): train_loss = 0.03644587, val_loss= 0.02580665\n",
            "Epoch (52/500): train_loss = 0.03783979, val_loss= 0.02554751\n",
            "Epoch (53/500): train_loss = 0.03586452, val_loss= 0.02520317\n",
            "Epoch (54/500): train_loss = 0.03590125, val_loss= 0.02741689\n",
            "Epoch (55/500): train_loss = 0.03572803, val_loss= 0.02709262\n",
            "Epoch (56/500): train_loss = 0.03684651, val_loss= 0.02642749\n",
            "Epoch (57/500): train_loss = 0.03506973, val_loss= 0.02738241\n",
            "Epoch (58/500): train_loss = 0.03594384, val_loss= 0.02438689\n",
            "Epoch (59/500): train_loss = 0.03507237, val_loss= 0.02388963\n",
            "Epoch (60/500): train_loss = 0.03520195, val_loss= 0.02387527\n",
            "Epoch (61/500): train_loss = 0.03432576, val_loss= 0.02351814\n",
            "Epoch (62/500): train_loss = 0.03313066, val_loss= 0.02371480\n",
            "Epoch (63/500): train_loss = 0.03378787, val_loss= 0.02625907\n",
            "Epoch (64/500): train_loss = 0.03345880, val_loss= 0.02344479\n",
            "Epoch (65/500): train_loss = 0.03174951, val_loss= 0.02301031\n",
            "Epoch (66/500): train_loss = 0.03375777, val_loss= 0.02659552\n",
            "Epoch (67/500): train_loss = 0.03359830, val_loss= 0.02409033\n",
            "Epoch (68/500): train_loss = 0.03310187, val_loss= 0.02226936\n",
            "Epoch (69/500): train_loss = 0.03010398, val_loss= 0.02450498\n",
            "Epoch (70/500): train_loss = 0.03272039, val_loss= 0.02288058\n",
            "Epoch (71/500): train_loss = 0.03127786, val_loss= 0.02183682\n",
            "Epoch (72/500): train_loss = 0.03042636, val_loss= 0.02267384\n",
            "Epoch (73/500): train_loss = 0.03240063, val_loss= 0.02149862\n",
            "Epoch (74/500): train_loss = 0.03122469, val_loss= 0.02343300\n",
            "Epoch (75/500): train_loss = 0.03284771, val_loss= 0.02657620\n",
            "Epoch (76/500): train_loss = 0.03152996, val_loss= 0.02158604\n",
            "Epoch (77/500): train_loss = 0.03126965, val_loss= 0.02101894\n",
            "Epoch (78/500): train_loss = 0.02992889, val_loss= 0.02088732\n",
            "Epoch (79/500): train_loss = 0.03037134, val_loss= 0.02070750\n",
            "Epoch (80/500): train_loss = 0.03200287, val_loss= 0.02109112\n",
            "Epoch (81/500): train_loss = 0.02951769, val_loss= 0.02034773\n",
            "Epoch (82/500): train_loss = 0.03150548, val_loss= 0.02061805\n",
            "Epoch (83/500): train_loss = 0.03025046, val_loss= 0.02005631\n",
            "Epoch (84/500): train_loss = 0.02994232, val_loss= 0.01992257\n",
            "Epoch (85/500): train_loss = 0.03087006, val_loss= 0.01974996\n",
            "Epoch (86/500): train_loss = 0.03064980, val_loss= 0.01988557\n",
            "Epoch (87/500): train_loss = 0.02957624, val_loss= 0.01982721\n",
            "Epoch (88/500): train_loss = 0.02959938, val_loss= 0.02003227\n",
            "Epoch (89/500): train_loss = 0.02894949, val_loss= 0.02113294\n",
            "Epoch (90/500): train_loss = 0.02774774, val_loss= 0.01982266\n",
            "Epoch (91/500): train_loss = 0.02872120, val_loss= 0.01893520\n",
            "Epoch (92/500): train_loss = 0.02962093, val_loss= 0.01908032\n",
            "Epoch (93/500): train_loss = 0.02758360, val_loss= 0.01882166\n",
            "Epoch (94/500): train_loss = 0.02767852, val_loss= 0.01860357\n",
            "Epoch (95/500): train_loss = 0.02735295, val_loss= 0.01843159\n",
            "Epoch (96/500): train_loss = 0.02641258, val_loss= 0.01831502\n",
            "Epoch (97/500): train_loss = 0.02738421, val_loss= 0.01818387\n",
            "Epoch (98/500): train_loss = 0.02733672, val_loss= 0.02048611\n",
            "Epoch (99/500): train_loss = 0.02803964, val_loss= 0.01801030\n",
            "Epoch (100/500): train_loss = 0.02602308, val_loss= 0.01780959\n",
            "Epoch (101/500): train_loss = 0.02671639, val_loss= 0.01770869\n",
            "Epoch (102/500): train_loss = 0.02615891, val_loss= 0.01765056\n",
            "Epoch (103/500): train_loss = 0.02626412, val_loss= 0.01753387\n",
            "Epoch (104/500): train_loss = 0.02535999, val_loss= 0.01739085\n",
            "Epoch (105/500): train_loss = 0.02546452, val_loss= 0.01876565\n",
            "Epoch (106/500): train_loss = 0.02586603, val_loss= 0.01715883\n",
            "Epoch (107/500): train_loss = 0.02565319, val_loss= 0.01702013\n",
            "Epoch (108/500): train_loss = 0.02485628, val_loss= 0.01698328\n",
            "Epoch (109/500): train_loss = 0.02594301, val_loss= 0.01681720\n",
            "Epoch (110/500): train_loss = 0.02653575, val_loss= 0.01743215\n",
            "Epoch (111/500): train_loss = 0.02501737, val_loss= 0.01678668\n",
            "Epoch (112/500): train_loss = 0.02419636, val_loss= 0.01670925\n",
            "Epoch (113/500): train_loss = 0.02423667, val_loss= 0.01688284\n",
            "Epoch (114/500): train_loss = 0.02477632, val_loss= 0.01638393\n",
            "Epoch (115/500): train_loss = 0.02459606, val_loss= 0.01676530\n",
            "Epoch (116/500): train_loss = 0.02450427, val_loss= 0.01629592\n",
            "Epoch (117/500): train_loss = 0.02506793, val_loss= 0.01622375\n",
            "Epoch (118/500): train_loss = 0.02466958, val_loss= 0.01590076\n",
            "Epoch (119/500): train_loss = 0.02331007, val_loss= 0.01601381\n",
            "Epoch (120/500): train_loss = 0.02469553, val_loss= 0.01574902\n",
            "Epoch (121/500): train_loss = 0.02328914, val_loss= 0.01562158\n",
            "Epoch (122/500): train_loss = 0.02506555, val_loss= 0.01554508\n",
            "Epoch (123/500): train_loss = 0.02253002, val_loss= 0.01549500\n",
            "Epoch (124/500): train_loss = 0.02424088, val_loss= 0.01541830\n",
            "Epoch (125/500): train_loss = 0.02207006, val_loss= 0.01703865\n",
            "Epoch (126/500): train_loss = 0.02375749, val_loss= 0.01551699\n",
            "Epoch (127/500): train_loss = 0.02301344, val_loss= 0.01526911\n",
            "Epoch (128/500): train_loss = 0.02283154, val_loss= 0.01558566\n",
            "Epoch (129/500): train_loss = 0.02379422, val_loss= 0.01640692\n",
            "Epoch (130/500): train_loss = 0.02283611, val_loss= 0.01506441\n",
            "Epoch (131/500): train_loss = 0.02148916, val_loss= 0.01476043\n",
            "Epoch (132/500): train_loss = 0.02163258, val_loss= 0.01489720\n",
            "Epoch (133/500): train_loss = 0.02120534, val_loss= 0.01677914\n",
            "Epoch (134/500): train_loss = 0.02122304, val_loss= 0.01471579\n",
            "Epoch (135/500): train_loss = 0.02190301, val_loss= 0.01549267\n",
            "Epoch (136/500): train_loss = 0.02187514, val_loss= 0.01489184\n",
            "Epoch (137/500): train_loss = 0.02132349, val_loss= 0.01429677\n",
            "Epoch (138/500): train_loss = 0.02120440, val_loss= 0.01416843\n",
            "Epoch (139/500): train_loss = 0.02076047, val_loss= 0.01406293\n",
            "Epoch (140/500): train_loss = 0.02207542, val_loss= 0.01444131\n",
            "Epoch (141/500): train_loss = 0.02118954, val_loss= 0.01417336\n",
            "Epoch (142/500): train_loss = 0.02052844, val_loss= 0.01388788\n",
            "Epoch (143/500): train_loss = 0.02186169, val_loss= 0.01381623\n",
            "Epoch (144/500): train_loss = 0.02125727, val_loss= 0.01398669\n",
            "Epoch (145/500): train_loss = 0.02096457, val_loss= 0.01366355\n",
            "Epoch (146/500): train_loss = 0.02017002, val_loss= 0.01363058\n",
            "Epoch (147/500): train_loss = 0.02044262, val_loss= 0.01363005\n",
            "Epoch (148/500): train_loss = 0.02180404, val_loss= 0.01419072\n",
            "Epoch (149/500): train_loss = 0.01966506, val_loss= 0.01405537\n",
            "Epoch (150/500): train_loss = 0.02066973, val_loss= 0.01383357\n",
            "Epoch (151/500): train_loss = 0.02004557, val_loss= 0.01333430\n",
            "Epoch (152/500): train_loss = 0.01977275, val_loss= 0.01334021\n",
            "Epoch (153/500): train_loss = 0.01920992, val_loss= 0.01396688\n",
            "Epoch (154/500): train_loss = 0.02023358, val_loss= 0.01301093\n",
            "Epoch (155/500): train_loss = 0.02045278, val_loss= 0.01300479\n",
            "Epoch (156/500): train_loss = 0.01960482, val_loss= 0.01362756\n",
            "Epoch (157/500): train_loss = 0.01945418, val_loss= 0.01276755\n",
            "Epoch (158/500): train_loss = 0.01948546, val_loss= 0.01262803\n",
            "Epoch (159/500): train_loss = 0.01925252, val_loss= 0.01299265\n",
            "Epoch (160/500): train_loss = 0.01994396, val_loss= 0.01295379\n",
            "Epoch (161/500): train_loss = 0.01948985, val_loss= 0.01272204\n",
            "Epoch (162/500): train_loss = 0.01875881, val_loss= 0.01372705\n",
            "Epoch (163/500): train_loss = 0.01948376, val_loss= 0.01226952\n",
            "Epoch (164/500): train_loss = 0.01898141, val_loss= 0.01266332\n",
            "Epoch (165/500): train_loss = 0.01842831, val_loss= 0.01286534\n",
            "Epoch (166/500): train_loss = 0.02004434, val_loss= 0.01222694\n",
            "Epoch (167/500): train_loss = 0.01878950, val_loss= 0.01248448\n",
            "Epoch (168/500): train_loss = 0.01812529, val_loss= 0.01269133\n",
            "Epoch (169/500): train_loss = 0.01917020, val_loss= 0.01334070\n",
            "Epoch (170/500): train_loss = 0.01899616, val_loss= 0.01258895\n",
            "Epoch (171/500): train_loss = 0.01893471, val_loss= 0.01349667\n",
            "Epoch (172/500): train_loss = 0.01820959, val_loss= 0.01334986\n",
            "Epoch (173/500): train_loss = 0.01929614, val_loss= 0.01169468\n",
            "Epoch (174/500): train_loss = 0.01839354, val_loss= 0.01296754\n",
            "Epoch (175/500): train_loss = 0.01809097, val_loss= 0.01157647\n",
            "Epoch (176/500): train_loss = 0.01780527, val_loss= 0.01188229\n",
            "Epoch (177/500): train_loss = 0.01726745, val_loss= 0.01161292\n",
            "Epoch (178/500): train_loss = 0.01866658, val_loss= 0.01155492\n",
            "Epoch (179/500): train_loss = 0.01761125, val_loss= 0.01131377\n",
            "Epoch (180/500): train_loss = 0.01722834, val_loss= 0.01206855\n",
            "Epoch (181/500): train_loss = 0.01733837, val_loss= 0.01132410\n",
            "Epoch (182/500): train_loss = 0.01714021, val_loss= 0.01169618\n",
            "Epoch (183/500): train_loss = 0.01734915, val_loss= 0.01133994\n",
            "Epoch (184/500): train_loss = 0.01867983, val_loss= 0.01460979\n",
            "Epoch (185/500): train_loss = 0.01791242, val_loss= 0.01204958\n",
            "Epoch (186/500): train_loss = 0.01785309, val_loss= 0.01102907\n",
            "Epoch (187/500): train_loss = 0.01650110, val_loss= 0.01090527\n",
            "Epoch (188/500): train_loss = 0.01734445, val_loss= 0.01088197\n",
            "Epoch (189/500): train_loss = 0.01684603, val_loss= 0.01362892\n",
            "Epoch (190/500): train_loss = 0.01747249, val_loss= 0.01081204\n",
            "Epoch (191/500): train_loss = 0.01708178, val_loss= 0.01091692\n",
            "Epoch (192/500): train_loss = 0.01605356, val_loss= 0.01090020\n",
            "Epoch (193/500): train_loss = 0.01654984, val_loss= 0.01057287\n",
            "Epoch (194/500): train_loss = 0.01689411, val_loss= 0.01052635\n",
            "Epoch (195/500): train_loss = 0.01639261, val_loss= 0.01050446\n",
            "Epoch (196/500): train_loss = 0.01653915, val_loss= 0.01074202\n",
            "Epoch (197/500): train_loss = 0.01633823, val_loss= 0.01047577\n",
            "Epoch (198/500): train_loss = 0.01686683, val_loss= 0.01041031\n",
            "Epoch (199/500): train_loss = 0.01627768, val_loss= 0.01032462\n",
            "Epoch (200/500): train_loss = 0.01635659, val_loss= 0.01029188\n",
            "Epoch (201/500): train_loss = 0.01593173, val_loss= 0.01062385\n",
            "Epoch (202/500): train_loss = 0.01734778, val_loss= 0.01021546\n",
            "Epoch (203/500): train_loss = 0.01590682, val_loss= 0.01009373\n",
            "Epoch (204/500): train_loss = 0.01613030, val_loss= 0.01013978\n",
            "Epoch (205/500): train_loss = 0.01573336, val_loss= 0.01025984\n",
            "Epoch (206/500): train_loss = 0.01586144, val_loss= 0.01022049\n",
            "Epoch (207/500): train_loss = 0.01650669, val_loss= 0.01038350\n",
            "Epoch (208/500): train_loss = 0.01539768, val_loss= 0.00988965\n",
            "Epoch (209/500): train_loss = 0.01592776, val_loss= 0.00982378\n",
            "Epoch (210/500): train_loss = 0.01571023, val_loss= 0.01009157\n",
            "Epoch (211/500): train_loss = 0.01573362, val_loss= 0.00979004\n",
            "Epoch (212/500): train_loss = 0.01506343, val_loss= 0.00967935\n",
            "Epoch (213/500): train_loss = 0.01518312, val_loss= 0.00980055\n",
            "Epoch (214/500): train_loss = 0.01553196, val_loss= 0.00971813\n",
            "Epoch (215/500): train_loss = 0.01487016, val_loss= 0.00955733\n",
            "Epoch (216/500): train_loss = 0.01581363, val_loss= 0.00984776\n",
            "Epoch (217/500): train_loss = 0.01515358, val_loss= 0.00961669\n",
            "Epoch (218/500): train_loss = 0.01533622, val_loss= 0.00956975\n",
            "Epoch (219/500): train_loss = 0.01548906, val_loss= 0.00941322\n",
            "Epoch (220/500): train_loss = 0.01499701, val_loss= 0.01048330\n",
            "Epoch (221/500): train_loss = 0.01514474, val_loss= 0.00957524\n",
            "Epoch (222/500): train_loss = 0.01490169, val_loss= 0.00926559\n",
            "Epoch (223/500): train_loss = 0.01460824, val_loss= 0.00925972\n",
            "Epoch (224/500): train_loss = 0.01513383, val_loss= 0.00918537\n",
            "Epoch (225/500): train_loss = 0.01461295, val_loss= 0.00929700\n",
            "Epoch (226/500): train_loss = 0.01450574, val_loss= 0.00909127\n",
            "Epoch (227/500): train_loss = 0.01482127, val_loss= 0.00912257\n",
            "Epoch (228/500): train_loss = 0.01449131, val_loss= 0.00903591\n",
            "Epoch (229/500): train_loss = 0.01440116, val_loss= 0.00898455\n",
            "Epoch (230/500): train_loss = 0.01418037, val_loss= 0.00911964\n",
            "Epoch (231/500): train_loss = 0.01419364, val_loss= 0.00889318\n",
            "Epoch (232/500): train_loss = 0.01491873, val_loss= 0.00897203\n",
            "Epoch (233/500): train_loss = 0.01452622, val_loss= 0.00980119\n",
            "Epoch (234/500): train_loss = 0.01350687, val_loss= 0.00952821\n",
            "Epoch (235/500): train_loss = 0.01414614, val_loss= 0.00935912\n",
            "Epoch (236/500): train_loss = 0.01387337, val_loss= 0.00914218\n",
            "Epoch (237/500): train_loss = 0.01405440, val_loss= 0.00865391\n",
            "Epoch (238/500): train_loss = 0.01375992, val_loss= 0.00861814\n",
            "Epoch (239/500): train_loss = 0.01386789, val_loss= 0.00859569\n",
            "Epoch (240/500): train_loss = 0.01342330, val_loss= 0.00893810\n",
            "Epoch (241/500): train_loss = 0.01380535, val_loss= 0.00897713\n",
            "Epoch (242/500): train_loss = 0.01377195, val_loss= 0.00877215\n",
            "Epoch (243/500): train_loss = 0.01379549, val_loss= 0.00854306\n",
            "Epoch (244/500): train_loss = 0.01354326, val_loss= 0.00850644\n",
            "Epoch (245/500): train_loss = 0.01349465, val_loss= 0.00916186\n",
            "Epoch (246/500): train_loss = 0.01399159, val_loss= 0.01026189\n",
            "Epoch (247/500): train_loss = 0.01375346, val_loss= 0.00903327\n",
            "Epoch (248/500): train_loss = 0.01371319, val_loss= 0.00985669\n",
            "Epoch (249/500): train_loss = 0.01406159, val_loss= 0.00863068\n",
            "Epoch (250/500): train_loss = 0.01302843, val_loss= 0.00827672\n",
            "Epoch (251/500): train_loss = 0.01381583, val_loss= 0.00820430\n",
            "Epoch (252/500): train_loss = 0.01310683, val_loss= 0.00819247\n",
            "Epoch (253/500): train_loss = 0.01396259, val_loss= 0.00844786\n",
            "Epoch (254/500): train_loss = 0.01327755, val_loss= 0.00859763\n",
            "Epoch (255/500): train_loss = 0.01337716, val_loss= 0.00829407\n",
            "Epoch (256/500): train_loss = 0.01321544, val_loss= 0.00819846\n",
            "Epoch (257/500): train_loss = 0.01322082, val_loss= 0.00816858\n",
            "Epoch (258/500): train_loss = 0.01312633, val_loss= 0.00808242\n",
            "Epoch (259/500): train_loss = 0.01286061, val_loss= 0.00827013\n",
            "Epoch (260/500): train_loss = 0.01315513, val_loss= 0.00842818\n",
            "Epoch (261/500): train_loss = 0.01352431, val_loss= 0.00802974\n",
            "Epoch (262/500): train_loss = 0.01308735, val_loss= 0.00823819\n",
            "Epoch (263/500): train_loss = 0.01281713, val_loss= 0.00786825\n",
            "Epoch (264/500): train_loss = 0.01275442, val_loss= 0.00781390\n",
            "Epoch (265/500): train_loss = 0.01282784, val_loss= 0.00774583\n",
            "Epoch (266/500): train_loss = 0.01249855, val_loss= 0.00784281\n",
            "Epoch (267/500): train_loss = 0.01252074, val_loss= 0.00782326\n",
            "Epoch (268/500): train_loss = 0.01229380, val_loss= 0.00830835\n",
            "Epoch (269/500): train_loss = 0.01259465, val_loss= 0.00815831\n",
            "Epoch (270/500): train_loss = 0.01258498, val_loss= 0.00761825\n",
            "Epoch (271/500): train_loss = 0.01258371, val_loss= 0.00755518\n",
            "Epoch (272/500): train_loss = 0.01253001, val_loss= 0.00769670\n",
            "Epoch (273/500): train_loss = 0.01220694, val_loss= 0.00764429\n",
            "Epoch (274/500): train_loss = 0.01269091, val_loss= 0.00767051\n",
            "Epoch (275/500): train_loss = 0.01268808, val_loss= 0.00832979\n",
            "Epoch (276/500): train_loss = 0.01247107, val_loss= 0.00755177\n",
            "Epoch (277/500): train_loss = 0.01234413, val_loss= 0.00785535\n",
            "Epoch (278/500): train_loss = 0.01215547, val_loss= 0.00736521\n",
            "Epoch (279/500): train_loss = 0.01206605, val_loss= 0.00792798\n",
            "Epoch (280/500): train_loss = 0.01216438, val_loss= 0.00730002\n",
            "Epoch (281/500): train_loss = 0.01240955, val_loss= 0.00763260\n",
            "Epoch (282/500): train_loss = 0.01231292, val_loss= 0.00772593\n",
            "Epoch (283/500): train_loss = 0.01204114, val_loss= 0.00733143\n",
            "Epoch (284/500): train_loss = 0.01222253, val_loss= 0.00728533\n",
            "Epoch (285/500): train_loss = 0.01171192, val_loss= 0.00753443\n",
            "Epoch (286/500): train_loss = 0.01229970, val_loss= 0.00715812\n",
            "Epoch (287/500): train_loss = 0.01231661, val_loss= 0.00717408\n",
            "Epoch (288/500): train_loss = 0.01208825, val_loss= 0.00744521\n",
            "Epoch (289/500): train_loss = 0.01204687, val_loss= 0.00853086\n",
            "Epoch (290/500): train_loss = 0.01208123, val_loss= 0.00736110\n",
            "Epoch (291/500): train_loss = 0.01157598, val_loss= 0.00710695\n",
            "Epoch (292/500): train_loss = 0.01159039, val_loss= 0.00701315\n",
            "Epoch (293/500): train_loss = 0.01138698, val_loss= 0.00708950\n",
            "Epoch (294/500): train_loss = 0.01156682, val_loss= 0.00711230\n",
            "Epoch (295/500): train_loss = 0.01162975, val_loss= 0.00722923\n",
            "Epoch (296/500): train_loss = 0.01198454, val_loss= 0.00688650\n",
            "Epoch (297/500): train_loss = 0.01162320, val_loss= 0.00692630\n",
            "Epoch (298/500): train_loss = 0.01153621, val_loss= 0.00703475\n",
            "Epoch (299/500): train_loss = 0.01204256, val_loss= 0.00681480\n",
            "Epoch (300/500): train_loss = 0.01167316, val_loss= 0.00684685\n",
            "Epoch (301/500): train_loss = 0.01215985, val_loss= 0.00739475\n",
            "Epoch (302/500): train_loss = 0.01141862, val_loss= 0.00705554\n",
            "Epoch (303/500): train_loss = 0.01164384, val_loss= 0.00672520\n",
            "Epoch (304/500): train_loss = 0.01146758, val_loss= 0.00696703\n",
            "Epoch (305/500): train_loss = 0.01132962, val_loss= 0.00675283\n",
            "Epoch (306/500): train_loss = 0.01114713, val_loss= 0.00746198\n",
            "Epoch (307/500): train_loss = 0.01145345, val_loss= 0.00703680\n",
            "Epoch (308/500): train_loss = 0.01108250, val_loss= 0.00677932\n",
            "Epoch (309/500): train_loss = 0.01192511, val_loss= 0.00716210\n",
            "Epoch (310/500): train_loss = 0.01135178, val_loss= 0.00717337\n",
            "Epoch (311/500): train_loss = 0.01140848, val_loss= 0.00686394\n",
            "Epoch (312/500): train_loss = 0.01158449, val_loss= 0.00671627\n",
            "Epoch (313/500): train_loss = 0.01107448, val_loss= 0.00690409\n",
            "Epoch (314/500): train_loss = 0.01091503, val_loss= 0.00650116\n",
            "Epoch (315/500): train_loss = 0.01137956, val_loss= 0.00651534\n",
            "Epoch (316/500): train_loss = 0.01107365, val_loss= 0.00680532\n",
            "Epoch (317/500): train_loss = 0.01079186, val_loss= 0.00641379\n",
            "Epoch (318/500): train_loss = 0.01108553, val_loss= 0.00691672\n",
            "Epoch (319/500): train_loss = 0.01109082, val_loss= 0.00654812\n",
            "Epoch (320/500): train_loss = 0.01081280, val_loss= 0.00659355\n",
            "Epoch (321/500): train_loss = 0.01061345, val_loss= 0.00638573\n",
            "Epoch (322/500): train_loss = 0.01127496, val_loss= 0.00632419\n",
            "Epoch (323/500): train_loss = 0.01078037, val_loss= 0.00693381\n",
            "Epoch (324/500): train_loss = 0.01082880, val_loss= 0.00647516\n",
            "Epoch (325/500): train_loss = 0.01052919, val_loss= 0.00652395\n",
            "Epoch (326/500): train_loss = 0.01080228, val_loss= 0.00621869\n",
            "Epoch (327/500): train_loss = 0.01117346, val_loss= 0.00624833\n",
            "Epoch (328/500): train_loss = 0.01099105, val_loss= 0.00650332\n",
            "Epoch (329/500): train_loss = 0.01056309, val_loss= 0.00615995\n",
            "Epoch (330/500): train_loss = 0.01089888, val_loss= 0.00627735\n",
            "Epoch (331/500): train_loss = 0.01029256, val_loss= 0.00691538\n",
            "Epoch (332/500): train_loss = 0.01088148, val_loss= 0.00655281\n",
            "Epoch (333/500): train_loss = 0.01041076, val_loss= 0.00705694\n",
            "Epoch (334/500): train_loss = 0.01041824, val_loss= 0.00614562\n",
            "Epoch (335/500): train_loss = 0.01007947, val_loss= 0.00604071\n",
            "Epoch (336/500): train_loss = 0.01075699, val_loss= 0.00632855\n",
            "Epoch (337/500): train_loss = 0.01054557, val_loss= 0.00630535\n",
            "Epoch (338/500): train_loss = 0.01036351, val_loss= 0.00609191\n",
            "Epoch (339/500): train_loss = 0.01046911, val_loss= 0.00620304\n",
            "Epoch (340/500): train_loss = 0.01033286, val_loss= 0.00612201\n",
            "Epoch (341/500): train_loss = 0.01044462, val_loss= 0.00594287\n",
            "Epoch (342/500): train_loss = 0.01068532, val_loss= 0.00613088\n",
            "Epoch (343/500): train_loss = 0.01002920, val_loss= 0.00592234\n",
            "Epoch (344/500): train_loss = 0.00993285, val_loss= 0.00720438\n",
            "Epoch (345/500): train_loss = 0.01030418, val_loss= 0.00624054\n",
            "Epoch (346/500): train_loss = 0.01039984, val_loss= 0.00614281\n",
            "Epoch (347/500): train_loss = 0.01001822, val_loss= 0.00619743\n",
            "Epoch (348/500): train_loss = 0.01007247, val_loss= 0.00628330\n",
            "Epoch (349/500): train_loss = 0.01051845, val_loss= 0.00625794\n",
            "Epoch (350/500): train_loss = 0.00990001, val_loss= 0.00585982\n",
            "Epoch (351/500): train_loss = 0.01013098, val_loss= 0.00572939\n",
            "Epoch (352/500): train_loss = 0.00989315, val_loss= 0.00573446\n",
            "Epoch (353/500): train_loss = 0.00985850, val_loss= 0.00573694\n",
            "Epoch (354/500): train_loss = 0.00949769, val_loss= 0.00583206\n",
            "Epoch (355/500): train_loss = 0.01002293, val_loss= 0.00568718\n",
            "Epoch (356/500): train_loss = 0.01011139, val_loss= 0.00569762\n",
            "Epoch (357/500): train_loss = 0.00994475, val_loss= 0.00601269\n",
            "Epoch (358/500): train_loss = 0.00973664, val_loss= 0.00572337\n",
            "Epoch (359/500): train_loss = 0.00971581, val_loss= 0.00630662\n",
            "Epoch (360/500): train_loss = 0.00989484, val_loss= 0.00572134\n",
            "Epoch (361/500): train_loss = 0.00990651, val_loss= 0.00616890\n",
            "Epoch (362/500): train_loss = 0.00966218, val_loss= 0.00603577\n",
            "Epoch (363/500): train_loss = 0.01007523, val_loss= 0.00567378\n",
            "Epoch (364/500): train_loss = 0.00966709, val_loss= 0.00550894\n",
            "Epoch (365/500): train_loss = 0.00999067, val_loss= 0.00551616\n",
            "Epoch (366/500): train_loss = 0.00981666, val_loss= 0.00565663\n",
            "Epoch (367/500): train_loss = 0.00950427, val_loss= 0.00594484\n",
            "Epoch (368/500): train_loss = 0.01029029, val_loss= 0.00594549\n",
            "Epoch (369/500): train_loss = 0.00947539, val_loss= 0.00545183\n",
            "Epoch (370/500): train_loss = 0.00970723, val_loss= 0.00550624\n",
            "Epoch (371/500): train_loss = 0.00962435, val_loss= 0.00542051\n",
            "Epoch (372/500): train_loss = 0.00946049, val_loss= 0.00569764\n",
            "Epoch (373/500): train_loss = 0.00991508, val_loss= 0.00591398\n",
            "Epoch (374/500): train_loss = 0.00922933, val_loss= 0.00535915\n",
            "Epoch (375/500): train_loss = 0.00928641, val_loss= 0.00533209\n",
            "Epoch (376/500): train_loss = 0.00963419, val_loss= 0.00567349\n",
            "Epoch (377/500): train_loss = 0.00941505, val_loss= 0.00554101\n",
            "Epoch (378/500): train_loss = 0.00927806, val_loss= 0.00532410\n",
            "Epoch (379/500): train_loss = 0.00949289, val_loss= 0.00563220\n",
            "Epoch (380/500): train_loss = 0.00944883, val_loss= 0.00535677\n",
            "Epoch (381/500): train_loss = 0.00954742, val_loss= 0.00586467\n",
            "Epoch (382/500): train_loss = 0.00918660, val_loss= 0.00521951\n",
            "Epoch (383/500): train_loss = 0.00924632, val_loss= 0.00536540\n",
            "Epoch (384/500): train_loss = 0.00955331, val_loss= 0.00538468\n",
            "Epoch (385/500): train_loss = 0.00928216, val_loss= 0.00547896\n",
            "Epoch (386/500): train_loss = 0.00934260, val_loss= 0.00545411\n",
            "Epoch (387/500): train_loss = 0.00930829, val_loss= 0.00543315\n",
            "Epoch (388/500): train_loss = 0.00903969, val_loss= 0.00585362\n",
            "Epoch (389/500): train_loss = 0.00920914, val_loss= 0.00522417\n",
            "Epoch (390/500): train_loss = 0.00935425, val_loss= 0.00527310\n",
            "Epoch (391/500): train_loss = 0.00926695, val_loss= 0.00519565\n",
            "Epoch (392/500): train_loss = 0.00914029, val_loss= 0.00521232\n",
            "Epoch (393/500): train_loss = 0.00925170, val_loss= 0.00505739\n",
            "Epoch (394/500): train_loss = 0.00933077, val_loss= 0.00511163\n",
            "Epoch (395/500): train_loss = 0.00912575, val_loss= 0.00546902\n",
            "Epoch (396/500): train_loss = 0.00897623, val_loss= 0.00505872\n",
            "Epoch (397/500): train_loss = 0.00913382, val_loss= 0.00525626\n",
            "Epoch (398/500): train_loss = 0.00896237, val_loss= 0.00499136\n",
            "Epoch (399/500): train_loss = 0.00909778, val_loss= 0.00507977\n",
            "Epoch (400/500): train_loss = 0.00903336, val_loss= 0.00496542\n",
            "Epoch (401/500): train_loss = 0.00940828, val_loss= 0.00521781\n",
            "Epoch (402/500): train_loss = 0.00879769, val_loss= 0.00520801\n",
            "Epoch (403/500): train_loss = 0.00890733, val_loss= 0.00523321\n",
            "Epoch (404/500): train_loss = 0.00891504, val_loss= 0.00522490\n",
            "Epoch (405/500): train_loss = 0.00895258, val_loss= 0.00508111\n",
            "Epoch (406/500): train_loss = 0.00853794, val_loss= 0.00493079\n",
            "Epoch (407/500): train_loss = 0.00900121, val_loss= 0.00499078\n",
            "Epoch (408/500): train_loss = 0.00863011, val_loss= 0.00500703\n",
            "Epoch (409/500): train_loss = 0.00871089, val_loss= 0.00482885\n",
            "Epoch (410/500): train_loss = 0.00875082, val_loss= 0.00491252\n",
            "Epoch (411/500): train_loss = 0.00891348, val_loss= 0.00498798\n",
            "Epoch (412/500): train_loss = 0.00871584, val_loss= 0.00487049\n",
            "Epoch (413/500): train_loss = 0.00841386, val_loss= 0.00478127\n",
            "Epoch (414/500): train_loss = 0.00862777, val_loss= 0.00518742\n",
            "Epoch (415/500): train_loss = 0.00862182, val_loss= 0.00496064\n",
            "Epoch (416/500): train_loss = 0.00855067, val_loss= 0.00515575\n",
            "Epoch (417/500): train_loss = 0.00884603, val_loss= 0.00500320\n",
            "Epoch (418/500): train_loss = 0.00878068, val_loss= 0.00499243\n",
            "Epoch (419/500): train_loss = 0.00848601, val_loss= 0.00483905\n",
            "Epoch (420/500): train_loss = 0.00864205, val_loss= 0.00473031\n",
            "Epoch (421/500): train_loss = 0.00842709, val_loss= 0.00475146\n",
            "Epoch (422/500): train_loss = 0.00859089, val_loss= 0.00493580\n",
            "Epoch (423/500): train_loss = 0.00864160, val_loss= 0.00476395\n",
            "Epoch (424/500): train_loss = 0.00847607, val_loss= 0.00499080\n",
            "Epoch (425/500): train_loss = 0.00830122, val_loss= 0.00480550\n",
            "Epoch (426/500): train_loss = 0.00856578, val_loss= 0.00467283\n",
            "Epoch (427/500): train_loss = 0.00856755, val_loss= 0.00470957\n",
            "Epoch (428/500): train_loss = 0.00821372, val_loss= 0.00505961\n",
            "Epoch (429/500): train_loss = 0.00853985, val_loss= 0.00523285\n",
            "Epoch (430/500): train_loss = 0.00874890, val_loss= 0.00470508\n",
            "Epoch (431/500): train_loss = 0.00838002, val_loss= 0.00476210\n",
            "Epoch (432/500): train_loss = 0.00839673, val_loss= 0.00503504\n",
            "Epoch (433/500): train_loss = 0.00840313, val_loss= 0.00460986\n",
            "Epoch (434/500): train_loss = 0.00828667, val_loss= 0.00453222\n",
            "Epoch (435/500): train_loss = 0.00836731, val_loss= 0.00453013\n",
            "Epoch (436/500): train_loss = 0.00831051, val_loss= 0.00489448\n",
            "Epoch (437/500): train_loss = 0.00821823, val_loss= 0.00467156\n",
            "Epoch (438/500): train_loss = 0.00828225, val_loss= 0.00456658\n",
            "Epoch (439/500): train_loss = 0.00820328, val_loss= 0.00468944\n",
            "Epoch (440/500): train_loss = 0.00827422, val_loss= 0.00466856\n",
            "Epoch (441/500): train_loss = 0.00812984, val_loss= 0.00514078\n",
            "Epoch (442/500): train_loss = 0.00837816, val_loss= 0.00470757\n",
            "Epoch (443/500): train_loss = 0.00814127, val_loss= 0.00454785\n",
            "Epoch (444/500): train_loss = 0.00811480, val_loss= 0.00449698\n",
            "Epoch (445/500): train_loss = 0.00802919, val_loss= 0.00470086\n",
            "Epoch (446/500): train_loss = 0.00808484, val_loss= 0.00446809\n",
            "Epoch (447/500): train_loss = 0.00810205, val_loss= 0.00457838\n",
            "Epoch (448/500): train_loss = 0.00825090, val_loss= 0.00436535\n",
            "Epoch (449/500): train_loss = 0.00809421, val_loss= 0.00449964\n",
            "Epoch (450/500): train_loss = 0.00801805, val_loss= 0.00435801\n",
            "Epoch (451/500): train_loss = 0.00820129, val_loss= 0.00442263\n",
            "Epoch (452/500): train_loss = 0.00785180, val_loss= 0.00496815\n",
            "Epoch (453/500): train_loss = 0.00787763, val_loss= 0.00431259\n",
            "Epoch (454/500): train_loss = 0.00815504, val_loss= 0.00433298\n",
            "Epoch (455/500): train_loss = 0.00791514, val_loss= 0.00427184\n",
            "Epoch (456/500): train_loss = 0.00792056, val_loss= 0.00437918\n",
            "Epoch (457/500): train_loss = 0.00776288, val_loss= 0.00438217\n",
            "Epoch (458/500): train_loss = 0.00801041, val_loss= 0.00434095\n",
            "Epoch (459/500): train_loss = 0.00770810, val_loss= 0.00463956\n",
            "Epoch (460/500): train_loss = 0.00820935, val_loss= 0.00441869\n",
            "Epoch (461/500): train_loss = 0.00795340, val_loss= 0.00434462\n",
            "Epoch (462/500): train_loss = 0.00770949, val_loss= 0.00433429\n",
            "Epoch (463/500): train_loss = 0.00776281, val_loss= 0.00459186\n",
            "Epoch (464/500): train_loss = 0.00760047, val_loss= 0.00514359\n",
            "Epoch (465/500): train_loss = 0.00813550, val_loss= 0.00475357\n",
            "Epoch (466/500): train_loss = 0.00772903, val_loss= 0.00463240\n",
            "Epoch (467/500): train_loss = 0.00765136, val_loss= 0.00418917\n",
            "Epoch (468/500): train_loss = 0.00778018, val_loss= 0.00416265\n",
            "Epoch (469/500): train_loss = 0.00781319, val_loss= 0.00421324\n",
            "Epoch (470/500): train_loss = 0.00774140, val_loss= 0.00465259\n",
            "Epoch (471/500): train_loss = 0.00770871, val_loss= 0.00519197\n",
            "Epoch (472/500): train_loss = 0.00785972, val_loss= 0.00461801\n",
            "Epoch (473/500): train_loss = 0.00781152, val_loss= 0.00483483\n",
            "Epoch (474/500): train_loss = 0.00762734, val_loss= 0.00407354\n",
            "Epoch (475/500): train_loss = 0.00782141, val_loss= 0.00408610\n",
            "Epoch (476/500): train_loss = 0.00773260, val_loss= 0.00457539\n",
            "Epoch (477/500): train_loss = 0.00782188, val_loss= 0.00459651\n",
            "Epoch (478/500): train_loss = 0.00797973, val_loss= 0.00423486\n",
            "Epoch (479/500): train_loss = 0.00745946, val_loss= 0.00406559\n",
            "Epoch (480/500): train_loss = 0.00777247, val_loss= 0.00431442\n",
            "Epoch (481/500): train_loss = 0.00793586, val_loss= 0.00448481\n",
            "Epoch (482/500): train_loss = 0.00743255, val_loss= 0.00468824\n",
            "Epoch (483/500): train_loss = 0.00747997, val_loss= 0.00401459\n",
            "Epoch (484/500): train_loss = 0.00774453, val_loss= 0.00403547\n",
            "Epoch (485/500): train_loss = 0.00744870, val_loss= 0.00425532\n",
            "Epoch (486/500): train_loss = 0.00781512, val_loss= 0.00412610\n",
            "Epoch (487/500): train_loss = 0.00734720, val_loss= 0.00424020\n",
            "Epoch (488/500): train_loss = 0.00741833, val_loss= 0.00406008\n",
            "Epoch (489/500): train_loss = 0.00770820, val_loss= 0.00407870\n",
            "Epoch (490/500): train_loss = 0.00732913, val_loss= 0.00441426\n",
            "Epoch (491/500): train_loss = 0.00748134, val_loss= 0.00409592\n",
            "Epoch (492/500): train_loss = 0.00753945, val_loss= 0.00391970\n",
            "Epoch (493/500): train_loss = 0.00770477, val_loss= 0.00422889\n",
            "Epoch (494/500): train_loss = 0.00731490, val_loss= 0.00390434\n",
            "Epoch (495/500): train_loss = 0.00735036, val_loss= 0.00407833\n",
            "Epoch (496/500): train_loss = 0.00715653, val_loss= 0.00388633\n",
            "Epoch (497/500): train_loss = 0.00735523, val_loss= 0.00390763\n",
            "Epoch (498/500): train_loss = 0.00732492, val_loss= 0.00415058\n",
            "Epoch (499/500): train_loss = 0.00758226, val_loss= 0.00466382\n",
            "Epoch (500/500): train_loss = 0.00737585, val_loss= 0.00407527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkyS3P5Pxci4"
      },
      "source": [
        "Como se puede observar, tanto el error de entrenamiento como el de validación comienzan a bajar, lo que nos indica que el entrenamiento se esta realizando de forma correcta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vxeeRbVxfbz"
      },
      "source": [
        "### Predicción (0.5 puntos)\n",
        "\n",
        "Las predicciones actuales son probabilidades. Sin embargo, en clasificación estamos interesados en valores discretos, en este caso nos interesan valores 0 y 1. Por lo tanto, podemos usar un threshold, si las probabilidades de predicción son mayores que ese threshold entonces clasificamos esos datos como clase 1 sino como clase 0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV0Dw7y3xkwc"
      },
      "source": [
        "def predict(X, model, threshold=0.5):\n",
        "  \"\"\" \n",
        "     Este método predice si la etiqueta es 0 o 1 utilizando los parámetros\n",
        "     del modelo (w, b) y un threshold\n",
        "\n",
        "    Args:\n",
        "      - X: tensor de dimensión (n x m), donde n es el número de datos y m\n",
        "           es el número de características\n",
        "      - model: modelo que recibe la data de entrada y devuelve probabilidades\n",
        "      - threshold: umbral para obtener valores discretos a partir de probabilidades\n",
        "\n",
        "    Returns:\n",
        "      - y_pred: tensor de dimensión (n x 1), representando las predicciones\n",
        "                con valores 0 o 1. No probabilidades.\n",
        "  \"\"\"    \n",
        "  # Debido a que en esta fase no actualizamos los parámetros\n",
        "  # no es necesario usar los gradientes\n",
        "  with torch.no_grad():\n",
        "    #TODO: Obtenga probabilidades a partir del modelo\n",
        "    y_prob = model(X)\n",
        "\n",
        "    #TODO: Convierta las probabilidades en 0 (si activación < threshold) o \n",
        "    # 1 (si activación >= threshold), almacenar las predicciones en un tensor y_pred\n",
        "    #      Se recomienda implementar la versión vectorizada (sin bucles)\n",
        "    y_pred = torch.where(y_prob<threshold,0,1)\n",
        "  \n",
        "  assert(y_pred.shape == y_prob.shape)\n",
        "  return y_pred "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc6sqlBNGTlZ"
      },
      "source": [
        "# Probemos la implementación\n",
        "y_pred_val = predict(X_val, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDI3e_KDxwtI"
      },
      "source": [
        "Podemos visualizar el límite de decisión, para ello será necesario acceder a los pesos y bias del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu8Di2Mmx1bM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "54260791-1f89-4e2e-e882-6bc00acb5bbe"
      },
      "source": [
        "# Accedemos a los pesos y bias, cambiamos las dimensinoes de los pesos acorde\n",
        "# a la implementación inicial\n",
        "w_model = model.linear.weight.reshape(-1, 1).detach()\n",
        "b_model = model.linear.bias.detach()\n",
        "plot_decision_boundary(X_val, y_pred_val, w_model, b_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bphOjgZdzvcx"
      },
      "source": [
        "### Métrica de Evaluación (0.5 puntos)\n",
        "\n",
        "La implementación realizada en la primera parte es válida para esta sección. Por lo tanto, solo deberá usar el método 'accuracy' para mostrar los resultados finales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L05EGdS9z70j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef5c7ae-4a01-4dcd-b471-cf26d1cb34a0"
      },
      "source": [
        "# TODO: Obtenga predicciones discretas para la data entrenamiento y validación\n",
        "y_pred_val = predict(X_val, model)\n",
        "y_pred_train = predict(X_train, model)\n",
        "\n",
        "# TODO: Calcule el accuracy de ambas predicciones\n",
        "train_acc = accuracy(y_val,y_pred_val)\n",
        "val_acc = accuracy(y_train,y_pred_train)\n",
        "\n",
        "print(f'accuracy: entrenamiento={train_acc:.5f}, validación={val_acc:.5f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: entrenamiento=1.00000, validación=1.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2qMijMWCKt1"
      },
      "source": [
        "Podemos observar que el accuracy es perfecto debido a que el conjunto de datos sintético es linealmente separable y es fácil de clasificar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xTopmGh1IOk"
      },
      "source": [
        "### Prueba Final (0.5 puntos)\n",
        "\n",
        "Es momento de realizar predicciones finales para la data de prueba (test)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXmfnq-D1WCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a72d3d21-62ce-43dc-c007-6d5b3525c909"
      },
      "source": [
        "# TODO: Obtenga predicciones discretas para la data de prueba\n",
        "y_pred_test = predict(X_test, model)\n",
        "\n",
        "# TODO: Calcule el accuracy de la data de prueba\n",
        "test_acc = accuracy(y_test,y_pred_test)\n",
        "\n",
        "print(f'Accuracy de data de prueba={test_acc:.5f}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy de data de prueba=0.99500\n"
          ]
        }
      ]
    }
  ]
}