{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DeepHistory_Tesis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4FzgANMFnD0K"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1aabc06e03ae4e699c7cd2008eb5b1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8493a1db269d4f28a6b5a6e8f3a243ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91a33121db5f4eafb183b3a60ad90cb0",
              "IPY_MODEL_775cf6ec27004db38ff76bdb1a96149e",
              "IPY_MODEL_89c04f9d3e564d389493954efbd1c9bc"
            ]
          }
        },
        "8493a1db269d4f28a6b5a6e8f3a243ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91a33121db5f4eafb183b3a60ad90cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c896ec58a76d4fd888ddca4bd88e96d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_441acecba76f47aa93fc947d0961669e"
          }
        },
        "775cf6ec27004db38ff76bdb1a96149e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_21f24be10e554411804c8e767655c09d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5946721611664a6690e9a018a61f1eea"
          }
        },
        "89c04f9d3e564d389493954efbd1c9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b9acc735ebe4de989996a5e7f98d69b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:05&lt;00:00, 112MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06a1fca76d99417bae2bff62fa792446"
          }
        },
        "c896ec58a76d4fd888ddca4bd88e96d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "441acecba76f47aa93fc947d0961669e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21f24be10e554411804c8e767655c09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5946721611664a6690e9a018a61f1eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b9acc735ebe4de989996a5e7f98d69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06a1fca76d99417bae2bff62fa792446": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/Malvodio/DeepHistory/blob/main/DeepHistory_Tesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeepHistory_Tesis"
      ],
      "metadata": {
        "id": "wEmy83_5Pjim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Re-entrenamiento del modelo"
      ],
      "metadata": {
        "id": "02v7XclydwEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Iniciando enviroment"
      ],
      "metadata": {
        "id": "C7w7AbU8INz4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o5Cn9_JrFSm",
        "outputId": "2fddf0d7-a374-4ee2-a1cd-8fce11d645b7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cd drive/MyDrive/"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMih_D4ybBaV",
        "outputId": "2a9d5a70-4c8e-441f-e70f-9d8f1c414ea2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Clonando repositorio FOM\r\n",
        "!git clone https://github.com/Malvodio/DeepHistory"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'first-order-model'...\n",
            "remote: Enumerating objects: 299, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 299 (delta 2), reused 2 (delta 0), pack-reused 293\u001b[K\n",
            "Receiving objects: 100% (299/299), 72.15 MiB | 20.21 MiB/s, done.\n",
            "Resolving deltas: 100% (153/153), done.\n",
            "Checking out files: 100% (47/47), done.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMlIRZIUd5lv",
        "outputId": "13ec7c61-660a-4c98-8600-eb5f8411ef28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cambiando a repositorio First Order Model"
      ],
      "metadata": {
        "id": "ymwLxTGF7Stf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cd DeepHistory/"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/first-order-model\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkDffz4xJVG_",
        "outputId": "0b0b1f83-c013-4dc9-b247-429bd7716a74"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Instalando requerimientos de repositorio First Order Model\r\n",
        "# !pip install -r requirements.txt\r\n",
        "# !pip install imgaug==0.2.5\r\n",
        "# !pip install scikit-image==0.17.2"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inicializando cuda y llamando librerias"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Verificando dispositivo GPU\r\n",
        "import torch\r\n",
        "\r\n",
        "torch.cuda.get_device_name(0)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla K80'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "metadata": {
        "id": "4onrFmZFmSHG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ca7f4a9e-bfa9-419a-f841-d3f159c4e295"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este punto, se debe subir el modelo pre-entrenado VOX a la ruta first-order-model/models, además se debe editar el archivo vox-adv-256.yaml y configurar un batch_size de 10"
      ],
      "metadata": {
        "id": "RbyARU1nm2Vp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Importando librerías necesarias para el re-entrenamiento\r\n",
        "from os import path, makedirs\r\n",
        "from shutil import copy\r\n",
        "import imageio\r\n",
        "import numpy as np\r\n",
        "import sys\r\n",
        "import uuid\r\n",
        "import yaml\r\n",
        "import torch\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.animation as animation\r\n",
        "import warnings\r\n",
        "from time import gmtime, strftime\r\n",
        "from skimage import img_as_ubyte\r\n",
        "from ctypes import cdll\r\n",
        "from train import train\r\n",
        "from modules.generator import OcclusionAwareGenerator\r\n",
        "from modules.discriminator import MultiScaleDiscriminator\r\n",
        "from modules.keypoint_detector import KPDetector\r\n",
        "from frames_dataset import FramesDataset\r\n",
        "from modules.util import DownBlock2d\r\n",
        "from tqdm import trange\r\n",
        "import torch\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from logger import Logger\r\n",
        "from modules.model import GeneratorFullModel, DiscriminatorFullModel\r\n",
        "from torch.optim.lr_scheduler import MultiStepLR\r\n",
        "from sync_batchnorm import DataParallelWithCallback\r\n",
        "from frames_dataset import DatasetRepeater\r\n",
        "from demo import load_checkpoints, make_animation, load_checkpoints_Unet_3"
      ],
      "outputs": [],
      "metadata": {
        "id": "mPKK7u7UnK0Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\"\"\"\r\n",
        "checkpoint_path = './models/vox-adv-cpk.pth.tar'\r\n",
        "config_path = './config/vox-adv-256.yaml'\r\n",
        "generator2, kp_detector2 = load_checkpoints(config_path,checkpoint_path)\r\n",
        "print(kp_detector2)\r\n",
        "\"\"\""
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#generator_new, kp_detector_new = load_checkpoints_Unet_3(config_path,checkpoint_path)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Re-definiendo función para cargar el checkpoint del modelo pre-entrenado"
      ],
      "metadata": {
        "id": "--FXe5wCnfh6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def load_cpk(checkpoint_path, generator=None, discriminator=None, kp_detector=None,\r\n",
        "                 optimizer_generator=None, optimizer_discriminator=None, optimizer_kp_detector=None):\r\n",
        "    checkpoint = torch.load(checkpoint_path)\r\n",
        "    if generator is not None:\r\n",
        "        generator.load_state_dict(checkpoint['generator'])\r\n",
        "    if kp_detector is not None:\r\n",
        "        kp_detector.load_state_dict(checkpoint['kp_detector'])\r\n",
        "    if discriminator is not None:\r\n",
        "        try:\r\n",
        "            discriminator.load_state_dict(checkpoint['discriminator'])\r\n",
        "        except:\r\n",
        "            print ('No discriminator in the state-dict. Dicriminator will be randomly initialized')\r\n",
        "\r\n",
        "   # print(kp_detector)\r\n",
        "    \r\n",
        "    if optimizer_generator is not None:\r\n",
        "        optimizer_generator.load_state_dict(checkpoint['optimizer_generator'])\r\n",
        "    if optimizer_discriminator is not None:\r\n",
        "        try:\r\n",
        "            optimizer_discriminator.load_state_dict(checkpoint['optimizer_discriminator'])\r\n",
        "        except RuntimeError as e:\r\n",
        "            print ('No discriminator optimizer in the state-dict. Optimizer will be not initialized')\r\n",
        "    if optimizer_kp_detector is not None:\r\n",
        "        optimizer_kp_detector.load_state_dict(checkpoint['optimizer_kp_detector'])\r\n",
        "\r\n",
        "    return checkpoint['epoch']"
      ],
      "outputs": [],
      "metadata": {
        "id": "ViDibqOrnZP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo Arquitectura UNET"
      ],
      "metadata": {
        "id": "2LJ0IsB4n1BJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "config = './config/vox-adv-256.yaml'\r\n",
        "device_ids = [0]\r\n",
        "#checkpoint = './models/vox-adv-cpk.pth.tar'\r\n",
        "checkpoint = None\r\n",
        "log_dir = './logs'\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    \r\n",
        "    with open(config) as f:\r\n",
        "        config = yaml.load(f)\r\n",
        "        \r\n",
        "    generator = OcclusionAwareGenerator(**config['model_params']['generator_params'], **config['model_params']['common_params'])\r\n",
        "\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        generator.to(device_ids[0])\r\n",
        "\r\n",
        "    discriminator = MultiScaleDiscriminator(**config['model_params']['discriminator_params'], **config['model_params']['common_params'])\r\n",
        "\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        discriminator.to(device_ids[0])\r\n",
        "\r\n",
        "    kp_detector = KPDetector(**config['model_params']['kp_detector_params'], **config['model_params']['common_params'])\r\n",
        "\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        kp_detector.to(device_ids[0])\r\n",
        "            \r\n",
        "    dataset = FramesDataset(is_train=1, **config['dataset_params'])\r\n",
        "\r\n",
        "\r\n",
        "    print(\"Training...\")\r\n",
        "\r\n",
        "    train_params = config['train_params']\r\n",
        "\r\n",
        "    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=train_params['lr_generator'], betas=(0.5, 0.999))\r\n",
        "    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=train_params['lr_discriminator'], betas=(0.5, 0.999))\r\n",
        "    optimizer_kp_detector = torch.optim.Adam(kp_detector.parameters(), lr=train_params['lr_kp_detector'], betas=(0.5, 0.999))\r\n",
        "\r\n",
        "    if checkpoint is not None:\r\n",
        "        start_epoch = load_cpk(checkpoint, generator, discriminator, kp_detector, optimizer_generator, optimizer_discriminator, None if train_params['lr_kp_detector'] == 0 else optimizer_kp_detector)\r\n",
        "    else:\r\n",
        "        start_epoch = 0\r\n",
        "    \r\n",
        "    # Changes\r\n",
        "    #kp_detector.predictor.encoder.down_blocks[0].conv.kernel_size = (5, 4)\r\n",
        "    #kp_detector.predictor.encoder.down_blocks[1].conv.kernel_size = (5, 4)\r\n",
        "    #kp_detector.predictor.encoder.down_blocks[2].conv.kernel_size = (5, 4)\r\n",
        "    #kp_detector.predictor.encoder.down_blocks[3].conv.kernel_size = (5, 4)\r\n",
        "    #kp_detector.predictor.encoder.down_blocks[4].conv.kernel_size = (4, 4)\r\n",
        "    #print(kp_detector.predictor.encoder)\r\n",
        "    # End Changes\r\n",
        "\r\n",
        "    scheduler_generator = MultiStepLR(optimizer_generator, train_params['epoch_milestones'], gamma=0.1, last_epoch=start_epoch - 1)\r\n",
        "\r\n",
        "    scheduler_discriminator = MultiStepLR(optimizer_discriminator, train_params['epoch_milestones'], gamma=0.1, last_epoch=start_epoch - 1)\r\n",
        "\r\n",
        "    scheduler_kp_detector = MultiStepLR(optimizer_kp_detector, train_params['epoch_milestones'], gamma=0.1, last_epoch=-1 + start_epoch * (train_params['lr_kp_detector'] != 0))\r\n",
        "\r\n",
        "    if 'num_repeats' in train_params or train_params['num_repeats'] != 1:\r\n",
        "        dataset = DatasetRepeater(dataset, train_params['num_repeats'])\r\n",
        "\r\n",
        "    dataloader = DataLoader(dataset, batch_size=train_params['batch_size'], shuffle=True, num_workers=6, drop_last=True)\r\n",
        "\r\n",
        "    generator_full = GeneratorFullModel(kp_detector, generator, discriminator, train_params)\r\n",
        "    discriminator_full = DiscriminatorFullModel(kp_detector, generator, discriminator, train_params)\r\n",
        "\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        generator_full = DataParallelWithCallback(generator_full, device_ids=device_ids)\r\n",
        "        discriminator_full = DataParallelWithCallback(discriminator_full, device_ids=device_ids)\r\n",
        "\r\n",
        "    with Logger(log_dir=log_dir, visualizer_params=config['visualizer_params'], checkpoint_freq=train_params['checkpoint_freq']) as logger:\r\n",
        "        for epoch in trange(start_epoch, train_params['num_epochs']):\r\n",
        "            for x in dataloader:\r\n",
        "                #print(dataloader)\r\n",
        "                losses_generator, generated = generator_full(x)\r\n",
        "\r\n",
        "                loss_values = [val.mean() for val in losses_generator.values()]\r\n",
        "                loss = sum(loss_values)\r\n",
        "\r\n",
        "                loss.backward()\r\n",
        "                optimizer_generator.step()\r\n",
        "                optimizer_generator.zero_grad()\r\n",
        "                optimizer_kp_detector.step()\r\n",
        "                optimizer_kp_detector.zero_grad()\r\n",
        "\r\n",
        "                if train_params['loss_weights']['generator_gan'] != 0:\r\n",
        "                    optimizer_discriminator.zero_grad()\r\n",
        "                    losses_discriminator = discriminator_full(x, generated)\r\n",
        "                    loss_values = [val.mean() for val in losses_discriminator.values()]\r\n",
        "                    loss = sum(loss_values)\r\n",
        "\r\n",
        "                    loss.backward()\r\n",
        "                    optimizer_discriminator.step()\r\n",
        "                    optimizer_discriminator.zero_grad()\r\n",
        "                else:\r\n",
        "                    losses_discriminator = {}\r\n",
        "\r\n",
        "                losses_generator.update(losses_discriminator)\r\n",
        "                losses = {key: value.mean().detach().data.cpu().numpy() for key, value in losses_generator.items()}\r\n",
        "                logger.log_iter(losses=losses)\r\n",
        "\r\n",
        "            scheduler_generator.step()\r\n",
        "            scheduler_discriminator.step()\r\n",
        "            scheduler_kp_detector.step()\r\n",
        "            \r\n",
        "            logger.log_epoch(epoch, {'generator': generator, 'discriminator': discriminator, 'kp_detector': kp_detector, 'optimizer_generator': optimizer_generator, 'optimizer_discriminator': optimizer_discriminator, 'optimizer_kp_detector': optimizer_kp_detector}, inp=x, out=generated)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use predefined train-test split.\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1aabc06e03ae4e699c7cd2008eb5b1df",
              "version_minor": 0,
              "version_major": 2
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [14:45<00:00, 88.59s/it]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "1aabc06e03ae4e699c7cd2008eb5b1df",
            "8493a1db269d4f28a6b5a6e8f3a243ea",
            "91a33121db5f4eafb183b3a60ad90cb0",
            "775cf6ec27004db38ff76bdb1a96149e",
            "89c04f9d3e564d389493954efbd1c9bc",
            "c896ec58a76d4fd888ddca4bd88e96d5",
            "441acecba76f47aa93fc947d0961669e",
            "21f24be10e554411804c8e767655c09d",
            "5946721611664a6690e9a018a61f1eea",
            "8b9acc735ebe4de989996a5e7f98d69b",
            "06a1fca76d99417bae2bff62fa792446"
          ]
        },
        "id": "XNsmwmeCnucw",
        "outputId": "bd662c61-863f-4c85-f666-31cda23dee3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo Arquitectura UNET 3 +"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "config = './config/prueba.yaml'\r\n",
        "device_ids = [0]\r\n",
        "#checkpoint = './models/vox-adv-cpk.pth.tar'\r\n",
        "checkpoint = None\r\n",
        "log_dir = './logs'\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    \r\n",
        "    with open(config) as f:\r\n",
        "        config = yaml.load(f)\r\n",
        "        \r\n",
        "    generator = OcclusionAwareGenerator(**config['model_params']['generator_params'], **config['model_params']['common_params'])\r\n",
        "\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        generator.to(device_ids[0])\r\n",
        "\r\n",
        "    discriminator = MultiScaleDiscriminator(**config['model_params']['discriminator_params'], **config['model_params']['common_params'])\r\n",
        "\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        discriminator.to(device_ids[0])\r\n",
        "\r\n",
        "    kp_detector = KPDetector(**config['model_params']['kp_detector_params'], **config['model_params']['common_params'])\r\n",
        "\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        kp_detector.to(device_ids[0])\r\n",
        "            \r\n",
        "    dataset = FramesDataset(is_train=1, **config['dataset_params'])\r\n",
        "\r\n",
        "    print(\"Training...\")\r\n",
        "\r\n",
        "    train_params = config['train_params']\r\n",
        "\r\n",
        "    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=train_params['lr_generator'], betas=(0.5, 0.999))\r\n",
        "    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=train_params['lr_discriminator'], betas=(0.5, 0.999))\r\n",
        "    optimizer_kp_detector = torch.optim.Adam(kp_detector.parameters(), lr=train_params['lr_kp_detector'], betas=(0.5, 0.999))\r\n",
        "\r\n",
        "    if checkpoint is not None:\r\n",
        "        start_epoch = load_cpk(checkpoint, generator, discriminator, kp_detector, optimizer_generator, optimizer_discriminator, None if train_params['lr_kp_detector'] == 0 else optimizer_kp_detector)\r\n",
        "    else:\r\n",
        "        start_epoch = 0\r\n",
        "\r\n",
        "    scheduler_generator = MultiStepLR(optimizer_generator, train_params['epoch_milestones'], gamma=0.1, last_epoch=start_epoch - 1)\r\n",
        "\r\n",
        "    scheduler_discriminator = MultiStepLR(optimizer_discriminator, train_params['epoch_milestones'], gamma=0.1, last_epoch=start_epoch - 1)\r\n",
        "\r\n",
        "    scheduler_kp_detector = MultiStepLR(optimizer_kp_detector, train_params['epoch_milestones'], gamma=0.1, last_epoch=-1 + start_epoch * (train_params['lr_kp_detector'] != 0))\r\n",
        "\r\n",
        "    if 'num_repeats' in train_params or train_params['num_repeats'] != 1:\r\n",
        "        dataset = DatasetRepeater(dataset, train_params['num_repeats'])\r\n",
        "\r\n",
        "    dataloader = DataLoader(dataset, batch_size=train_params['batch_size'], shuffle=True, num_workers=6, drop_last=True)\r\n",
        "\r\n",
        "    generator_full = GeneratorFullModel(kp_detector, generator, discriminator, train_params)\r\n",
        "    discriminator_full = DiscriminatorFullModel(kp_detector, generator, discriminator, train_params)\r\n",
        "\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        generator_full = DataParallelWithCallback(generator_full, device_ids=device_ids)\r\n",
        "        discriminator_full = DataParallelWithCallback(discriminator_full, device_ids=device_ids)\r\n",
        "\r\n",
        "    with Logger(log_dir=log_dir, visualizer_params=config['visualizer_params'], checkpoint_freq=train_params['checkpoint_freq']) as logger:\r\n",
        "        for epoch in trange(start_epoch, train_params['num_epochs']):\r\n",
        "            for x in dataloader:\r\n",
        "                #print(dataloader)\r\n",
        "                losses_generator, generated = generator_full(x)\r\n",
        "\r\n",
        "                loss_values = [val.mean() for val in losses_generator.values()]\r\n",
        "                loss = sum(loss_values)\r\n",
        "\r\n",
        "                loss.backward()\r\n",
        "                optimizer_generator.step()\r\n",
        "                optimizer_generator.zero_grad()\r\n",
        "                optimizer_kp_detector.step()\r\n",
        "                optimizer_kp_detector.zero_grad()\r\n",
        "\r\n",
        "                if train_params['loss_weights']['generator_gan'] != 0:\r\n",
        "                    optimizer_discriminator.zero_grad()\r\n",
        "                    losses_discriminator = discriminator_full(x, generated)\r\n",
        "                    loss_values = [val.mean() for val in losses_discriminator.values()]\r\n",
        "                    loss = sum(loss_values)\r\n",
        "\r\n",
        "                    loss.backward()\r\n",
        "                    optimizer_discriminator.step()\r\n",
        "                    optimizer_discriminator.zero_grad()\r\n",
        "                else:\r\n",
        "                    losses_discriminator = {}\r\n",
        "\r\n",
        "                losses_generator.update(losses_discriminator)\r\n",
        "                losses = {key: value.mean().detach().data.cpu().numpy() for key, value in losses_generator.items()}\r\n",
        "                logger.log_iter(losses=losses)\r\n",
        "\r\n",
        "            scheduler_generator.step()\r\n",
        "            scheduler_discriminator.step()\r\n",
        "            scheduler_kp_detector.step()\r\n",
        "            \r\n",
        "            logger.log_epoch(epoch, {'generator': generator, 'discriminator': discriminator, 'kp_detector': kp_detector, 'optimizer_generator': optimizer_generator, 'optimizer_discriminator': optimizer_discriminator, 'optimizer_kp_detector': optimizer_kp_detector}, inp=x, out=generated)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "checkpoint_path = './logs/00000009-checkpoint.pth.tar'\r\n",
        "config_path = './config/prueba.yaml'\r\n",
        "generator1, kp_detector1 = load_checkpoints_Unet_3(config_path,checkpoint_path)\r\n",
        "print(kp_detector1.module.predictor)"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}