{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DeepHistory_Tesis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4FzgANMFnD0K"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1aabc06e03ae4e699c7cd2008eb5b1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8493a1db269d4f28a6b5a6e8f3a243ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91a33121db5f4eafb183b3a60ad90cb0",
              "IPY_MODEL_775cf6ec27004db38ff76bdb1a96149e",
              "IPY_MODEL_89c04f9d3e564d389493954efbd1c9bc"
            ]
          }
        },
        "8493a1db269d4f28a6b5a6e8f3a243ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91a33121db5f4eafb183b3a60ad90cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c896ec58a76d4fd888ddca4bd88e96d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_441acecba76f47aa93fc947d0961669e"
          }
        },
        "775cf6ec27004db38ff76bdb1a96149e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_21f24be10e554411804c8e767655c09d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5946721611664a6690e9a018a61f1eea"
          }
        },
        "89c04f9d3e564d389493954efbd1c9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b9acc735ebe4de989996a5e7f98d69b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:05&lt;00:00, 112MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06a1fca76d99417bae2bff62fa792446"
          }
        },
        "c896ec58a76d4fd888ddca4bd88e96d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "441acecba76f47aa93fc947d0961669e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21f24be10e554411804c8e767655c09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5946721611664a6690e9a018a61f1eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b9acc735ebe4de989996a5e7f98d69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06a1fca76d99417bae2bff62fa792446": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Malvodio/DeepHistory/blob/main/DeepHistory_Tesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEmy83_5Pjim"
      },
      "source": [
        "# DeepHistory_Tesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02v7XclydwEA"
      },
      "source": [
        "## Re-entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7w7AbU8INz4"
      },
      "source": [
        "### Iniciando enviroment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o5Cn9_JrFSm",
        "outputId": "2fddf0d7-a374-4ee2-a1cd-8fce11d645b7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4pOenyff9Di",
        "outputId": "0987ef22-40c9-4da0-99b2-0b542763cf14"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMih_D4ybBaV",
        "outputId": "2a9d5a70-4c8e-441f-e70f-9d8f1c414ea2"
      },
      "source": [
        "cd drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMlIRZIUd5lv",
        "outputId": "13ec7c61-660a-4c98-8600-eb5f8411ef28"
      },
      "source": [
        "# Clonando repositorio FOM\n",
        "!git clone https://github.com/AliaksandrSiarohin/first-order-model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'first-order-model'...\n",
            "remote: Enumerating objects: 299, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 299 (delta 2), reused 2 (delta 0), pack-reused 293\u001b[K\n",
            "Receiving objects: 100% (299/299), 72.15 MiB | 20.21 MiB/s, done.\n",
            "Resolving deltas: 100% (153/153), done.\n",
            "Checking out files: 100% (47/47), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymwLxTGF7Stf"
      },
      "source": [
        "Cambiando a repositorio First Order Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkDffz4xJVG_",
        "outputId": "0b0b1f83-c013-4dc9-b247-429bd7716a74"
      },
      "source": [
        "cd first-order-model/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/first-order-model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MAvLyzWymNIk",
        "outputId": "090ec815-afc0-4873-ab89-84ddb1b840fb"
      },
      "source": [
        "# Instalando requerimientos de repositorio First Order Model\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio==2.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: matplotlib==2.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
            "Collecting numpy==1.15.0\n",
            "  Using cached numpy-1.15.0-cp37-cp37m-manylinux1_x86_64.whl (13.8 MB)\n",
            "Requirement already satisfied: pandas==0.23.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.23.4)\n",
            "Requirement already satisfied: python-dateutil==2.7.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.7.3)\n",
            "Requirement already satisfied: pytz==2018.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (2018.5)\n",
            "Requirement already satisfied: PyYAML==5.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (5.1)\n",
            "Collecting scikit-image==0.14.0\n",
            "  Using cached scikit_image-0.14.0-cp37-cp37m-manylinux1_x86_64.whl (25.3 MB)\n",
            "Requirement already satisfied: scikit-learn==0.19.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (0.19.2)\n",
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.1.0)\n",
            "Requirement already satisfied: torch==1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.0.0)\n",
            "Requirement already satisfied: torchvision==0.2.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.2.1)\n",
            "Requirement already satisfied: tqdm==4.24.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.24.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.3.0->-r requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements.txt (line 2)) (2.4.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements.txt (line 2)) (0.10.0)\n",
            "Requirement already satisfied: dask[array]>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r requirements.txt (line 8)) (2.12.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r requirements.txt (line 8)) (1.1.1)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r requirements.txt (line 8)) (2.6.2)\n",
            "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[array]>=0.9.0->scikit-image==0.14.0->-r requirements.txt (line 8)) (0.11.1)\n",
            "Installing collected packages: numpy, scikit-image\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.2\n",
            "    Uninstalling numpy-1.21.2:\n",
            "      Successfully uninstalled numpy-1.21.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.2\n",
            "    Uninstalling scikit-image-0.18.2:\n",
            "      Successfully uninstalled scikit-image-0.18.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 0.9.1 requires scikit-learn>=0.20, but you have scikit-learn 0.19.2 which is incompatible.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.15.0 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.23.4 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.0.0 which is incompatible.\n",
            "tifffile 2021.8.8 requires numpy>=1.15.1, but you have numpy 1.15.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.15.0 which is incompatible.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.24.0 which is incompatible.\n",
            "pymc3 3.11.2 requires pandas>=0.24.0, but you have pandas 0.23.4 which is incompatible.\n",
            "pymc3 3.11.2 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "pyerfa 2.0.0 requires numpy>=1.17, but you have numpy 1.15.0 which is incompatible.\n",
            "pyarrow 3.0.0 requires numpy>=1.16.6, but you have numpy 1.15.0 which is incompatible.\n",
            "plotnine 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 2.2.2 which is incompatible.\n",
            "plotnine 0.6.0 requires numpy>=1.16.0, but you have numpy 1.15.0 which is incompatible.\n",
            "plotnine 0.6.0 requires pandas>=0.25.0, but you have pandas 0.23.4 which is incompatible.\n",
            "plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "mizani 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 2.2.2 which is incompatible.\n",
            "mizani 0.6.0 requires pandas>=0.25.0, but you have pandas 0.23.4 which is incompatible.\n",
            "kapre 0.3.5 requires numpy>=1.18.5, but you have numpy 1.15.0 which is incompatible.\n",
            "jaxlib 0.1.70+cuda110 requires numpy>=1.18, but you have numpy 1.15.0 which is incompatible.\n",
            "jax 0.2.19 requires numpy>=1.18, but you have numpy 1.15.0 which is incompatible.\n",
            "imbalanced-learn 0.4.3 requires scikit-learn>=0.20, but you have scikit-learn 0.19.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 0.23.4 which is incompatible.\n",
            "fbprophet 0.7.1 requires numpy>=1.15.4, but you have numpy 1.15.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.23.4 which is incompatible.\n",
            "fbprophet 0.7.1 requires python-dateutil>=2.8.0, but you have python-dateutil 2.7.3 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.24.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cupy-cuda101 9.1.0 requires numpy>=1.17, but you have numpy 1.15.0 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.15.0 which is incompatible.\n",
            "arviz 0.11.2 requires matplotlib>=3.0, but you have matplotlib 2.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.15.0 scikit-image-0.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMekzBTaYXSq",
        "outputId": "d017844d-db4b-41c6-c4fb-fab94f0eeb76"
      },
      "source": [
        "pip install imgaug==0.2.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imgaug==0.2.5 in /usr/local/lib/python3.7/dist-packages (0.2.5)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (0.14.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.15.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.2.2)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.6.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (7.1.2)\n",
            "Requirement already satisfied: dask[array]>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.12.0)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (1.3.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (1.1.1)\n",
            "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[array]>=0.9.0->scikit-image>=0.11.0->imgaug==0.2.5) (0.11.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (2018.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (2.7.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "VXN54jUTUHIj",
        "outputId": "102340b2-a0c6-4d49-ccc9-aa8d239e6231"
      },
      "source": [
        "pip install scikit-image==0.17.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-image==0.17.2\n",
            "  Downloading scikit_image-0.17.2-cp37-cp37m-manylinux1_x86_64.whl (12.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.5 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.17.2) (2021.8.8)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.17.2) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.17.2) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.17.2) (1.1.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.17.2) (2.6.2)\n",
            "Collecting numpy>=1.15.1\n",
            "  Using cached numpy-1.21.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.17.2) (2.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.17.2) (2.3.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.17.2) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.17.2) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.17.2) (2.7.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.17.2) (2018.5)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.17.2) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.17.2) (0.10.0)\n",
            "Installing collected packages: numpy, scikit-image\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.15.0\n",
            "    Uninstalling numpy-1.15.0:\n",
            "      Successfully uninstalled numpy-1.15.0\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.14.0\n",
            "    Uninstalling scikit-image-0.14.0:\n",
            "      Successfully uninstalled scikit-image-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 0.9.1 requires scikit-learn>=0.20, but you have scikit-learn 0.19.2 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.23.4 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.0.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.2 which is incompatible.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.24.0 which is incompatible.\n",
            "pymc3 3.11.2 requires pandas>=0.24.0, but you have pandas 0.23.4 which is incompatible.\n",
            "pymc3 3.11.2 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "plotnine 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 2.2.2 which is incompatible.\n",
            "plotnine 0.6.0 requires pandas>=0.25.0, but you have pandas 0.23.4 which is incompatible.\n",
            "plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "mizani 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 2.2.2 which is incompatible.\n",
            "mizani 0.6.0 requires pandas>=0.25.0, but you have pandas 0.23.4 which is incompatible.\n",
            "imbalanced-learn 0.4.3 requires scikit-learn>=0.20, but you have scikit-learn 0.19.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 0.23.4 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.23.4 which is incompatible.\n",
            "fbprophet 0.7.1 requires python-dateutil>=2.8.0, but you have python-dateutil 2.7.3 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.24.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "arviz 0.11.2 requires matplotlib>=3.0, but you have matplotlib 2.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.2 scikit-image-0.17.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4onrFmZFmSHG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ca7f4a9e-bfa9-419a-f841-d3f159c4e295"
      },
      "source": [
        "# Verificando dispositivo GPU\n",
        "import torch\n",
        "\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbyARU1nm2Vp"
      },
      "source": [
        "En este punto, se debe subir el modelo pre-entrenado VOX a la ruta first-order-model/models, además se debe editar el archivo vox-adv-256.yaml y configurar un batch_size de 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "id": "URs1eOTnd7Aj",
        "outputId": "0113426d-a072-4d06-a202-60e6c4636573"
      },
      "source": [
        "pip install --upgrade scikit-image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Collecting scikit-image\n",
            "  Downloading scikit_image-0.18.2-cp37-cp37m-manylinux1_x86_64.whl (29.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.2 MB 46 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.2.2)\n",
            "Collecting numpy>=1.16.5\n",
            "  Downloading numpy-1.21.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 185 kB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.8.8)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2018.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.7.3)\n",
            "Installing collected packages: numpy, scikit-image\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.15.0\n",
            "    Uninstalling numpy-1.15.0:\n",
            "      Successfully uninstalled numpy-1.15.0\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.14.0\n",
            "    Uninstalling scikit-image-0.14.0:\n",
            "      Successfully uninstalled scikit-image-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 0.9.1 requires scikit-learn>=0.20, but you have scikit-learn 0.19.2 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.23.4 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.0.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.2 which is incompatible.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.24.0 which is incompatible.\n",
            "pymc3 3.11.2 requires pandas>=0.24.0, but you have pandas 0.23.4 which is incompatible.\n",
            "pymc3 3.11.2 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "plotnine 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 2.2.2 which is incompatible.\n",
            "plotnine 0.6.0 requires pandas>=0.25.0, but you have pandas 0.23.4 which is incompatible.\n",
            "plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "mizani 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 2.2.2 which is incompatible.\n",
            "mizani 0.6.0 requires pandas>=0.25.0, but you have pandas 0.23.4 which is incompatible.\n",
            "imbalanced-learn 0.4.3 requires scikit-learn>=0.20, but you have scikit-learn 0.19.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 0.23.4 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.23.4 which is incompatible.\n",
            "fbprophet 0.7.1 requires python-dateutil>=2.8.0, but you have python-dateutil 2.7.3 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.24.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "arviz 0.11.2 requires matplotlib>=3.0, but you have matplotlib 2.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.2 scikit-image-0.18.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPKK7u7UnK0Z"
      },
      "source": [
        "# Importando librerías necesarias para el re-entrenamiento\n",
        "from os import path, makedirs\n",
        "from shutil import copy\n",
        "import imageio\n",
        "import numpy as np\n",
        "import sys\n",
        "import uuid\n",
        "import yaml\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import warnings\n",
        "from time import gmtime, strftime\n",
        "from skimage import img_as_ubyte\n",
        "from ctypes import cdll\n",
        "from train import train\n",
        "from modules.generator import OcclusionAwareGenerator\n",
        "from modules.discriminator import MultiScaleDiscriminator\n",
        "from modules.keypoint_detector import KPDetector\n",
        "from frames_dataset import FramesDataset\n",
        "from modules.util import DownBlock2d\n",
        "from tqdm import trange\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from logger import Logger\n",
        "from modules.model import GeneratorFullModel, DiscriminatorFullModel\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from sync_batchnorm import DataParallelWithCallback\n",
        "from frames_dataset import DatasetRepeater\n",
        "from demo import load_checkpoints, make_animation,load_checkpoints_Unet_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOyVn-jX46KB"
      },
      "source": [
        "checkpoint_path = './models/vox-adv-cpk.pth.tar'\n",
        "config_path = './config/vox-adv-256.yaml'\n",
        "#generator2, kp_detector2 = load_checkpoints(config_path,checkpoint_path)\n",
        "#print(kp_detector2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A954cuDjyYPH",
        "outputId": "b565dec0-2946-4d0e-f74a-4ca01480146a"
      },
      "source": [
        "checkpoint_path = './models/vox-adv-cpk.pth.tar'\n",
        "config_path = './config/vox-adv-256.yaml'\n",
        "generator2, kp_detector2 = load_checkpoints(config_path,checkpoint_path)\n",
        "print(kp_detector2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataParallelWithCallback(\n",
            "  (module): KPDetector(\n",
            "    (predictor): Hourglass(\n",
            "      (encoder): Encoder(\n",
            "        (down_blocks): ModuleList(\n",
            "          (0): DownBlock2d(\n",
            "            (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (norm): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "          )\n",
            "          (1): DownBlock2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (norm): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "          )\n",
            "          (2): DownBlock2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (norm): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "          )\n",
            "          (3): DownBlock2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (norm): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "          )\n",
            "          (4): DownBlock2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (norm): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (decoder): Decoder(\n",
            "        (up_blocks): ModuleList(\n",
            "          (0): UpBlock2d(\n",
            "            (conv): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (norm): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (1): UpBlock2d(\n",
            "            (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (norm): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (2): UpBlock2d(\n",
            "            (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (norm): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (3): UpBlock2d(\n",
            "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (norm): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (4): UpBlock2d(\n",
            "            (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (norm): SynchronizedBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (kp): Conv2d(35, 10, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (jacobian): Conv2d(35, 40, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (down): AntiAliasInterpolation2d()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MpDeQbg2wDi",
        "outputId": "c2d1e78f-9d78-4e67-fee2-371afa907228"
      },
      "source": [
        "for i in range(5)[::-1]:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "3\n",
            "2\n",
            "1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "cDxn0fEHKGsV",
        "outputId": "710df6d6-9c00-4a2f-9bb0-ee0413bf4209"
      },
      "source": [
        "generator_new, kp_detector_new = load_checkpoints_Unet_3(config_path,checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a7230592e788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkp_detector_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoints_Unet_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/MyDrive/first-order-model/demo.py\u001b[0m in \u001b[0;36mload_checkpoints_Unet_3\u001b[0;34m(config_path, checkpoint_path, cpu)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     kp_detector = KPDetector_Unet_3(**config['model_params']['kp_detector_params'],\n\u001b[0;32m--> 169\u001b[0;31m                              **config['model_params']['common_params'])\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mkp_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/first-order-model/modules/keypoint_detector.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block_expansion, num_kp, num_channels, max_features, num_blocks, temperature, estimate_jacobian, scale_factor, single_jacobian_map, pad)\u001b[0m\n\u001b[1;32m     84\u001b[0m                  \u001b[0mnum_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimate_jacobian\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                  single_jacobian_map=False, pad=0):\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKPDetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         self.predictor = Unet_3_Plus(block_expansion, in_features=num_channels,\n",
            "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4TjHOmIKF15",
        "outputId": "87548989-de11-4fcf-e75b-7585e57ae48f"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yUypA3CKGiU",
        "outputId": "b10e876e-c509-4712-fe94-90e68a7f8d45"
      },
      "source": [
        "cd first-order-model-mod/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/first-order-model-mod\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--FXe5wCnfh6"
      },
      "source": [
        "Re-definiendo función para cargar el checkpoint del modelo pre-entrenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViDibqOrnZP8"
      },
      "source": [
        "def load_cpk(checkpoint_path, generator=None, discriminator=None, kp_detector=None,\n",
        "                 optimizer_generator=None, optimizer_discriminator=None, optimizer_kp_detector=None):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    if generator is not None:\n",
        "        generator.load_state_dict(checkpoint['generator'])\n",
        "    if kp_detector is not None:\n",
        "        kp_detector.load_state_dict(checkpoint['kp_detector'])\n",
        "    if discriminator is not None:\n",
        "        try:\n",
        "            discriminator.load_state_dict(checkpoint['discriminator'])\n",
        "        except:\n",
        "            print ('No discriminator in the state-dict. Dicriminator will be randomly initialized')\n",
        "\n",
        "   # print(kp_detector)\n",
        "    \n",
        "    if optimizer_generator is not None:\n",
        "        optimizer_generator.load_state_dict(checkpoint['optimizer_generator'])\n",
        "    if optimizer_discriminator is not None:\n",
        "        try:\n",
        "            optimizer_discriminator.load_state_dict(checkpoint['optimizer_discriminator'])\n",
        "        except RuntimeError as e:\n",
        "            print ('No discriminator optimizer in the state-dict. Optimizer will be not initialized')\n",
        "    if optimizer_kp_detector is not None:\n",
        "        optimizer_kp_detector.load_state_dict(checkpoint['optimizer_kp_detector'])\n",
        "\n",
        "    return checkpoint['epoch']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LJ0IsB4n1BJ"
      },
      "source": [
        "Estableciendo parámetros iniciales y re-entrenando modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "1aabc06e03ae4e699c7cd2008eb5b1df",
            "8493a1db269d4f28a6b5a6e8f3a243ea",
            "91a33121db5f4eafb183b3a60ad90cb0",
            "775cf6ec27004db38ff76bdb1a96149e",
            "89c04f9d3e564d389493954efbd1c9bc",
            "c896ec58a76d4fd888ddca4bd88e96d5",
            "441acecba76f47aa93fc947d0961669e",
            "21f24be10e554411804c8e767655c09d",
            "5946721611664a6690e9a018a61f1eea",
            "8b9acc735ebe4de989996a5e7f98d69b",
            "06a1fca76d99417bae2bff62fa792446"
          ]
        },
        "id": "XNsmwmeCnucw",
        "outputId": "bd662c61-863f-4c85-f666-31cda23dee3b"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "config = './config/vox-adv-256.yaml'\n",
        "device_ids = [0]\n",
        "#checkpoint = './models/vox-adv-cpk.pth.tar'\n",
        "checkpoint = None\n",
        "log_dir = './logs'\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    with open(config) as f:\n",
        "        config = yaml.load(f)\n",
        "        \n",
        "    generator = OcclusionAwareGenerator(**config['model_params']['generator_params'], **config['model_params']['common_params'])\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        generator.to(device_ids[0])\n",
        "\n",
        "    discriminator = MultiScaleDiscriminator(**config['model_params']['discriminator_params'], **config['model_params']['common_params'])\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        discriminator.to(device_ids[0])\n",
        "\n",
        "    kp_detector = KPDetector(**config['model_params']['kp_detector_params'], **config['model_params']['common_params'])\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        kp_detector.to(device_ids[0])\n",
        "            \n",
        "    dataset = FramesDataset(is_train=1, **config['dataset_params'])\n",
        "\n",
        "\n",
        "    print(\"Training...\")\n",
        "\n",
        "    train_params = config['train_params']\n",
        "\n",
        "    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=train_params['lr_generator'], betas=(0.5, 0.999))\n",
        "    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=train_params['lr_discriminator'], betas=(0.5, 0.999))\n",
        "    optimizer_kp_detector = torch.optim.Adam(kp_detector.parameters(), lr=train_params['lr_kp_detector'], betas=(0.5, 0.999))\n",
        "\n",
        "    if checkpoint is not None:\n",
        "        start_epoch = load_cpk(checkpoint, generator, discriminator, kp_detector, optimizer_generator, optimizer_discriminator, None if train_params['lr_kp_detector'] == 0 else optimizer_kp_detector)\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "    \n",
        "    # Changes\n",
        "    #kp_detector.predictor.encoder.down_blocks[0].conv.kernel_size = (5, 4)\n",
        "    #kp_detector.predictor.encoder.down_blocks[1].conv.kernel_size = (5, 4)\n",
        "    #kp_detector.predictor.encoder.down_blocks[2].conv.kernel_size = (5, 4)\n",
        "    #kp_detector.predictor.encoder.down_blocks[3].conv.kernel_size = (5, 4)\n",
        "    #kp_detector.predictor.encoder.down_blocks[4].conv.kernel_size = (4, 4)\n",
        "    #print(kp_detector.predictor.encoder)\n",
        "    # End Changes\n",
        "\n",
        "    scheduler_generator = MultiStepLR(optimizer_generator, train_params['epoch_milestones'], gamma=0.1, last_epoch=start_epoch - 1)\n",
        "\n",
        "    scheduler_discriminator = MultiStepLR(optimizer_discriminator, train_params['epoch_milestones'], gamma=0.1, last_epoch=start_epoch - 1)\n",
        "\n",
        "    scheduler_kp_detector = MultiStepLR(optimizer_kp_detector, train_params['epoch_milestones'], gamma=0.1, last_epoch=-1 + start_epoch * (train_params['lr_kp_detector'] != 0))\n",
        "\n",
        "    if 'num_repeats' in train_params or train_params['num_repeats'] != 1:\n",
        "        dataset = DatasetRepeater(dataset, train_params['num_repeats'])\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=train_params['batch_size'], shuffle=True, num_workers=6, drop_last=True)\n",
        "\n",
        "    generator_full = GeneratorFullModel(kp_detector, generator, discriminator, train_params)\n",
        "    discriminator_full = DiscriminatorFullModel(kp_detector, generator, discriminator, train_params)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        generator_full = DataParallelWithCallback(generator_full, device_ids=device_ids)\n",
        "        discriminator_full = DataParallelWithCallback(discriminator_full, device_ids=device_ids)\n",
        "\n",
        "    with Logger(log_dir=log_dir, visualizer_params=config['visualizer_params'], checkpoint_freq=train_params['checkpoint_freq']) as logger:\n",
        "        for epoch in trange(start_epoch, train_params['num_epochs']):\n",
        "            for x in dataloader:\n",
        "                #print(dataloader)\n",
        "                losses_generator, generated = generator_full(x)\n",
        "\n",
        "                loss_values = [val.mean() for val in losses_generator.values()]\n",
        "                loss = sum(loss_values)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer_generator.step()\n",
        "                optimizer_generator.zero_grad()\n",
        "                optimizer_kp_detector.step()\n",
        "                optimizer_kp_detector.zero_grad()\n",
        "\n",
        "                if train_params['loss_weights']['generator_gan'] != 0:\n",
        "                    optimizer_discriminator.zero_grad()\n",
        "                    losses_discriminator = discriminator_full(x, generated)\n",
        "                    loss_values = [val.mean() for val in losses_discriminator.values()]\n",
        "                    loss = sum(loss_values)\n",
        "\n",
        "                    loss.backward()\n",
        "                    optimizer_discriminator.step()\n",
        "                    optimizer_discriminator.zero_grad()\n",
        "                else:\n",
        "                    losses_discriminator = {}\n",
        "\n",
        "                losses_generator.update(losses_discriminator)\n",
        "                losses = {key: value.mean().detach().data.cpu().numpy() for key, value in losses_generator.items()}\n",
        "                logger.log_iter(losses=losses)\n",
        "\n",
        "            scheduler_generator.step()\n",
        "            scheduler_discriminator.step()\n",
        "            scheduler_kp_detector.step()\n",
        "            \n",
        "            logger.log_epoch(epoch, {'generator': generator, 'discriminator': discriminator, 'kp_detector': kp_detector, 'optimizer_generator': optimizer_generator, 'optimizer_discriminator': optimizer_discriminator, 'optimizer_kp_detector': optimizer_kp_detector}, inp=x, out=generated)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use predefined train-test split.\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1aabc06e03ae4e699c7cd2008eb5b1df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [14:45<00:00, 88.59s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YYsMw0Vz0zr",
        "outputId": "d56c3a5e-f021-41aa-8360-238b7c32dd67"
      },
      "source": [
        "checkpoint_path = './logs/00000009-checkpoint.pth.tar'\n",
        "config_path = './config/vox-adv-256.yaml'\n",
        "generator1, kp_detector1 = load_checkpoints(config_path,checkpoint_path)\n",
        "print(kp_detector1.module.predictor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hourglass(\n",
            "  (encoder): Encoder(\n",
            "    (down_blocks): ModuleList(\n",
            "      (0): DownBlock2d(\n",
            "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "      )\n",
            "      (1): DownBlock2d(\n",
            "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "      )\n",
            "      (2): DownBlock2d(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "      )\n",
            "      (3): DownBlock2d(\n",
            "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "      )\n",
            "      (4): DownBlock2d(\n",
            "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "      )\n",
            "      (5): DownBlock2d(\n",
            "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (up_blocks): ModuleList(\n",
            "      (0): UpBlock2d(\n",
            "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): UpBlock2d(\n",
            "        (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): UpBlock2d(\n",
            "        (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): UpBlock2d(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (4): UpBlock2d(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (5): UpBlock2d(\n",
            "        (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (norm): SynchronizedBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ7JkcpRQsYO",
        "outputId": "e7fe2513-66f7-4f7f-fc06-43d1dd3a1732"
      },
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python run.py --config config/vox-adv-256.yaml --device_ids 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run.py:40: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  config = yaml.load(f)\n",
            "Use predefined train-test split.\n",
            "Training...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "  0% 0/150 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"run.py\", line 81, in <module>\n",
            "    train(config, generator, discriminator, kp_detector, opt.checkpoint, log_dir, dataset, opt.device_ids)\n",
            "  File \"/content/first-order-model/train.py\", line 50, in train\n",
            "    for x in dataloader:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 425, in reraise\n",
            "    raise self.exc_type(msg)\n",
            "TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/first-order-model/frames_dataset.py\", line 154, in __getitem__\n",
            "    return self.dataset[idx % self.dataset.__len__()]\n",
            "  File \"/content/first-order-model/frames_dataset.py\", line 114, in __getitem__\n",
            "    video_array = [img_as_float32(io.imread(os.path.join(path, frames[idx]))) for idx in frame_idx]\n",
            "  File \"/content/first-order-model/frames_dataset.py\", line 114, in <listcomp>\n",
            "    video_array = [img_as_float32(io.imread(os.path.join(path, frames[idx]))) for idx in frame_idx]\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 94, in join\n",
            "    genericpath._check_arg_types('join', a, *p)\n",
            "  File \"/usr/lib/python3.7/genericpath.py\", line 155, in _check_arg_types\n",
            "    raise TypeError(\"Can't mix strings and bytes in path components\") from None\n",
            "TypeError: Can't mix strings and bytes in path components\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3V4idNUTU08"
      },
      "source": [
        "!rm -rf video-preprocessing/vox-png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAM-XvkHyYLH"
      },
      "source": [
        "!rmdir 'data/vox-png/train/id11181#cu11S_2dNyA#007258#007702.mp4/.ipynb_checkpoints'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}